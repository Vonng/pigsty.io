<!doctype html>
<html itemscope itemtype="http://schema.org/WebPage" lang="en" class="no-js">
  <head>
    <meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link rel="canonical" type="text/html" href="/blog/pg/">
<link rel="alternate" type="application/rss&#43;xml" href="/blog/pg/index.xml">
<meta name="robots" content="noindex, nofollow">


<link rel="shortcut icon" href="/favicons/favicon.ico" >
<link rel="apple-touch-icon" href="/favicons/apple-touch-icon-180x180.png" sizes="180x180">
<link rel="icon" type="image/png" href="/favicons/favicon-16x16.png" sizes="16x16">
<link rel="icon" type="image/png" href="/favicons/favicon-32x32.png" sizes="32x32">
<link rel="icon" type="image/png" href="/favicons/android-36x36.png" sizes="36x36">
<link rel="icon" type="image/png" href="/favicons/android-48x48.png" sizes="48x48">
<link rel="icon" type="image/png" href="/favicons/android-72x72.png" sizes="72x72">
<link rel="icon" type="image/png" href="/favicons/android-96x96.png" sizes="96x96">
<link rel="icon" type="image/png" href="/favicons/android-144x144.png" sizes="144x144">
<link rel="icon" type="image/png" href="/favicons/android-192x192.png" sizes="192x192">

<title>Postgres | Pigsty</title>
<meta name="description" content="Posts about Pigsty and PostgreSQL">
<meta property="og:title" content="Postgres" />
<meta property="og:description" content="Posts about Pigsty and PostgreSQL" />
<meta property="og:type" content="website" />
<meta property="og:url" content="/blog/pg/" />

<meta itemprop="name" content="Postgres">
<meta itemprop="description" content="Posts about Pigsty and PostgreSQL"><meta name="twitter:card" content="summary"/><meta name="twitter:title" content="Postgres"/>
<meta name="twitter:description" content="Posts about Pigsty and PostgreSQL"/>




<link rel="preload" href="/scss/main.min.194607c777ee31a481a26dfc3d1c65134dfc8eb296a0aae9d353b3bd5be6a683.css" as="style">
<link href="/scss/main.min.194607c777ee31a481a26dfc3d1c65134dfc8eb296a0aae9d353b3bd5be6a683.css" rel="stylesheet" integrity="">

<script
  src="/js/jquery-3.6.3.min.js"
  integrity="sha512-STof4xm1wgkfm7heWqFJVn58Hm3EtS31XFaagaa8VMReCXAkQnJZ+jEy8PCC/iT18dFy95WcExNHFTqLyp72eQ=="
  crossorigin="anonymous"></script>
<script defer
  src="/js/lunr.min.js"
  integrity="sha384-203J0SNzyqHby3iU6hzvzltrWi/M41wOP5Gu+BiJMz5nwKykbkUx8Kp7iti0Lpli"
  crossorigin="anonymous"></script>
<script async src="https://www.googletagmanager.com/gtag/js?id=G-LG1V9WTKGE"></script>
<script>
var doNotTrack = false;
if (!doNotTrack) {
	window.dataLayer = window.dataLayer || [];
	function gtag(){dataLayer.push(arguments);}
	gtag('js', new Date());
	gtag('config', 'G-LG1V9WTKGE');
}
</script>
  </head>
  <body class="td-section td-blog">
    <header>
      <nav class="td-navbar navbar-dark js-navbar-scroll">
<div class="container-fluid flex-column flex-md-row">
  <a class="navbar-brand" href="/"><span class="navbar-brand__logo navbar-logo"><svg xmlns="http://www.w3.org/2000/svg" xmlns:xl="http://www.w3.org/1999/xlink" xmlns:dc="http://purl.org/dc/elements/1.1/" viewBox="0 0 24 24" width="24" height="24"><defs/><g id="32" fill="none" stroke-dasharray="none" fill-opacity="1" stroke-opacity="1" stroke="none"><title>32</title><g id="32_图层_2"><title>图层 2</title><g id="Group_17"><g id="Graphic_16"/><g id="Graphic_15"><path d="M7.666187 11.971335l2.165064-3.75H14.16138l2.165065 3.75-2.165065 3.75H9.831251z" fill="#bbb" fill-opacity=".9526367"/><path d="M7.666187 11.971335l2.165064-3.75H14.16138l2.165065 3.75-2.165065 3.75H9.831251z" stroke="#fff" stroke-linecap="round" stroke-linejoin="round" stroke-width=".6730434"/></g><g id="Graphic_14"><path d="M7.666187 19.474806l2.165064-3.75H14.16138l2.165065 3.75-2.165065 3.75H9.831251z" fill="#de372c" fill-opacity=".8545852"/><path d="M7.666187 19.474806l2.165064-3.75H14.16138l2.165065 3.75-2.165065 3.75H9.831251z" stroke="#fff" stroke-linecap="round" stroke-linejoin="round" stroke-width=".6730434"/></g><g id="Graphic_13"><path d="M14.161476 15.751202l2.165064-3.75h4.33013l2.165064 3.75-2.165064 3.75H16.32654z" fill="#424242" fill-opacity=".9016462"/><path d="M14.161476 15.751202l2.165064-3.75h4.33013l2.165064 3.75-2.165064 3.75H16.32654z" stroke="#fff" stroke-linecap="round" stroke-linejoin="round" stroke-width=".6730434"/></g><g id="Graphic_12"><path d="M14.161476 8.226008 16.32654 4.4760076h4.33013L22.821734 8.226008l-2.165064 3.75H16.32654z" fill="#ffa269" fill-opacity=".8975772"/><path d="M14.161476 8.226008 16.32654 4.4760076h4.33013L22.821734 8.226008l-2.165064 3.75H16.32654z" stroke="#fff" stroke-linecap="round" stroke-linejoin="round" stroke-width=".6730434"/></g><g id="Graphic_11"><path d="M7.666187 4.5 9.831251.75H14.16138L16.326445 4.5 14.16138 8.25H9.831251z" fill="#419edb" fill-opacity=".8979957"/><path d="M7.666187 4.5 9.831251.75H14.16138L16.326445 4.5 14.16138 8.25H9.831251z" stroke="#fff" stroke-linecap="round" stroke-linejoin="round" stroke-width=".6730434"/></g><g id="Graphic_10"><path d="M1.1491742 8.226008 3.3142388 4.4760076H7.644368L9.809432 8.226008l-2.165064 3.75H3.3142388z" fill="#2f6793" fill-opacity=".9002511"/><path d="M1.1491742 8.226008 3.3142388 4.4760076H7.644368L9.809432 8.226008l-2.165064 3.75H3.3142388z" stroke="#fff" stroke-linecap="round" stroke-linejoin="round" stroke-width=".6730434"/></g><g id="Graphic_9"><path d="M1.182071 15.741036l2.1650645-3.75h4.330129l2.1650645 3.75-2.1650645 3.75H3.3471355z" fill="#53ac79" fill-opacity=".9"/><path d="M1.182071 15.741036l2.1650645-3.75h4.330129l2.1650645 3.75-2.1650645 3.75H3.3471355z" stroke="#fff" stroke-linecap="round" stroke-linejoin="round" stroke-width=".6730434"/></g></g></g></g></svg></span><span class="navbar-brand__name">Pigsty</span></a>
  <div class="td-navbar-nav-scroll ms-md-auto" id="main_navbar">
    <ul class="navbar-nav">
      <li class="nav-item">
        <a class="nav-link" href="/docs/"><i class='fa-solid fa-book'></i><span>Docs</span></a>
      </li>
      <li class="nav-item">
        <a class="nav-link active" href="/blog/"><i class="fas fa-blog"></i><span>Blog</span></a>
      </li>
      <li class="nav-item">
        <a class="nav-link" href="https://github.com/Vonng/pigsty/" target="_blank" rel="noopener"><i class='fab fa-github'></i><span>GitHub</span></a>
      </li>
      <li class="nav-item dropdown d-none d-lg-block">
        <div class="dropdown">
  <a class="nav-link dropdown-toggle" href="#" role="button" data-bs-toggle="dropdown" aria-haspopup="true" aria-expanded="false">
      <i class="fa-solid fa-language"></i>English</a>
  <ul class="dropdown-menu">
    <li><a class="dropdown-item" href="/zh/blog/pg/">中文</a></li>
    </ul>
</div>
</li>
      </ul>
  </div>
  <div class="d-none d-lg-block">
    <div class="td-search td-search--offline">
  <div class="td-search__icon"></div>
  <input
    type="search"
    class="td-search__input form-control"
    placeholder="Search this site…"
    aria-label="Search this site…"
    autocomplete="off"
    
    data-offline-search-index-json-src="/offline-search-index.b40d8bc16bcda835248990ff9db38455.json"
    data-offline-search-base-href="/"
    data-offline-search-max-results="10"
  >
</div>
  </div>
</div>
</nav>
    </header>
    <div class="container-fluid td-outer">
      <div class="td-main">
        <div class="row flex-xl-nowrap">
          <div class="col-12 col-md-3 col-xl-2 td-sidebar d-print-none">
          </div>
          <div class="d-none d-xl-block col-xl-2 td-toc d-print-none">
          </div>
          <main class="col-12 col-md-9 col-xl-8 ps-md-5 pe-md-4" role="main">
            




<div class="td-content">
<div class="pageinfo pageinfo-primary d-print-none">
<p>
This is the multi-page printable view of this section.
<a href="#" onclick="print();return false;">Click here to print</a>.
</p><p>
<a href="/blog/pg/">Return to the regular view of this page</a>.
</p>
</div>



<h1 class="title">Postgres</h1>
<div class="lead">Posts about Pigsty and PostgreSQL</div>




    <ul>
    
  
  
  
  

  
    
    
	

    <li><a href="#pg-cc0f3b60839047690e18daaf6e1b2eb0">Pig, The Postgres Extension Wizard</a></li>



    
  
    
    
	

    <li><a href="#pg-7f5a0de014a67abd29c62899ad7fa900">The idea way to install PostgreSQL Extensions</a></li>



    
  
    
    
	

    <li><a href="#pg-635f4dbe52424af419b468e194e22c72">Self-Hosting Dify with PG, PGVector, and Pigsty</a></li>



    
  
    
    
	

    <li><a href="#pg-7b7e2fed3610aaf3b302a1fa64530049">PGCon.Dev 2024, The conf that shutdown PG for a week</a></li>



    
  
    
    
	

    <li><a href="#pg-7d36280c97d93954ecc5eee99cde64b7">Postgres is eating the database world</a></li>



    
  
    
    
	

    <li><a href="#pg-fe0303de91d0c7a97aa03dbbd71290fa">PostgreSQL Convention 2024</a></li>



    
  
    
    
	

    <li><a href="#pg-9ac7b152e2b98d51f3cf9cda74feaf4a">PostgreSQL, The most successful database</a></li>



    
  

    </ul>


<div class="content">
      
</div>
</div>


  
  
  
  

  
  

  
    
    
	
    


  

<div class="td-content" style="">
    <h1 id="pg-cc0f3b60839047690e18daaf6e1b2eb0">Pig, The Postgres Extension Wizard</h1>
	
	<div class="td-byline mb-4">
		By <b><a href="https://vonng.com">RuohangFeng</a>(<a href="https://vonng.com/en/">@Vonng</a>)| <a href="https://mp.weixin.qq.com/s/8zxeDQ7p5tPNGYED_1Bugg">WeChat</a></b> |
        
		<time datetime="2024-12-29" class="text-muted">2024-12-29</time>
        
	</div>
	<h2 id="title-meet-pig-the-postgres-extension-wizard"><strong>Title</strong>: Meet <em>Pig</em>: The Postgres Extension Wizard</h2>
<p>Ever wished installing or upgrading PostgreSQL extensions didn’t feel like digging through outdated readmes, cryptic configure scripts, or random GitHub forks &amp; patches? The painful truth is that Postgres’s richness of extension often comes at the cost of complicated setups—especially if you’re juggling multiple distros or CPU architectures.</p>
<p>Enter <strong>Pig</strong>, a Go-based package manager built to tame Postgres and its ecosystem of <a href="https://ext.pigsty.io/#/list">340+</a> extensions in one fell swoop. TimescaleDB, Citus, PGVector, 20+ Rust extensions, plus every must-have piece to <a href="https://pigsty.io/blog/db/supabase">self-host</a> Supabase — Pig’s unified CLI makes them all effortlessly accessible. It cuts out messy source builds and half-baked repos, offering version-aligned RPM/DEB packages that work seamlessly across Debian, Ubuntu, and RedHat flavors. No guesswork, no drama.</p>
<p>Instead of reinventing the wheel, Pig piggyback your system’s native package manager (APT, YUM, DNF) and follow official PGDG packaging conventions to ensure a glitch-free fit. That means you don’t have to choose between “the right way” and “the quick way”; Pig respects your existing repos, aligns with standard OS best practices, and fits neatly alongside other packages you already use.</p>
<p>Ready to give your Postgres superpowers without the usual hassle? Check out <strong><a href="https://github.com/pgsty/pig">GitHub</a></strong> for documentation, installation steps, and a peek at its massive <a href="https://ext.pigsty.io/#/list">extension list</a>. Then, watch your local Postgres instance transform into a powerhouse of specialized modules—no black magic is required. If <a href="https://medium.com/@fengruohang/postgres-is-eating-the-database-world-157c204dcfc4">the future of Postgres is unstoppable extensibility</a>, Pig is the genie that helps you unlock it. Honestly, nobody ever complained that they had <em>too many</em> extensions.</p>
<p><a href="https://github.com/pgsty/pig">PIG v0.1 Release</a> | <a href="https://github.com/pgsty/pig">GitHub Repo</a> | Blog: <a href="https://medium.com/@fengruohang/the-idea-way-to-deliver-postgresql-extensions-35646464bb71">The Idea Way to deliver PG Extensions</a></p>
<hr>
<h2 id="get-started">Get Started</h2>
<p><a href="/blog/pg/pig/#installation">Install</a> the <code>pig</code> package itself with scripts or the traditional yum/apt way.</p>
<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>curl -fsSL https://repo.pigsty.io/pig <span style="color:#000;font-weight:bold">|</span> bash
</span></span></code></pre></div><p>Then it&rsquo;s ready to use; assume you want to install the <a href="https://ext.pigsty.io/#/pg_duckdb"><code>pg_duckdb</code></a> extension:</p>
<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>$ pig repo add pigsty pgdg -u  <span style="color:#8f5902;font-style:italic"># add pgdg &amp; pigsty repo, update cache</span>
</span></span><span style="display:flex;"><span>$ pig repo <span style="color:#204a87">set</span> -u              <span style="color:#8f5902;font-style:italic"># overwrite all existing repos, brute but effective</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>$ pig ext install pg17         <span style="color:#8f5902;font-style:italic"># install native PGDG PostgreSQL 17 kernels packages</span>
</span></span><span style="display:flex;"><span>$ pig ext install pg_duckdb    <span style="color:#8f5902;font-style:italic"># install the pg_duckdb extension (for current pg17)</span>
</span></span></code></pre></div><h3 id="extension-management"><strong>Extension Management</strong></h3>
<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>pig ext list    <span style="color:#ce5c00;font-weight:bold">[</span>query<span style="color:#ce5c00;font-weight:bold">]</span>      <span style="color:#8f5902;font-style:italic"># list &amp; search extension      </span>
</span></span><span style="display:flex;"><span>pig ext info    <span style="color:#ce5c00;font-weight:bold">[</span>ext...<span style="color:#ce5c00;font-weight:bold">]</span>     <span style="color:#8f5902;font-style:italic"># get information of a specific extension</span>
</span></span><span style="display:flex;"><span>pig ext status  <span style="color:#ce5c00;font-weight:bold">[</span>-v<span style="color:#ce5c00;font-weight:bold">]</span>         <span style="color:#8f5902;font-style:italic"># show installed extension and pg status</span>
</span></span><span style="display:flex;"><span>pig ext add     <span style="color:#ce5c00;font-weight:bold">[</span>ext...<span style="color:#ce5c00;font-weight:bold">]</span>     <span style="color:#8f5902;font-style:italic"># install extension for current pg version</span>
</span></span><span style="display:flex;"><span>pig ext rm      <span style="color:#ce5c00;font-weight:bold">[</span>ext...<span style="color:#ce5c00;font-weight:bold">]</span>     <span style="color:#8f5902;font-style:italic"># remove extension for current pg version</span>
</span></span><span style="display:flex;"><span>pig ext update  <span style="color:#ce5c00;font-weight:bold">[</span>ext...<span style="color:#ce5c00;font-weight:bold">]</span>     <span style="color:#8f5902;font-style:italic"># update extension to the latest version</span>
</span></span><span style="display:flex;"><span>pig ext import  <span style="color:#ce5c00;font-weight:bold">[</span>ext...<span style="color:#ce5c00;font-weight:bold">]</span>     <span style="color:#8f5902;font-style:italic"># download extension to local repo</span>
</span></span><span style="display:flex;"><span>pig ext link    <span style="color:#ce5c00;font-weight:bold">[</span>ext...<span style="color:#ce5c00;font-weight:bold">]</span>     <span style="color:#8f5902;font-style:italic"># link postgres installation to path</span>
</span></span><span style="display:flex;"><span>pig ext build   <span style="color:#ce5c00;font-weight:bold">[</span>ext...<span style="color:#ce5c00;font-weight:bold">]</span>     <span style="color:#8f5902;font-style:italic"># setup building env for extension</span>
</span></span></code></pre></div><h3 id="repo-management"><strong>Repo Management</strong></h3>
<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>pig repo list                    <span style="color:#8f5902;font-style:italic"># available repo list             (info)</span>
</span></span><span style="display:flex;"><span>pig repo info   <span style="color:#ce5c00;font-weight:bold">[</span>repo<span style="color:#000;font-weight:bold">|</span>module...<span style="color:#ce5c00;font-weight:bold">]</span> <span style="color:#8f5902;font-style:italic"># show repo info                  (info)</span>
</span></span><span style="display:flex;"><span>pig repo status                  <span style="color:#8f5902;font-style:italic"># show current repo status        (info)</span>
</span></span><span style="display:flex;"><span>pig repo add    <span style="color:#ce5c00;font-weight:bold">[</span>repo<span style="color:#000;font-weight:bold">|</span>module...<span style="color:#ce5c00;font-weight:bold">]</span> <span style="color:#8f5902;font-style:italic"># add repo and modules            (root)</span>
</span></span><span style="display:flex;"><span>pig repo rm     <span style="color:#ce5c00;font-weight:bold">[</span>repo<span style="color:#000;font-weight:bold">|</span>module...<span style="color:#ce5c00;font-weight:bold">]</span> <span style="color:#8f5902;font-style:italic"># remove repo &amp; modules           (root)</span>
</span></span><span style="display:flex;"><span>pig repo update                  <span style="color:#8f5902;font-style:italic"># update repo pkg cache           (root)</span>
</span></span><span style="display:flex;"><span>pig repo create                  <span style="color:#8f5902;font-style:italic"># create repo on current system   (root)</span>
</span></span><span style="display:flex;"><span>pig repo boot                    <span style="color:#8f5902;font-style:italic"># boot repo from offline package  (root)</span>
</span></span><span style="display:flex;"><span>pig repo cache                   <span style="color:#8f5902;font-style:italic"># cache repo as offline package   (root)</span>
</span></span></code></pre></div>
</div>





    
	
  
    
    
	
    


  

<div class="td-content" style="page-break-before: always">
    <h1 id="pg-7f5a0de014a67abd29c62899ad7fa900">The idea way to install PostgreSQL Extensions</h1>
	
	<div class="td-byline mb-4">
		By <b><a href="https://vonng.com">Vonng</a>(<a href="https://vonng.com/en/">@Vonng</a>)</b> |
        
		<time datetime="2024-11-02" class="text-muted">2024-11-02</time>
        
	</div>
	<p><a href="/blog/pg/pg-eat-db-world/"><strong>PostgreSQL Is Eating the Database World</strong></a> through the power of <strong>extensibility</strong>.
With <strong>340</strong> extensions powering PostgreSQL, we may not say it&rsquo;s invincible, but it’s definitely getting much closer.</p>
<p>I believe the PostgreSQL community has reached a consensus on the importance of extensions.
So the real question now becomes: <strong>&ldquo;What should we do about it?&rdquo;</strong></p>
<p>What&rsquo;s the primary problem with PostgreSQL extensions? In my opinion, it’s their <strong>accessibility</strong>.
Extensions are useless if most users can’t easily install and enable them. But it&rsquo;s not that easy.</p>
<p>Even the largest cloud postgres vendors are struggling with this.
They have some inherent limitations (multi-tenancy, security, licensing) that make it hard for them to fully address this issue.</p>
<p>So here&rsquo;s my plan, I&rsquo;ve created a <a href="https://ext.pigsty.io/"><strong>repository</strong></a> that hosts <a href="https://ext.pigsty.io/#/list"><strong>340</strong></a> of the most capable extensions in the PostgreSQL ecosystem,
available as RPM / DEB packages on mainstream Linux OS distros.  And the goal is to take PostgreSQL one solid step closer to becoming the all-powerful database and achieve <strong>the great alignment</strong> between the Debian and EL OS ecosystems.</p>
<blockquote>
<p><a href="/blog/pg/pg-ext-repo/#apt-repo"><strong>TL;DR: Take me to the HOW-TO part!</strong></a></p>
</blockquote>
<p><a href="/blog/pg/pg-eat-deb-world"><img src="/img/pigsty/ecosystem.jpg" style="max-width: 800px; max-height: 1000px; width: 100%; height: auto;"></a></p>
<hr>
<h2 id="the-status-quo">The status quo</h2>
<p>The PostgreSQL ecosystem is rich with extensions, but how do you actually install and use them? This initial hurdle becomes a roadblock for many. There are some existing solutions:</p>
<p>PGXN says, &ldquo;<em>You can download and compile extensions on the fly with <code>pgxnclient</code>.</em>&rdquo;
Tembo says, &ldquo;<em>We have prepared pre-configured extension stack as Docker images.</em>&rdquo;
StackGres &amp; Omnigres says, &ldquo;<em>We download <code>.so</code> files on the fly.</em>&rdquo; All solid ideas.</p>
<p>While based on my experience, the vast majority of users still rely on their operating system&rsquo;s package manager to install PG extensions.
On-the-fly compilation and downloading shared libraries might not be a viable option for production env. Since many DB setups don’t have internet access or a proper toolchain ready.</p>
<p>In the meantime, Existing OS package managers like <code>yum</code>/<code>dnf</code>/<code>apt</code> already solve issues like dependency resolution, upgrades, and version management well.
There&rsquo;s no need to reinvent the wheel or disrupt existing standards. So the real question is: Who&rsquo;s going to package these extensions into ready-to-use software?</p>
<p>PGDG has already made a fantastic effort with official <a href="https://download.postgresql.org/pub/repos/yum/">YUM</a> and <a href="http://apt.postgresql.org/pub/repos/apt/">APT</a> repositories.
In addition to the <strong>70</strong> built-in <a href="https://ext.pigsty.io/#/contrib">Contrib</a> extensions bundled with PostgreSQL,the PGDG YUM repo offers <strong>128</strong> RPM extensions, while the APT repo offers <strong>104</strong> DEB extensions.
These extensions are compiled and packaged in the same environment as the PostgreSQL kernel, making them easy to install alongside the PostgreSQL binary packages.
In fact, even most PostgreSQL Docker images rely on the PGDG repo to install extensions.</p>
<p>I’m deeply grateful for Devrim&rsquo;s maintenance of the PGDG YUM repo and Christoph&rsquo;s work with the APT repo. Their efforts to make PostgreSQL installation and extension management seamless are incredibly valuable.
But as a distribution creator myself, I’ve encountered some challenges with PostgreSQL extension distribution.</p>
<hr>
<h2 id="whats-the-challenge">What&rsquo;s the challenge?</h2>
<p>The first major issue facing extension users is <strong>Alignment</strong>.</p>
<p>In the two primary Linux distro camps — Debian and EL — there’s a significant number of PostgreSQL extensions.
Excluding the <strong>70</strong> built-in Contrib extensions bundled with PostgreSQL, the YUM repo offers <strong>128</strong> extensions, and the APT repo provides <strong>104</strong>.</p>
<p>However, when we dig deeper, we see that alignment between the two repos is not ideal.
The combined total of extensions across both repos is <strong>153</strong>, but the overlap is just <strong>79</strong>. That means <strong>only half</strong> of the extensions are available in both ecosystems!</p>
<p><a href="pgdg-ext.png"><img src="pgdg-ext.png" style="max-width: 1000px; max-height: 1000px; width: 100%; height: auto;"></a></p>
<blockquote>
<p>Only half of the extensions are available in both EL and Debian ecosystems!</p>
</blockquote>
<p>Next, we run into further alignment issues within each ecosystem itself. The availability of extensions can vary between different major OS versions.
For instance, <code>pljava</code>, <code>sequential_uuids</code>, and <code>firebird_fdw</code> are only available in EL9, but not in EL8. Similarly, <code>rdkit</code> is available in Ubuntu 22+ / Debian 12+, but not in Ubuntu 20 / Debian 11.
There’s also the issue of architecture support. For example, <code>citus</code> does not provide <code>arm64</code> packages in the Debian repo.</p>
<p>And then we have alignment issues across different PostgreSQL major versions. Some extensions won’t compile on older PostgreSQL versions, while others won’t work on newer ones.
Some extensions are only available for specific PostgreSQL versions in certain distributions, and so on.</p>
<p>These alignment issues lead to a significant number of permutations. For example, if we consider five mainstream OS distributions (el8, el9, debian12, ubuntu22, ubuntu24),
two CPU architectures (<code>x86_64</code> and <code>arm64</code>), and six PostgreSQL major versions (12–17), that’s <strong>60-70</strong> RPM/DEB packages per extension—just for one extension!</p>
<p>On top of alignment, there’s the problem of <strong>completeness</strong>. PGXN lists over <strong>375</strong> extensions, but the PostgreSQL ecosystem could have as many as <a href="https://gist.github.com/joelonsql/e5aa27f8cc9bd22b8999b7de8aee9d47"><strong>1,000+</strong></a>. The PGDG repos, however, contain only about <strong>one-tenth</strong> of them.</p>
<p>There are also several powerful new Rust-based extensions that PGDG doesn’t include, such as <code>pg_graphql</code>, <code>pg_jsonschema</code>, and <code>wrappers</code> for <a href="/">self-hosting Supabase</a>;
<code>pg_search</code> as an Elasticsearch alternative; and <code>pg_analytics</code>, <code>pg_parquet</code>, <code>pg_mooncake</code> for OLAP processing. The reason? They are too slow to compile&hellip;</p>
<hr>
<h2 id="whats-the-solution">What&rsquo;s the solution?</h2>
<p>Over the past six months, I’ve focused on consolidating the PostgreSQL extension ecosystem.
Recently, I reached a milestone I’m quite happy with. I’ve created a PG YUM/APT repository with a catalog of <strong>340</strong>available PostgreSQL extensions.</p>
<p>Here are some key stats for the repo: It hosts <strong>340</strong> extensions in total. Excluding the <strong>70</strong> built-in extensions that come with PostgreSQL, this leaves <strong>270</strong> third-party extensions.
Of these, about half are maintained by the official PGDG repos (<strong>126</strong> RPM, <strong>102</strong> DEB). The other half (<strong>131</strong> RPM, <strong>143</strong>DEB) are maintained, fixed, compiled, packaged, and distributed by myself.</p>
<table>
<thead>
<tr>
<th style="text-align:center">OS \ Entry</th>
<th style="text-align:center">All</th>
<th style="text-align:center">PGDG</th>
<th style="text-align:center">PIGSTY</th>
<th style="text-align:center">CONTRIB</th>
<th style="text-align:center">MISC</th>
<th style="text-align:center">MISS</th>
<th style="text-align:center">PG17</th>
<th style="text-align:center">PG16</th>
<th style="text-align:center">PG15</th>
<th style="text-align:center">PG14</th>
<th style="text-align:center">PG13</th>
<th style="text-align:center">PG12</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center"><a href="https://ext.pigsty.io/#/rpm"><strong>RPM</strong></a></td>
<td style="text-align:center">334</td>
<td style="text-align:center">115</td>
<td style="text-align:center">143</td>
<td style="text-align:center">70</td>
<td style="text-align:center">4</td>
<td style="text-align:center">6</td>
<td style="text-align:center">301</td>
<td style="text-align:center">330</td>
<td style="text-align:center">333</td>
<td style="text-align:center">319</td>
<td style="text-align:center">307</td>
<td style="text-align:center">294</td>
</tr>
<tr>
<td style="text-align:center"><a href="https://ext.pigsty.io/#/deb"><strong>DEB</strong></a></td>
<td style="text-align:center">326</td>
<td style="text-align:center">104</td>
<td style="text-align:center">144</td>
<td style="text-align:center">70</td>
<td style="text-align:center">4</td>
<td style="text-align:center">14</td>
<td style="text-align:center">302</td>
<td style="text-align:center">322</td>
<td style="text-align:center">325</td>
<td style="text-align:center">316</td>
<td style="text-align:center">303</td>
<td style="text-align:center">293</td>
</tr>
</tbody>
</table>
<p>For each extension, I’ve built versions for the <strong>6</strong> major PostgreSQL versions (12–17) across five popular Linux distributions: EL8, EL9, Ubuntu 22.04, Ubuntu 24.04, and Debian 12.
I’ve also provided some limited support for older OS versions like EL7, Debian 11, and Ubuntu 20.04.</p>
<p>This repository also addresses most of the <strong>alignment</strong> issue. Initially, there were extensions in the APT and YUM repos that were unique to each, but I’ve worked to port as many of these unique extensions to the other ecosystem.
Now, only <strong>7</strong> APT extensions are missing from the YUM repo, and <strong>16</strong> extensions are missing in APT—just <strong>6%</strong> of the total. Many missing PGDG extensions have also been resolved.</p>
<p><a href="pigsty-ext.png"><img src="pigsty-ext.png" style="max-width: 1000px; max-height: 1000px; width: 100%; height: auto;"></a></p>
<p>I’ve created a comprehensive directory listing all supported extensions, with detailed info, dependency installation instructions, and other important notes.</p>
<p><a href="citus.png"><img src="citus.png" style="max-width: 800px; max-height: 1000px; width: 100%; height: auto;"></a></p>
<p>I hope this repository can serve as the ultimate solution to the frustration users face when extensions are difficult to find, compile, or install.</p>
<hr>
<h2 id="how-to-use-this-repo">How to use this repo?</h2>
<p>Now, for a quick plug — what’s the easiest way to install and use these extensions?</p>
<p>The simplest option is to use the OSS PostgreSQL distribution: <a href="https://ext.pigsty.io/"><strong>Pigsty</strong></a>.
The repo is autoconfigured by default, so all you need to do is declare them in the <a href="/docs/setup/config/">config inventory</a>.</p>
<p>For example,  the <a href="/docs/db/supabase">self-hosting supabase</a> template requires extensions that aren’t available in the PGDG repo.
You can simply  <a href="/docs/pgext/usage/download/">download</a>, <a href="/docs/pgext/usage/install/">install</a>, <a href="/docs/pgext/usage/load/">preload</a>, <a href="/docs/pgext/usage/config">config</a> and <a href="/docs/pgext/usage/create/">create</a> extensions by referring to their names.</p>
<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span><span style="color:#204a87;font-weight:bold">all</span><span style="color:#000;font-weight:bold">:</span><span style="color:#f8f8f8;text-decoration:underline">
</span></span></span><span style="display:flex;"><span><span style="color:#f8f8f8;text-decoration:underline">  </span><span style="color:#204a87;font-weight:bold">children</span><span style="color:#000;font-weight:bold">:</span><span style="color:#f8f8f8;text-decoration:underline">
</span></span></span><span style="display:flex;"><span><span style="color:#f8f8f8;text-decoration:underline">    </span><span style="color:#204a87;font-weight:bold">pg-meta</span><span style="color:#000;font-weight:bold">:</span><span style="color:#f8f8f8;text-decoration:underline">
</span></span></span><span style="display:flex;"><span><span style="color:#f8f8f8;text-decoration:underline">      </span><span style="color:#204a87;font-weight:bold">hosts</span><span style="color:#000;font-weight:bold">:</span><span style="color:#f8f8f8;text-decoration:underline"> </span>{<span style="color:#f8f8f8;text-decoration:underline"> </span><span style="color:#204a87;font-weight:bold">10.10.10.10</span><span style="color:#000;font-weight:bold">:</span><span style="color:#f8f8f8;text-decoration:underline"> </span>{<span style="color:#f8f8f8;text-decoration:underline"> </span><span style="color:#204a87;font-weight:bold">pg_seq: 1, pg_role</span><span style="color:#000;font-weight:bold">:</span><span style="color:#f8f8f8;text-decoration:underline"> </span><span style="color:#000">primary } }</span><span style="color:#f8f8f8;text-decoration:underline">
</span></span></span><span style="display:flex;"><span><span style="color:#f8f8f8;text-decoration:underline">      </span><span style="color:#204a87;font-weight:bold">vars</span><span style="color:#000;font-weight:bold">:</span><span style="color:#f8f8f8;text-decoration:underline">
</span></span></span><span style="display:flex;"><span><span style="color:#f8f8f8;text-decoration:underline">        </span><span style="color:#204a87;font-weight:bold">pg_cluster</span><span style="color:#000;font-weight:bold">:</span><span style="color:#f8f8f8;text-decoration:underline"> </span><span style="color:#000">pg-meta</span><span style="color:#f8f8f8;text-decoration:underline">
</span></span></span><span style="display:flex;"><span><span style="color:#f8f8f8;text-decoration:underline">
</span></span></span><span style="display:flex;"><span><span style="color:#f8f8f8;text-decoration:underline">        </span><span style="color:#8f5902;font-style:italic"># INSTALL EXTENSIONS</span><span style="color:#f8f8f8;text-decoration:underline">
</span></span></span><span style="display:flex;"><span><span style="color:#f8f8f8;text-decoration:underline">        </span><span style="color:#204a87;font-weight:bold">pg_extensions</span><span style="color:#000;font-weight:bold">:</span><span style="color:#f8f8f8;text-decoration:underline">
</span></span></span><span style="display:flex;"><span><span style="color:#f8f8f8;text-decoration:underline">          </span>- <span style="color:#000">supabase  </span><span style="color:#f8f8f8;text-decoration:underline"> </span><span style="color:#8f5902;font-style:italic"># essential extensions for supabase</span><span style="color:#f8f8f8;text-decoration:underline">
</span></span></span><span style="display:flex;"><span><span style="color:#f8f8f8;text-decoration:underline">          </span>- <span style="color:#000">timescaledb postgis pg_graphql pg_jsonschema wrappers pg_search pg_analytics pg_parquet plv8 duckdb_fdw pg_cron pg_timetable pgqr</span><span style="color:#f8f8f8;text-decoration:underline">
</span></span></span><span style="display:flex;"><span><span style="color:#f8f8f8;text-decoration:underline">          </span>- <span style="color:#000">supautils pg_plan_filter passwordcheck plpgsql_check pgaudit pgsodium pg_vault pgjwt pg_ecdsa pg_session_jwt index_advisor</span><span style="color:#f8f8f8;text-decoration:underline">
</span></span></span><span style="display:flex;"><span><span style="color:#f8f8f8;text-decoration:underline">          </span>- <span style="color:#000">pgvector pgvectorscale pg_summarize pg_tiktoken pg_tle pg_stat_monitor hypopg pg_hint_plan pg_http pg_net pg_smtp_client pg_idkit</span><span style="color:#f8f8f8;text-decoration:underline">
</span></span></span><span style="display:flex;"><span><span style="color:#f8f8f8;text-decoration:underline">
</span></span></span><span style="display:flex;"><span><span style="color:#f8f8f8;text-decoration:underline">        </span><span style="color:#8f5902;font-style:italic"># LOAD EXTENSIONS</span><span style="color:#f8f8f8;text-decoration:underline">
</span></span></span><span style="display:flex;"><span><span style="color:#f8f8f8;text-decoration:underline">        </span><span style="color:#204a87;font-weight:bold">pg_libs</span><span style="color:#000;font-weight:bold">:</span><span style="color:#f8f8f8;text-decoration:underline"> </span><span style="color:#4e9a06">&#39;pg_stat_statements, plpgsql, plpgsql_check, pg_cron, pg_net, timescaledb, auto_explain, pg_tle, plan_filter&#39;</span><span style="color:#f8f8f8;text-decoration:underline">
</span></span></span><span style="display:flex;"><span><span style="color:#f8f8f8;text-decoration:underline">
</span></span></span><span style="display:flex;"><span><span style="color:#f8f8f8;text-decoration:underline">        </span><span style="color:#8f5902;font-style:italic"># CONFIG EXTENSIONS</span><span style="color:#f8f8f8;text-decoration:underline">
</span></span></span><span style="display:flex;"><span><span style="color:#f8f8f8;text-decoration:underline">        </span><span style="color:#204a87;font-weight:bold">pg_parameters</span><span style="color:#000;font-weight:bold">:</span><span style="color:#f8f8f8;text-decoration:underline">
</span></span></span><span style="display:flex;"><span><span style="color:#f8f8f8;text-decoration:underline">          </span><span style="color:#204a87;font-weight:bold">cron.database_name</span><span style="color:#000;font-weight:bold">:</span><span style="color:#f8f8f8;text-decoration:underline"> </span><span style="color:#000">postgres</span><span style="color:#f8f8f8;text-decoration:underline">
</span></span></span><span style="display:flex;"><span><span style="color:#f8f8f8;text-decoration:underline">          </span><span style="color:#204a87;font-weight:bold">pgsodium.enable_event_trigger</span><span style="color:#000;font-weight:bold">:</span><span style="color:#f8f8f8;text-decoration:underline"> </span><span style="color:#204a87;font-weight:bold">off</span><span style="color:#f8f8f8;text-decoration:underline">
</span></span></span><span style="display:flex;"><span><span style="color:#f8f8f8;text-decoration:underline">
</span></span></span><span style="display:flex;"><span><span style="color:#f8f8f8;text-decoration:underline">        </span><span style="color:#8f5902;font-style:italic"># CREATE EXTENSIONS</span><span style="color:#f8f8f8;text-decoration:underline">
</span></span></span><span style="display:flex;"><span><span style="color:#f8f8f8;text-decoration:underline">        </span><span style="color:#204a87;font-weight:bold">pg_databases</span><span style="color:#000;font-weight:bold">:</span><span style="color:#f8f8f8;text-decoration:underline">
</span></span></span><span style="display:flex;"><span><span style="color:#f8f8f8;text-decoration:underline">          </span>- <span style="color:#204a87;font-weight:bold">name</span><span style="color:#000;font-weight:bold">:</span><span style="color:#f8f8f8;text-decoration:underline"> </span><span style="color:#000">postgres</span><span style="color:#f8f8f8;text-decoration:underline">
</span></span></span><span style="display:flex;"><span><span style="color:#f8f8f8;text-decoration:underline">            </span><span style="color:#204a87;font-weight:bold">baseline</span><span style="color:#000;font-weight:bold">:</span><span style="color:#f8f8f8;text-decoration:underline"> </span><span style="color:#000">supabase.sql</span><span style="color:#f8f8f8;text-decoration:underline">
</span></span></span><span style="display:flex;"><span><span style="color:#f8f8f8;text-decoration:underline">            </span><span style="color:#204a87;font-weight:bold">schemas</span><span style="color:#000;font-weight:bold">:</span><span style="color:#f8f8f8;text-decoration:underline"> </span><span style="color:#000;font-weight:bold">[</span><span style="color:#f8f8f8;text-decoration:underline"> </span><span style="color:#000">extensions ,auth ,realtime ,storage ,graphql_public ,supabase_functions ,_analytics ,_realtime ]</span><span style="color:#f8f8f8;text-decoration:underline">
</span></span></span><span style="display:flex;"><span><span style="color:#f8f8f8;text-decoration:underline">            </span><span style="color:#204a87;font-weight:bold">extensions</span><span style="color:#000;font-weight:bold">:</span><span style="color:#f8f8f8;text-decoration:underline">
</span></span></span><span style="display:flex;"><span><span style="color:#f8f8f8;text-decoration:underline">              </span>- {<span style="color:#f8f8f8;text-decoration:underline"> </span><span style="color:#204a87;font-weight:bold">name: pgcrypto  ,schema</span><span style="color:#000;font-weight:bold">:</span><span style="color:#f8f8f8;text-decoration:underline"> </span><span style="color:#000">extensions  }</span><span style="color:#f8f8f8;text-decoration:underline">
</span></span></span><span style="display:flex;"><span><span style="color:#f8f8f8;text-decoration:underline">              </span>- {<span style="color:#f8f8f8;text-decoration:underline"> </span><span style="color:#204a87;font-weight:bold">name: pg_net    ,schema</span><span style="color:#000;font-weight:bold">:</span><span style="color:#f8f8f8;text-decoration:underline"> </span><span style="color:#000">extensions  }</span><span style="color:#f8f8f8;text-decoration:underline">
</span></span></span><span style="display:flex;"><span><span style="color:#f8f8f8;text-decoration:underline">              </span>- {<span style="color:#f8f8f8;text-decoration:underline"> </span><span style="color:#204a87;font-weight:bold">name: pgjwt     ,schema</span><span style="color:#000;font-weight:bold">:</span><span style="color:#f8f8f8;text-decoration:underline"> </span><span style="color:#000">extensions  }</span><span style="color:#f8f8f8;text-decoration:underline">
</span></span></span><span style="display:flex;"><span><span style="color:#f8f8f8;text-decoration:underline">              </span>- {<span style="color:#f8f8f8;text-decoration:underline"> </span><span style="color:#204a87;font-weight:bold">name: uuid-ossp ,schema</span><span style="color:#000;font-weight:bold">:</span><span style="color:#f8f8f8;text-decoration:underline"> </span><span style="color:#000">extensions  }</span><span style="color:#f8f8f8;text-decoration:underline">
</span></span></span><span style="display:flex;"><span><span style="color:#f8f8f8;text-decoration:underline">              </span>- {<span style="color:#f8f8f8;text-decoration:underline"> </span><span style="color:#204a87;font-weight:bold">name</span><span style="color:#000;font-weight:bold">:</span><span style="color:#f8f8f8;text-decoration:underline"> </span><span style="color:#000">pgsodium        }               </span><span style="color:#f8f8f8;text-decoration:underline">
</span></span></span><span style="display:flex;"><span><span style="color:#f8f8f8;text-decoration:underline">              </span>- {<span style="color:#f8f8f8;text-decoration:underline"> </span><span style="color:#204a87;font-weight:bold">name</span><span style="color:#000;font-weight:bold">:</span><span style="color:#f8f8f8;text-decoration:underline"> </span><span style="color:#000">supabase_vault  }               </span><span style="color:#f8f8f8;text-decoration:underline">
</span></span></span><span style="display:flex;"><span><span style="color:#f8f8f8;text-decoration:underline">              </span>- {<span style="color:#f8f8f8;text-decoration:underline"> </span><span style="color:#204a87;font-weight:bold">name</span><span style="color:#000;font-weight:bold">:</span><span style="color:#f8f8f8;text-decoration:underline"> </span><span style="color:#000">pg_graphql      }               </span><span style="color:#f8f8f8;text-decoration:underline">
</span></span></span><span style="display:flex;"><span><span style="color:#f8f8f8;text-decoration:underline">              </span>- {<span style="color:#f8f8f8;text-decoration:underline"> </span><span style="color:#204a87;font-weight:bold">name</span><span style="color:#000;font-weight:bold">:</span><span style="color:#f8f8f8;text-decoration:underline"> </span><span style="color:#000">pg_jsonschema   }               </span><span style="color:#f8f8f8;text-decoration:underline">
</span></span></span><span style="display:flex;"><span><span style="color:#f8f8f8;text-decoration:underline">              </span>- {<span style="color:#f8f8f8;text-decoration:underline"> </span><span style="color:#204a87;font-weight:bold">name</span><span style="color:#000;font-weight:bold">:</span><span style="color:#f8f8f8;text-decoration:underline"> </span><span style="color:#000">wrappers        }               </span><span style="color:#f8f8f8;text-decoration:underline">
</span></span></span><span style="display:flex;"><span><span style="color:#f8f8f8;text-decoration:underline">              </span>- {<span style="color:#f8f8f8;text-decoration:underline"> </span><span style="color:#204a87;font-weight:bold">name</span><span style="color:#000;font-weight:bold">:</span><span style="color:#f8f8f8;text-decoration:underline"> </span><span style="color:#000">http            }               </span><span style="color:#f8f8f8;text-decoration:underline">
</span></span></span><span style="display:flex;"><span><span style="color:#f8f8f8;text-decoration:underline">              </span>- {<span style="color:#f8f8f8;text-decoration:underline"> </span><span style="color:#204a87;font-weight:bold">name</span><span style="color:#000;font-weight:bold">:</span><span style="color:#f8f8f8;text-decoration:underline"> </span><span style="color:#000">pg_cron         }               </span><span style="color:#f8f8f8;text-decoration:underline">
</span></span></span><span style="display:flex;"><span><span style="color:#f8f8f8;text-decoration:underline">              </span>- {<span style="color:#f8f8f8;text-decoration:underline"> </span><span style="color:#204a87;font-weight:bold">name</span><span style="color:#000;font-weight:bold">:</span><span style="color:#f8f8f8;text-decoration:underline"> </span><span style="color:#000">timescaledb     }               </span><span style="color:#f8f8f8;text-decoration:underline">
</span></span></span><span style="display:flex;"><span><span style="color:#f8f8f8;text-decoration:underline">              </span>- {<span style="color:#f8f8f8;text-decoration:underline"> </span><span style="color:#204a87;font-weight:bold">name</span><span style="color:#000;font-weight:bold">:</span><span style="color:#f8f8f8;text-decoration:underline"> </span><span style="color:#000">pg_tle          }               </span><span style="color:#f8f8f8;text-decoration:underline">
</span></span></span><span style="display:flex;"><span><span style="color:#f8f8f8;text-decoration:underline">              </span>- {<span style="color:#f8f8f8;text-decoration:underline"> </span><span style="color:#204a87;font-weight:bold">name</span><span style="color:#000;font-weight:bold">:</span><span style="color:#f8f8f8;text-decoration:underline"> </span><span style="color:#000">vector          }               </span><span style="color:#f8f8f8;text-decoration:underline">
</span></span></span><span style="display:flex;"><span><span style="color:#f8f8f8;text-decoration:underline">  </span><span style="color:#204a87;font-weight:bold">vars</span><span style="color:#000;font-weight:bold">:</span><span style="color:#f8f8f8;text-decoration:underline">
</span></span></span><span style="display:flex;"><span><span style="color:#f8f8f8;text-decoration:underline">    </span><span style="color:#204a87;font-weight:bold">pg_version</span><span style="color:#000;font-weight:bold">:</span><span style="color:#f8f8f8;text-decoration:underline"> </span><span style="color:#0000cf;font-weight:bold">17</span><span style="color:#f8f8f8;text-decoration:underline">
</span></span></span><span style="display:flex;"><span><span style="color:#f8f8f8;text-decoration:underline">
</span></span></span><span style="display:flex;"><span><span style="color:#f8f8f8;text-decoration:underline">    </span><span style="color:#8f5902;font-style:italic"># DOWNLOAD EXTENSIONS</span><span style="color:#f8f8f8;text-decoration:underline">
</span></span></span><span style="display:flex;"><span><span style="color:#f8f8f8;text-decoration:underline">    </span><span style="color:#204a87;font-weight:bold">repo_extra_packages</span><span style="color:#000;font-weight:bold">:</span><span style="color:#f8f8f8;text-decoration:underline">
</span></span></span><span style="display:flex;"><span><span style="color:#f8f8f8;text-decoration:underline">      </span>- <span style="color:#000">pgsql-main</span><span style="color:#f8f8f8;text-decoration:underline">
</span></span></span><span style="display:flex;"><span><span style="color:#f8f8f8;text-decoration:underline">      </span>- <span style="color:#000">supabase  </span><span style="color:#f8f8f8;text-decoration:underline"> </span><span style="color:#8f5902;font-style:italic"># essential extensions for supabase</span><span style="color:#f8f8f8;text-decoration:underline">
</span></span></span><span style="display:flex;"><span><span style="color:#f8f8f8;text-decoration:underline">      </span>- <span style="color:#000">timescaledb postgis pg_graphql pg_jsonschema wrappers pg_search pg_analytics pg_parquet plv8 duckdb_fdw pg_cron pg_timetable pgqr</span><span style="color:#f8f8f8;text-decoration:underline">
</span></span></span><span style="display:flex;"><span><span style="color:#f8f8f8;text-decoration:underline">      </span>- <span style="color:#000">supautils pg_plan_filter passwordcheck plpgsql_check pgaudit pgsodium pg_vault pgjwt pg_ecdsa pg_session_jwt index_advisor</span><span style="color:#f8f8f8;text-decoration:underline">
</span></span></span><span style="display:flex;"><span><span style="color:#f8f8f8;text-decoration:underline">      </span>- <span style="color:#000">pgvector pgvectorscale pg_summarize pg_tiktoken pg_tle pg_stat_monitor hypopg pg_hint_plan pg_http pg_net pg_smtp_client pg_idkit</span><span style="color:#f8f8f8;text-decoration:underline">
</span></span></span></code></pre></div><p>To simply add extensions to existing clusters:</p>
<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>./infra.yml -t repo_build -e <span style="color:#4e9a06">&#39;{&#34;repo_packages&#34;:[citus]}&#39;</span>         <span style="color:#8f5902;font-style:italic"># download</span>
</span></span><span style="display:flex;"><span>./pgsql.yml -t pg_extension -e <span style="color:#4e9a06">&#39;{&#34;pg_extensions&#34;: [&#34;citus&#34;]}&#39;</span>    <span style="color:#8f5902;font-style:italic"># install</span>
</span></span></code></pre></div><p>Through this repo was meant to be used with Pigsty, But it is <strong>not mandatory</strong>. You can still enable this repository on any EL/Debian/Ubuntu system with a simple one-liner in the shell:</p>
<h3 id="apt-repo">APT Repo</h3>
<p><a href="https://pigsty.io/docs/node"><img alt="Linux" src="https://img.shields.io/badge/Linux-x86_64-%23FCC624?style=flat&logo=linux&labelColor=FCC624&logoColor=black"></a>
<a href="https://pigsty.io/docs/pgext/list/deb/"><img alt="Ubuntu Support: 24" src="https://img.shields.io/badge/Ubuntu-24/noble-%23E95420?style=flat&logo=ubuntu&logoColor=%23E95420"></a>
<a href="https://pigsty.io/docs/pgext/list/deb/"><img alt="Ubuntu Support: 22" src="https://img.shields.io/badge/Ubuntu-22/jammy-%23E95420?style=flat&logo=ubuntu&logoColor=%23E95420"></a>
<a href="https://pigsty.io/docs/reference/compatibility/"><img alt="Debian Support: 12" src="https://img.shields.io/badge/Debian-12/bookworm-%23A81D33?style=flat&logo=debian&logoColor=%23A81D33"></a></p>
<p>For Ubuntu 22.04 &amp; Debian 12 or any compatible platforms, use the following commands to add the APT repo:</p>
<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>curl -fsSL https://repo.pigsty.io/key <span style="color:#000;font-weight:bold">|</span> sudo gpg --dearmor -o /etc/apt/keyrings/pigsty.gpg
</span></span><span style="display:flex;"><span>sudo tee /etc/apt/sources.list.d/pigsty-io.list &gt; /dev/null <span style="color:#4e9a06">&lt;&lt;EOF
</span></span></span><span style="display:flex;"><span><span style="color:#4e9a06">deb [signed-by=/etc/apt/keyrings/pigsty.gpg] https://repo.pigsty.io/apt/infra generic main 
</span></span></span><span style="display:flex;"><span><span style="color:#4e9a06">deb [signed-by=/etc/apt/keyrings/pigsty.gpg] https://repo.pigsty.io/apt/pgsql/$(lsb_release -cs) $(lsb_release -cs) main
</span></span></span><span style="display:flex;"><span><span style="color:#4e9a06">EOF</span>
</span></span><span style="display:flex;"><span>sudo apt update
</span></span></code></pre></div><h3 id="yum-repo">YUM Repo</h3>
<p><a href="https://pigsty.io/docs/node"><img alt="Linux" src="https://img.shields.io/badge/Linux-x86_64-%23FCC624?style=flat&logo=linux&labelColor=FCC624&logoColor=black"></a>
<a href="https://pigsty.io/docs/pgext/list/rpm/"><img alt="RHEL Support: 8/9" src="https://img.shields.io/badge/EL-7/8/9-red?style=flat&logo=redhat&logoColor=red"></a>
<a href="https://pigsty.io/docs/pgext/list/rpm/"><img alt="RHEL" src="https://img.shields.io/badge/RHEL-slategray?style=flat&logo=redhat&logoColor=red"></a>
<a href="https://almalinux.org/"><img alt="CentOS" src="https://img.shields.io/badge/CentOS-slategray?style=flat&logo=centos&logoColor=%23262577"></a>
<a href="https://almalinux.org/"><img alt="RockyLinux" src="https://img.shields.io/badge/RockyLinux-slategray?style=flat&logo=rockylinux&logoColor=%2310B981"></a>
<a href="https://almalinux.org/"><img alt="AlmaLinux" src="https://img.shields.io/badge/AlmaLinux-slategray?style=flat&logo=almalinux&logoColor=black"></a>
<a href="https://almalinux.org/"><img alt="OracleLinux" src="https://img.shields.io/badge/OracleLinux-slategray?style=flat&logo=oracle&logoColor=%23F80000"></a></p>
<p>For EL 8/9 and compatible platforms, use the following commands to add the YUM repo:</p>
<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>curl -fsSL https://repo.pigsty.io/key      <span style="color:#000;font-weight:bold">|</span> sudo tee /etc/pki/rpm-gpg/RPM-GPG-KEY-pigsty &gt;/dev/null  <span style="color:#8f5902;font-style:italic"># add gpg key</span>
</span></span><span style="display:flex;"><span>curl -fsSL https://repo.pigsty.io/yum/repo <span style="color:#000;font-weight:bold">|</span> sudo tee /etc/yum.repos.d/pigsty.repo        &gt;/dev/null  <span style="color:#8f5902;font-style:italic"># add repo file</span>
</span></span><span style="display:flex;"><span>sudo yum makecache
</span></span></code></pre></div><hr>
<h2 id="whats-in-this-repo">What&rsquo;s in this repo?</h2>
<p>In this repo, all the extensions are categorized into one of the <strong>15</strong> categories: TIME, GIS, RAG, FTS, OLAP, FEAT, LANG, TYPE, FUNC, ADMIN, STAT, SEC, FDW, SIM, ETL, as shown below.</p>
<p><a href="https://ext.pigsty.io/#/time"><strong>TIME</strong></a>: <a href="https://ext.pigsty.io/#/timescaledb"><code>timescaledb</code></a> <a href="https://ext.pigsty.io/#/timescaledb_toolkit"><code>timescaledb_toolkit</code></a> <a href="https://ext.pigsty.io/#/timeseries"><code>timeseries</code></a> <a href="https://ext.pigsty.io/#/periods"><code>periods</code></a> <a href="https://ext.pigsty.io/#/temporal_tables"><code>temporal_tables</code></a> <a href="https://ext.pigsty.io/#/emaj"><code>emaj</code></a> <a href="https://ext.pigsty.io/#/table_version"><code>table_version</code></a> <a href="https://ext.pigsty.io/#/pg_cron"><code>pg_cron</code></a> <a href="https://ext.pigsty.io/#/pg_later"><code>pg_later</code></a> <a href="https://ext.pigsty.io/#/pg_background"><code>pg_background</code></a>
<a href="https://ext.pigsty.io/#/gis"><strong>GIS</strong></a>: <a href="https://ext.pigsty.io/#/postgis"><code>postgis</code></a> <a href="https://ext.pigsty.io/#/postgis_topology"><code>postgis_topology</code></a> <a href="https://ext.pigsty.io/#/postgis_raster"><code>postgis_raster</code></a> <a href="https://ext.pigsty.io/#/postgis_sfcgal"><code>postgis_sfcgal</code></a> <a href="https://ext.pigsty.io/#/postgis_tiger_geocoder"><code>postgis_tiger_geocoder</code></a> <a href="https://ext.pigsty.io/#/address_standardizer"><code>address_standardizer</code></a> <a href="https://ext.pigsty.io/#/address_standardizer_data_us"><code>address_standardizer_data_us</code></a> <a href="https://ext.pigsty.io/#/pgrouting"><code>pgrouting</code></a> <a href="https://ext.pigsty.io/#/pointcloud"><code>pointcloud</code></a> <a href="https://ext.pigsty.io/#/pointcloud_postgis"><code>pointcloud_postgis</code></a> <a href="https://ext.pigsty.io/#/h3"><code>h3</code></a> <a href="https://ext.pigsty.io/#/h3_postgis"><code>h3_postgis</code></a> <a href="https://ext.pigsty.io/#/q3c"><code>q3c</code></a> <a href="https://ext.pigsty.io/#/ogr_fdw"><code>ogr_fdw</code></a> <a href="https://ext.pigsty.io/#/geoip"><code>geoip</code></a> <a href="https://ext.pigsty.io/#/pg_polyline"><code>pg_polyline</code></a> <a href="https://ext.pigsty.io/#/pg_geohash"><code>pg_geohash</code></a> <a href="https://ext.pigsty.io/#/mobilitydb"><code>mobilitydb</code></a> <a href="https://ext.pigsty.io/#/earthdistance"><code>earthdistance</code></a>
<a href="https://ext.pigsty.io/#/rag"><strong>RAG</strong></a>: <a href="https://ext.pigsty.io/#/vector"><code>vector</code></a> <a href="https://ext.pigsty.io/#/vectorscale"><code>vectorscale</code></a> <a href="https://ext.pigsty.io/#/vectorize"><code>vectorize</code></a> <a href="https://ext.pigsty.io/#/pg_similarity"><code>pg_similarity</code></a> <a href="https://ext.pigsty.io/#/smlar"><code>smlar</code></a> <a href="https://ext.pigsty.io/#/pg_summarize"><code>pg_summarize</code></a> <a href="https://ext.pigsty.io/#/pg_tiktoken"><code>pg_tiktoken</code></a> <a href="https://ext.pigsty.io/#/pgml"><code>pgml</code></a> <a href="https://ext.pigsty.io/#/pg4ml"><code>pg4ml</code></a>
<a href="https://ext.pigsty.io/#/fts"><strong>FTS</strong></a>: <a href="https://ext.pigsty.io/#/pg_search"><code>pg_search</code></a> <a href="https://ext.pigsty.io/#/pg_bigm"><code>pg_bigm</code></a> <a href="https://ext.pigsty.io/#/zhparser"><code>zhparser</code></a> <a href="https://ext.pigsty.io/#/hunspell_cs_cz"><code>hunspell_cs_cz</code></a> <a href="https://ext.pigsty.io/#/hunspell_de_de"><code>hunspell_de_de</code></a> <a href="https://ext.pigsty.io/#/hunspell_en_us"><code>hunspell_en_us</code></a> <a href="https://ext.pigsty.io/#/hunspell_fr"><code>hunspell_fr</code></a> <a href="https://ext.pigsty.io/#/hunspell_ne_np"><code>hunspell_ne_np</code></a> <a href="https://ext.pigsty.io/#/hunspell_nl_nl"><code>hunspell_nl_nl</code></a> <a href="https://ext.pigsty.io/#/hunspell_nn_no"><code>hunspell_nn_no</code></a> <a href="https://ext.pigsty.io/#/hunspell_pt_pt"><code>hunspell_pt_pt</code></a> <a href="https://ext.pigsty.io/#/hunspell_ru_ru"><code>hunspell_ru_ru</code></a> <a href="https://ext.pigsty.io/#/hunspell_ru_ru_aot"><code>hunspell_ru_ru_aot</code></a> <a href="https://ext.pigsty.io/#/fuzzystrmatch"><code>fuzzystrmatch</code></a> <a href="https://ext.pigsty.io/#/pg_trgm"><code>pg_trgm</code></a>
<a href="https://ext.pigsty.io/#/olap"><strong>OLAP</strong></a>: <a href="https://ext.pigsty.io/#/citus"><code>citus</code></a> <a href="https://ext.pigsty.io/#/citus_columnar"><code>citus_columnar</code></a> <a href="https://ext.pigsty.io/#/columnar"><code>columnar</code></a> <a href="https://ext.pigsty.io/#/pg_analytics"><code>pg_analytics</code></a> <a href="https://ext.pigsty.io/#/pg_duckdb"><code>pg_duckdb</code></a> <a href="https://ext.pigsty.io/#/pg_mooncake"><code>pg_mooncake</code></a> <a href="https://ext.pigsty.io/#/duckdb_fdw"><code>duckdb_fdw</code></a> <a href="https://ext.pigsty.io/#/pg_parquet"><code>pg_parquet</code></a> <a href="https://ext.pigsty.io/#/pg_fkpart"><code>pg_fkpart</code></a> <a href="https://ext.pigsty.io/#/pg_partman"><code>pg_partman</code></a> <a href="https://ext.pigsty.io/#/plproxy"><code>plproxy</code></a> <a href="https://ext.pigsty.io/#/pg_strom"><code>pg_strom</code></a> <a href="https://ext.pigsty.io/#/tablefunc"><code>tablefunc</code></a>
<a href="https://ext.pigsty.io/#/feat"><strong>FEAT</strong></a>: <a href="https://ext.pigsty.io/#/age"><code>age</code></a> <a href="https://ext.pigsty.io/#/hll"><code>hll</code></a> <a href="https://ext.pigsty.io/#/rum"><code>rum</code></a> <a href="https://ext.pigsty.io/#/pg_graphql"><code>pg_graphql</code></a> <a href="https://ext.pigsty.io/#/pg_jsonschema"><code>pg_jsonschema</code></a> <a href="https://ext.pigsty.io/#/jsquery"><code>jsquery</code></a> <a href="https://ext.pigsty.io/#/pg_hint_plan"><code>pg_hint_plan</code></a> <a href="https://ext.pigsty.io/#/hypopg"><code>hypopg</code></a> <a href="https://ext.pigsty.io/#/index_advisor"><code>index_advisor</code></a> <a href="https://ext.pigsty.io/#/plan_filter"><code>plan_filter</code></a> <a href="https://ext.pigsty.io/#/imgsmlr"><code>imgsmlr</code></a> <a href="https://ext.pigsty.io/#/pg_ivm"><code>pg_ivm</code></a> <a href="https://ext.pigsty.io/#/pgmq"><code>pgmq</code></a> <a href="https://ext.pigsty.io/#/pgq"><code>pgq</code></a> <a href="https://ext.pigsty.io/#/pg_cardano"><code>pg_cardano</code></a> <a href="https://ext.pigsty.io/#/rdkit"><code>rdkit</code></a> <a href="https://ext.pigsty.io/#/bloom"><code>bloom</code></a>
<a href="https://ext.pigsty.io/#/lang"><strong>LANG</strong></a>: <a href="https://ext.pigsty.io/#/pg_tle"><code>pg_tle</code></a> <a href="https://ext.pigsty.io/#/plv8"><code>plv8</code></a> <a href="https://ext.pigsty.io/#/pllua"><code>pllua</code></a> <a href="https://ext.pigsty.io/#/hstore_pllua"><code>hstore_pllua</code></a> <a href="https://ext.pigsty.io/#/plluau"><code>plluau</code></a> <a href="https://ext.pigsty.io/#/hstore_plluau"><code>hstore_plluau</code></a> <a href="https://ext.pigsty.io/#/plprql"><code>plprql</code></a> <a href="https://ext.pigsty.io/#/pldbgapi"><code>pldbgapi</code></a> <a href="https://ext.pigsty.io/#/plpgsql_check"><code>plpgsql_check</code></a> <a href="https://ext.pigsty.io/#/plprofiler"><code>plprofiler</code></a> <a href="https://ext.pigsty.io/#/plsh"><code>plsh</code></a> <a href="https://ext.pigsty.io/#/pljava"><code>pljava</code></a> <a href="https://ext.pigsty.io/#/plr"><code>plr</code></a> <a href="https://ext.pigsty.io/#/pgtap"><code>pgtap</code></a> <a href="https://ext.pigsty.io/#/faker"><code>faker</code></a> <a href="https://ext.pigsty.io/#/dbt2"><code>dbt2</code></a> <a href="https://ext.pigsty.io/#/pltcl"><code>pltcl</code></a> <a href="https://ext.pigsty.io/#/pltclu"><code>pltclu</code></a> <a href="https://ext.pigsty.io/#/plperl"><code>plperl</code></a> <a href="https://ext.pigsty.io/#/bool_plperl"><code>bool_plperl</code></a> <a href="https://ext.pigsty.io/#/hstore_plperl"><code>hstore_plperl</code></a> <a href="https://ext.pigsty.io/#/jsonb_plperl"><code>jsonb_plperl</code></a> <a href="https://ext.pigsty.io/#/plperlu"><code>plperlu</code></a> <a href="https://ext.pigsty.io/#/bool_plperlu"><code>bool_plperlu</code></a> <a href="https://ext.pigsty.io/#/jsonb_plperlu"><code>jsonb_plperlu</code></a> <a href="https://ext.pigsty.io/#/hstore_plperlu"><code>hstore_plperlu</code></a> <a href="https://ext.pigsty.io/#/plpgsql"><code>plpgsql</code></a> <a href="https://ext.pigsty.io/#/plpython3u"><code>plpython3u</code></a> <a href="https://ext.pigsty.io/#/jsonb_plpython3u"><code>jsonb_plpython3u</code></a> <a href="https://ext.pigsty.io/#/ltree_plpython3u"><code>ltree_plpython3u</code></a> <a href="https://ext.pigsty.io/#/hstore_plpython3u"><code>hstore_plpython3u</code></a>
<a href="https://ext.pigsty.io/#/type"><strong>TYPE</strong></a>: <a href="https://ext.pigsty.io/#/prefix"><code>prefix</code></a> <a href="https://ext.pigsty.io/#/semver"><code>semver</code></a> <a href="https://ext.pigsty.io/#/unit"><code>unit</code></a> <a href="https://ext.pigsty.io/#/md5hash"><code>md5hash</code></a> <a href="https://ext.pigsty.io/#/asn1oid"><code>asn1oid</code></a> <a href="https://ext.pigsty.io/#/roaringbitmap"><code>roaringbitmap</code></a> <a href="https://ext.pigsty.io/#/pgfaceting"><code>pgfaceting</code></a> <a href="https://ext.pigsty.io/#/pg_sphere"><code>pg_sphere</code></a> <a href="https://ext.pigsty.io/#/country"><code>country</code></a> <a href="https://ext.pigsty.io/#/currency"><code>currency</code></a> <a href="https://ext.pigsty.io/#/pgmp"><code>pgmp</code></a> <a href="https://ext.pigsty.io/#/numeral"><code>numeral</code></a> <a href="https://ext.pigsty.io/#/pg_rational"><code>pg_rational</code></a> <a href="https://ext.pigsty.io/#/uint"><code>uint</code></a> <a href="https://ext.pigsty.io/#/uint128"><code>uint128</code></a> <a href="https://ext.pigsty.io/#/ip4r"><code>ip4r</code></a> <a href="https://ext.pigsty.io/#/uri"><code>uri</code></a> <a href="https://ext.pigsty.io/#/pgemailaddr"><code>pgemailaddr</code></a> <a href="https://ext.pigsty.io/#/acl"><code>acl</code></a> <a href="https://ext.pigsty.io/#/debversion"><code>debversion</code></a> <a href="https://ext.pigsty.io/#/pg_rrule"><code>pg_rrule</code></a> <a href="https://ext.pigsty.io/#/timestamp9"><code>timestamp9</code></a> <a href="https://ext.pigsty.io/#/chkpass"><code>chkpass</code></a> <a href="https://ext.pigsty.io/#/isn"><code>isn</code></a> <a href="https://ext.pigsty.io/#/seg"><code>seg</code></a> <a href="https://ext.pigsty.io/#/cube"><code>cube</code></a> <a href="https://ext.pigsty.io/#/ltree"><code>ltree</code></a> <a href="https://ext.pigsty.io/#/hstore"><code>hstore</code></a> <a href="https://ext.pigsty.io/#/citext"><code>citext</code></a> <a href="https://ext.pigsty.io/#/xml2"><code>xml2</code></a>
<a href="https://ext.pigsty.io/#/func"><strong>FUNC</strong></a>: <a href="https://ext.pigsty.io/#/topn"><code>topn</code></a> <a href="https://ext.pigsty.io/#/gzip"><code>gzip</code></a> <a href="https://ext.pigsty.io/#/zstd"><code>zstd</code></a> <a href="https://ext.pigsty.io/#/http"><code>http</code></a> <a href="https://ext.pigsty.io/#/pg_net"><code>pg_net</code></a> <a href="https://ext.pigsty.io/#/pg_smtp_client"><code>pg_smtp_client</code></a> <a href="https://ext.pigsty.io/#/pg_html5_email_address"><code>pg_html5_email_address</code></a> <a href="https://ext.pigsty.io/#/pgsql_tweaks"><code>pgsql_tweaks</code></a> <a href="https://ext.pigsty.io/#/pg_extra_time"><code>pg_extra_time</code></a> <a href="https://ext.pigsty.io/#/timeit"><code>timeit</code></a> <a href="https://ext.pigsty.io/#/count_distinct"><code>count_distinct</code></a> <a href="https://ext.pigsty.io/#/extra_window_functions"><code>extra_window_functions</code></a> <a href="https://ext.pigsty.io/#/first_last_agg"><code>first_last_agg</code></a> <a href="https://ext.pigsty.io/#/tdigest"><code>tdigest</code></a> <a href="https://ext.pigsty.io/#/aggs_for_vecs"><code>aggs_for_vecs</code></a> <a href="https://ext.pigsty.io/#/aggs_for_arrays"><code>aggs_for_arrays</code></a> <a href="https://ext.pigsty.io/#/arraymath"><code>arraymath</code></a> <a href="https://ext.pigsty.io/#/quantile"><code>quantile</code></a> <a href="https://ext.pigsty.io/#/lower_quantile"><code>lower_quantile</code></a> <a href="https://ext.pigsty.io/#/pg_idkit"><code>pg_idkit</code></a> <a href="https://ext.pigsty.io/#/pg_uuidv7"><code>pg_uuidv7</code></a> <a href="https://ext.pigsty.io/#/permuteseq"><code>permuteseq</code></a> <a href="https://ext.pigsty.io/#/pg_hashids"><code>pg_hashids</code></a> <a href="https://ext.pigsty.io/#/sequential_uuids"><code>sequential_uuids</code></a> <a href="https://ext.pigsty.io/#/pg_math"><code>pg_math</code></a> <a href="https://ext.pigsty.io/#/random"><code>random</code></a> <a href="https://ext.pigsty.io/#/base36"><code>base36</code></a> <a href="https://ext.pigsty.io/#/base62"><code>base62</code></a> <a href="https://ext.pigsty.io/#/pg_base58"><code>pg_base58</code></a> <a href="https://ext.pigsty.io/#/floatvec"><code>floatvec</code></a> <a href="https://ext.pigsty.io/#/financial"><code>financial</code></a> <a href="https://ext.pigsty.io/#/pgjwt"><code>pgjwt</code></a> <a href="https://ext.pigsty.io/#/pg_hashlib"><code>pg_hashlib</code></a> <a href="https://ext.pigsty.io/#/shacrypt"><code>shacrypt</code></a> <a href="https://ext.pigsty.io/#/cryptint"><code>cryptint</code></a> <a href="https://ext.pigsty.io/#/pguecc"><code>pguecc</code></a> <a href="https://ext.pigsty.io/#/pgpcre"><code>pgpcre</code></a> <a href="https://ext.pigsty.io/#/icu_ext"><code>icu_ext</code></a> <a href="https://ext.pigsty.io/#/pgqr"><code>pgqr</code></a> <a href="https://ext.pigsty.io/#/envvar"><code>envvar</code></a> <a href="https://ext.pigsty.io/#/pg_protobuf"><code>pg_protobuf</code></a> <a href="https://ext.pigsty.io/#/url_encode"><code>url_encode</code></a> <a href="https://ext.pigsty.io/#/refint"><code>refint</code></a> <a href="https://ext.pigsty.io/#/autoinc"><code>autoinc</code></a> <a href="https://ext.pigsty.io/#/insert_username"><code>insert_username</code></a> <a href="https://ext.pigsty.io/#/moddatetime"><code>moddatetime</code></a> <a href="https://ext.pigsty.io/#/tsm_system_time"><code>tsm_system_time</code></a> <a href="https://ext.pigsty.io/#/dict_xsyn"><code>dict_xsyn</code></a> <a href="https://ext.pigsty.io/#/tsm_system_rows"><code>tsm_system_rows</code></a> <a href="https://ext.pigsty.io/#/tcn"><code>tcn</code></a> <a href="https://ext.pigsty.io/#/uuid-ossp"><code>uuid-ossp</code></a> <a href="https://ext.pigsty.io/#/btree_gist"><code>btree_gist</code></a> <a href="https://ext.pigsty.io/#/btree_gin"><code>btree_gin</code></a> <a href="https://ext.pigsty.io/#/intarray"><code>intarray</code></a> <a href="https://ext.pigsty.io/#/intagg"><code>intagg</code></a> <a href="https://ext.pigsty.io/#/dict_int"><code>dict_int</code></a> <a href="https://ext.pigsty.io/#/unaccent"><code>unaccent</code></a>
<a href="https://ext.pigsty.io/#/admin"><strong>ADMIN</strong></a>: <a href="https://ext.pigsty.io/#/pg_repack"><code>pg_repack</code></a> <a href="https://ext.pigsty.io/#/pg_squeeze"><code>pg_squeeze</code></a> <a href="https://ext.pigsty.io/#/pg_dirtyread"><code>pg_dirtyread</code></a> <a href="https://ext.pigsty.io/#/pgfincore"><code>pgfincore</code></a> <a href="https://ext.pigsty.io/#/pgdd"><code>pgdd</code></a> <a href="https://ext.pigsty.io/#/ddlx"><code>ddlx</code></a> <a href="https://ext.pigsty.io/#/prioritize"><code>prioritize</code></a> <a href="https://ext.pigsty.io/#/pg_checksums"><code>pg_checksums</code></a> <a href="https://ext.pigsty.io/#/pg_readonly"><code>pg_readonly</code></a> <a href="https://ext.pigsty.io/#/safeupdate"><code>safeupdate</code></a> <a href="https://ext.pigsty.io/#/pg_permissions"><code>pg_permissions</code></a> <a href="https://ext.pigsty.io/#/pgautofailover"><code>pgautofailover</code></a> <a href="https://ext.pigsty.io/#/pg_catcheck"><code>pg_catcheck</code></a> <a href="https://ext.pigsty.io/#/pre_prepare"><code>pre_prepare</code></a> <a href="https://ext.pigsty.io/#/pgcozy"><code>pgcozy</code></a> <a href="https://ext.pigsty.io/#/pg_orphaned"><code>pg_orphaned</code></a> <a href="https://ext.pigsty.io/#/pg_crash"><code>pg_crash</code></a> <a href="https://ext.pigsty.io/#/pg_cheat_funcs"><code>pg_cheat_funcs</code></a> <a href="https://ext.pigsty.io/#/pg_savior"><code>pg_savior</code></a> <a href="https://ext.pigsty.io/#/table_log"><code>table_log</code></a> <a href="https://ext.pigsty.io/#/pg_fio"><code>pg_fio</code></a> <a href="https://ext.pigsty.io/#/pgpool_adm"><code>pgpool_adm</code></a> <a href="https://ext.pigsty.io/#/pgpool_recovery"><code>pgpool_recovery</code></a> <a href="https://ext.pigsty.io/#/pgpool_regclass"><code>pgpool_regclass</code></a> <a href="https://ext.pigsty.io/#/pgagent"><code>pgagent</code></a> <a href="https://ext.pigsty.io/#/vacuumlo"><code>vacuumlo</code></a> <a href="https://ext.pigsty.io/#/pg_prewarm"><code>pg_prewarm</code></a> <a href="https://ext.pigsty.io/#/oid2name"><code>oid2name</code></a> <a href="https://ext.pigsty.io/#/lo"><code>lo</code></a> <a href="https://ext.pigsty.io/#/basic_archive"><code>basic_archive</code></a> <a href="https://ext.pigsty.io/#/basebackup_to_shell"><code>basebackup_to_shell</code></a> <a href="https://ext.pigsty.io/#/old_snapshot"><code>old_snapshot</code></a> <a href="https://ext.pigsty.io/#/adminpack"><code>adminpack</code></a> <a href="https://ext.pigsty.io/#/amcheck"><code>amcheck</code></a> <a href="https://ext.pigsty.io/#/pg_surgery"><code>pg_surgery</code></a>
<a href="https://ext.pigsty.io/#/stat"><strong>STAT</strong></a>: <a href="https://ext.pigsty.io/#/pg_profile"><code>pg_profile</code></a> <a href="https://ext.pigsty.io/#/pg_show_plans"><code>pg_show_plans</code></a> <a href="https://ext.pigsty.io/#/pg_stat_kcache"><code>pg_stat_kcache</code></a> <a href="https://ext.pigsty.io/#/pg_stat_monitor"><code>pg_stat_monitor</code></a> <a href="https://ext.pigsty.io/#/pg_qualstats"><code>pg_qualstats</code></a> <a href="https://ext.pigsty.io/#/pg_store_plans"><code>pg_store_plans</code></a> <a href="https://ext.pigsty.io/#/pg_track_settings"><code>pg_track_settings</code></a> <a href="https://ext.pigsty.io/#/pg_wait_sampling"><code>pg_wait_sampling</code></a> <a href="https://ext.pigsty.io/#/system_stats"><code>system_stats</code></a> <a href="https://ext.pigsty.io/#/meta"><code>meta</code></a> <a href="https://ext.pigsty.io/#/pgnodemx"><code>pgnodemx</code></a> <a href="https://ext.pigsty.io/#/pg_proctab"><code>pg_proctab</code></a> <a href="https://ext.pigsty.io/#/pg_sqlog"><code>pg_sqlog</code></a> <a href="https://ext.pigsty.io/#/bgw_replstatus"><code>bgw_replstatus</code></a> <a href="https://ext.pigsty.io/#/pgmeminfo"><code>pgmeminfo</code></a> <a href="https://ext.pigsty.io/#/toastinfo"><code>toastinfo</code></a> <a href="https://ext.pigsty.io/#/explain_ui"><code>explain_ui</code></a> <a href="https://ext.pigsty.io/#/pg_relusage"><code>pg_relusage</code></a> <a href="https://ext.pigsty.io/#/pg_top"><code>pg_top</code></a> <a href="https://ext.pigsty.io/#/pagevis"><code>pagevis</code></a> <a href="https://ext.pigsty.io/#/powa"><code>powa</code></a> <a href="https://ext.pigsty.io/#/pageinspect"><code>pageinspect</code></a> <a href="https://ext.pigsty.io/#/pgrowlocks"><code>pgrowlocks</code></a> <a href="https://ext.pigsty.io/#/sslinfo"><code>sslinfo</code></a> <a href="https://ext.pigsty.io/#/pg_buffercache"><code>pg_buffercache</code></a> <a href="https://ext.pigsty.io/#/pg_walinspect"><code>pg_walinspect</code></a> <a href="https://ext.pigsty.io/#/pg_freespacemap"><code>pg_freespacemap</code></a> <a href="https://ext.pigsty.io/#/pg_visibility"><code>pg_visibility</code></a> <a href="https://ext.pigsty.io/#/pgstattuple"><code>pgstattuple</code></a> <a href="https://ext.pigsty.io/#/auto_explain"><code>auto_explain</code></a> <a href="https://ext.pigsty.io/#/pg_stat_statements"><code>pg_stat_statements</code></a>
<a href="https://ext.pigsty.io/#/sec"><strong>SEC</strong></a>: <a href="https://ext.pigsty.io/#/passwordcheck_cracklib"><code>passwordcheck_cracklib</code></a> <a href="https://ext.pigsty.io/#/supautils"><code>supautils</code></a> <a href="https://ext.pigsty.io/#/pgsodium"><code>pgsodium</code></a> <a href="https://ext.pigsty.io/#/supabase_vault"><code>supabase_vault</code></a> <a href="https://ext.pigsty.io/#/pg_session_jwt"><code>pg_session_jwt</code></a> <a href="https://ext.pigsty.io/#/anon"><code>anon</code></a> <a href="https://ext.pigsty.io/#/pg_tde"><code>pg_tde</code></a> <a href="https://ext.pigsty.io/#/pgsmcrypto"><code>pgsmcrypto</code></a> <a href="https://ext.pigsty.io/#/pgaudit"><code>pgaudit</code></a> <a href="https://ext.pigsty.io/#/pgauditlogtofile"><code>pgauditlogtofile</code></a> <a href="https://ext.pigsty.io/#/pg_auth_mon"><code>pg_auth_mon</code></a> <a href="https://ext.pigsty.io/#/credcheck"><code>credcheck</code></a> <a href="https://ext.pigsty.io/#/pgcryptokey"><code>pgcryptokey</code></a> <a href="https://ext.pigsty.io/#/pg_jobmon"><code>pg_jobmon</code></a> <a href="https://ext.pigsty.io/#/logerrors"><code>logerrors</code></a> <a href="https://ext.pigsty.io/#/login_hook"><code>login_hook</code></a> <a href="https://ext.pigsty.io/#/set_user"><code>set_user</code></a> <a href="https://ext.pigsty.io/#/pg_snakeoil"><code>pg_snakeoil</code></a> <a href="https://ext.pigsty.io/#/pgextwlist"><code>pgextwlist</code></a> <a href="https://ext.pigsty.io/#/pg_auditor"><code>pg_auditor</code></a> <a href="https://ext.pigsty.io/#/sslutils"><code>sslutils</code></a> <a href="https://ext.pigsty.io/#/noset"><code>noset</code></a> <a href="https://ext.pigsty.io/#/sepgsql"><code>sepgsql</code></a> <a href="https://ext.pigsty.io/#/auth_delay"><code>auth_delay</code></a> <a href="https://ext.pigsty.io/#/pgcrypto"><code>pgcrypto</code></a> <a href="https://ext.pigsty.io/#/passwordcheck"><code>passwordcheck</code></a>
<a href="https://ext.pigsty.io/#/fdw"><strong>FDW</strong></a>: <a href="https://ext.pigsty.io/#/wrappers"><code>wrappers</code></a> <a href="https://ext.pigsty.io/#/multicorn"><code>multicorn</code></a> <a href="https://ext.pigsty.io/#/odbc_fdw"><code>odbc_fdw</code></a> <a href="https://ext.pigsty.io/#/jdbc_fdw"><code>jdbc_fdw</code></a> <a href="https://ext.pigsty.io/#/mysql_fdw"><code>mysql_fdw</code></a> <a href="https://ext.pigsty.io/#/oracle_fdw"><code>oracle_fdw</code></a> <a href="https://ext.pigsty.io/#/tds_fdw"><code>tds_fdw</code></a> <a href="https://ext.pigsty.io/#/db2_fdw"><code>db2_fdw</code></a> <a href="https://ext.pigsty.io/#/sqlite_fdw"><code>sqlite_fdw</code></a> <a href="https://ext.pigsty.io/#/pgbouncer_fdw"><code>pgbouncer_fdw</code></a> <a href="https://ext.pigsty.io/#/mongo_fdw"><code>mongo_fdw</code></a> <a href="https://ext.pigsty.io/#/redis_fdw"><code>redis_fdw</code></a> <a href="https://ext.pigsty.io/#/redis"><code>redis</code></a> <a href="https://ext.pigsty.io/#/kafka_fdw"><code>kafka_fdw</code></a> <a href="https://ext.pigsty.io/#/hdfs_fdw"><code>hdfs_fdw</code></a> <a href="https://ext.pigsty.io/#/firebird_fdw"><code>firebird_fdw</code></a> <a href="https://ext.pigsty.io/#/aws_s3"><code>aws_s3</code></a> <a href="https://ext.pigsty.io/#/log_fdw"><code>log_fdw</code></a> <a href="https://ext.pigsty.io/#/dblink"><code>dblink</code></a> <a href="https://ext.pigsty.io/#/file_fdw"><code>file_fdw</code></a> <a href="https://ext.pigsty.io/#/postgres_fdw"><code>postgres_fdw</code></a>
<a href="https://ext.pigsty.io/#/sim"><strong>SIM</strong></a>: <a href="https://ext.pigsty.io/#/orafce"><code>orafce</code></a> <a href="https://ext.pigsty.io/#/pgtt"><code>pgtt</code></a> <a href="https://ext.pigsty.io/#/session_variable"><code>session_variable</code></a> <a href="https://ext.pigsty.io/#/pg_statement_rollback"><code>pg_statement_rollback</code></a> <a href="https://ext.pigsty.io/#/pg_dbms_metadata"><code>pg_dbms_metadata</code></a> <a href="https://ext.pigsty.io/#/pg_dbms_lock"><code>pg_dbms_lock</code></a> <a href="https://ext.pigsty.io/#/pg_dbms_job"><code>pg_dbms_job</code></a> <a href="https://ext.pigsty.io/#/babelfishpg_common"><code>babelfishpg_common</code></a> <a href="https://ext.pigsty.io/#/babelfishpg_tsql"><code>babelfishpg_tsql</code></a> <a href="https://ext.pigsty.io/#/babelfishpg_tds"><code>babelfishpg_tds</code></a> <a href="https://ext.pigsty.io/#/babelfishpg_money"><code>babelfishpg_money</code></a> <a href="https://ext.pigsty.io/#/pgmemcache"><code>pgmemcache</code></a>
<a href="https://ext.pigsty.io/#/etl"><strong>ETL</strong></a>: <a href="https://ext.pigsty.io/#/pglogical"><code>pglogical</code></a> <a href="https://ext.pigsty.io/#/pglogical_origin"><code>pglogical_origin</code></a> <a href="https://ext.pigsty.io/#/pglogical_ticker"><code>pglogical_ticker</code></a> <a href="https://ext.pigsty.io/#/pgl_ddl_deploy"><code>pgl_ddl_deploy</code></a> <a href="https://ext.pigsty.io/#/pg_failover_slots"><code>pg_failover_slots</code></a> <a href="https://ext.pigsty.io/#/wal2json"><code>wal2json</code></a> <a href="https://ext.pigsty.io/#/wal2mongo"><code>wal2mongo</code></a> <a href="https://ext.pigsty.io/#/decoderbufs"><code>decoderbufs</code></a> <a href="https://ext.pigsty.io/#/decoder_raw"><code>decoder_raw</code></a> <a href="https://ext.pigsty.io/#/test_decoding"><code>test_decoding</code></a> <a href="https://ext.pigsty.io/#/mimeo"><code>mimeo</code></a> <a href="https://ext.pigsty.io/#/repmgr"><code>repmgr</code></a> <a href="https://ext.pigsty.io/#/pg_fact_loader"><code>pg_fact_loader</code></a> <a href="https://ext.pigsty.io/#/pg_bulkload"><code>pg_bulkload</code></a></p>
<p>Check <a href="https://ext.pigsty.io">ext.pigsty.io</a> for all the details.</p>
<hr>
<h2 id="some-thoughts">Some Thoughts</h2>
<p>Each major PostgreSQL version introduces changes, making the maintenance of <strong>140+</strong> extension packages a bit of a beast.</p>
<p>Especially when some extension authors haven’t updated their work in years. In these cases, you often have no choice but to take matters into your own hands.
I’ve personally fixed several extensions and ensured they support the latest PostgreSQL major versions. For those authors I could reach, I’ve submitted numerous PRs and issues to keep things moving forward.</p>
<p><a href="https://github.com/Vonng"><img src="github-contrib.png" style="max-width: 800px; width: 100%; height: auto;"></a></p>
<p>Back to the point: <strong>my goal with this repo is to establish a standard for PostgreSQL extension installation and distribution, solving the distribution challenges that have long troubles the users</strong>.</p>
<p>A recent milestone is that, the popular open-source PostgreSQL HA cluster project <a href="https://autobase.tech/docs/extensions/list"><strong>postgresql_cluster</strong></a>, has made this extension repository the default upstream for PG extension installation.</p>
<p>Currently, this repository (repo.pigsty.io) is hosted on Cloudflare. In the past month, the repo and its mirrors have served about <strong>300GB</strong> of downloads.
Given that most extensions are just a few KB to a few MB, that amounts to nearly <strong>a million downloads per month</strong>.
Since Cloudflare doesn’t charge for traffic, I can confidently commit to keeping this repository completely free &amp; under active maintenance for the foreseeable future, as long as cloudflare doesn&rsquo;t charge me too much.</p>
<p>I believe my work can help PostgreSQL users worldwide and contribute to the thriving PostgreSQL ecosystem. I hope it proves useful to you as well. <strong>Enjoy PostgreSQL!</strong></p>

</div>





    
	
  
    
    
	
    


  

<div class="td-content" style="page-break-before: always">
    <h1 id="pg-635f4dbe52424af419b468e194e22c72">Self-Hosting Dify with PG, PGVector, and Pigsty</h1>
	
	<div class="td-byline mb-4">
		By <b><a href="https://vonng.com/en/">Ruohang Feng</a> (<a href="https://vonng.com/en/">@Vonng</a>) | <a href="https://mp.weixin.qq.com">Wechat Column</a></b> |
        
		<time datetime="2024-06-22" class="text-muted">2024-06-22</time>
        
	</div>
	<p><a href="https://dify.ai/"><strong>Dify</strong></a> &ndash; The Innovation Engine for GenAI Applications</p>
<p>Dify is an open-source LLM app development platform. Orchestrate LLM apps from agents to complex AI workflows, with an RAG engine.
Which claims to be more production-ready than LangChain.</p>
<p>Of course, a workflow orchestration software like this needs a database underneath — Dify uses <strong>PostgreSQL</strong> for meta data storage, as well as Redis for caching and a dedicated vector database.
You can pull the Docker images and play locally, but for production deployment, this setup won&rsquo;t suffice — there&rsquo;s no HA, backup, PITR, monitoring, and many other things.</p>
<p>Fortunately, Pigsty provides a battery-include production-grade highly available PostgreSQL cluster, along with the Redis and S3 (MinIO) capabilities that Dify needs, as well as Nginx to expose the Web service, making it the perfect companion for Dify.</p>
<p><a href="https://github.com/langgenius/dify/blob/main/docker/docker-compose.yaml"><img alt="docker-compose.png" src="/zh/blog/pg/dify-setup/docker-compose.png"></a></p>
<blockquote>
<p>Off-load the stateful part to Pigsty, you only need to pull up the stateless blue circle part with a simple <code>docker compose up</code>.</p>
</blockquote>
<p>BTW, I have to criticize the design of the Dify template. Since the metadata is already stored in PostgreSQL, why not add <code>pgvector</code> to use it as a vector database? What&rsquo;s even more baffling is that <code>pgvector</code> is a separate image and container. Why not just use a PG image with <code>pgvector</code> included?</p>
<p>Dify &ldquo;supports&rdquo; a bunch of flashy vector databases, but since PostgreSQL is already chosen, using <code>pgvector</code> as the default vector database is the natural choice. Similarly, I think the Dify team should consider removing Redis. Celery task queues can use PostgreSQL as backend storage, so having multiple databases is unnecessary. Entities should not be multiplied without necessity.</p>
<p>Therefore, the Pigsty-provided <a href="https://github.com/Vonng/pigsty/tree/master/app/dify">Dify Docker Compose template</a> has made some adjustments to the official example. It removes the <code>db</code> and <code>redis</code> database images, using instances managed by Pigsty. The vector database is fixed to use <code>pgvector</code>, reusing the same PostgreSQL instance.</p>
<p>In the end, the architecture is simplified to three stateless containers: <code>dify-api</code>, <code>dify-web</code>, and <code>dify-worker</code>, which can be created and destroyed at will. There are also two optional containers, <code>ssrf_proxy</code> and <code>nginx</code>, for providing proxy and some security features.</p>
<p>There’s a bit of state management left with <a href="https://github.com/Vonng/pigsty/blob/main/app/dify/docker-compose.yml#L128">file system volumes</a>, storing things like private keys. Regular backups are sufficient.</p>
<p>Reference:</p>
<ul>
<li><a href="https://github.com/langgenius/dify/">GitHub: langgenius/Dify</a></li>
<li><a href="https://github.com/Vonng/pigsty/tree/master/app/dify">Pigsty: Dify Docker Compose Template</a></li>
</ul>
<hr>
<h2 id="pigsty-preparation">Pigsty Preparation</h2>
<p>Let&rsquo;s take the <a href="/docs/concept/arch/#singleton-meta">single-node installation</a> of Pigsty as an example. Suppose you have a machine with the IP address <code>10.10.10.10</code> and already pigsty <a href="/docs/setup/install/">installed</a>.</p>
<p>We need to define the database clusters required in the Pigsty configuration file <code>pigsty.yml</code>.</p>
<p>Here, we define a cluster named <code>pg-meta</code>, which includes a superuser named <code>dbuser_dify</code> (the implementation is a bit rough as the Migration script executes <code>CREATE EXTENSION</code> which require dbsu privilege for now),</p>
<p>And there&rsquo;s a database named <code>dify</code> with the <code>pgvector</code> extension installed, and a specific firewall rule allowing users to access the database from anywhere using a password (you can also restrict it to a more precise range, such as the Docker subnet <code>172.0.0.0/8</code>).</p>
<p>Additionally, a standard single-instance Redis cluster <code>redis-dify</code> with the password <code>redis.dify</code> is defined.</p>
<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span><span style="color:#204a87;font-weight:bold">pg-meta</span><span style="color:#000;font-weight:bold">:</span><span style="color:#f8f8f8;text-decoration:underline">
</span></span></span><span style="display:flex;"><span><span style="color:#f8f8f8;text-decoration:underline">  </span><span style="color:#204a87;font-weight:bold">hosts</span><span style="color:#000;font-weight:bold">:</span><span style="color:#f8f8f8;text-decoration:underline"> </span>{<span style="color:#f8f8f8;text-decoration:underline"> </span><span style="color:#204a87;font-weight:bold">10.10.10.10</span><span style="color:#000;font-weight:bold">:</span><span style="color:#f8f8f8;text-decoration:underline"> </span>{<span style="color:#f8f8f8;text-decoration:underline"> </span><span style="color:#204a87;font-weight:bold">pg_seq: 1, pg_role</span><span style="color:#000;font-weight:bold">:</span><span style="color:#f8f8f8;text-decoration:underline"> </span><span style="color:#000">primary } }</span><span style="color:#f8f8f8;text-decoration:underline">
</span></span></span><span style="display:flex;"><span><span style="color:#f8f8f8;text-decoration:underline">  </span><span style="color:#204a87;font-weight:bold">vars</span><span style="color:#000;font-weight:bold">:</span><span style="color:#f8f8f8;text-decoration:underline">
</span></span></span><span style="display:flex;"><span><span style="color:#f8f8f8;text-decoration:underline">    </span><span style="color:#204a87;font-weight:bold">pg_cluster</span><span style="color:#000;font-weight:bold">:</span><span style="color:#f8f8f8;text-decoration:underline"> </span><span style="color:#000">pg-meta</span><span style="color:#f8f8f8;text-decoration:underline">
</span></span></span><span style="display:flex;"><span><span style="color:#f8f8f8;text-decoration:underline">    </span><span style="color:#204a87;font-weight:bold">pg_users</span><span style="color:#000;font-weight:bold">:</span><span style="color:#f8f8f8;text-decoration:underline"> </span><span style="color:#000;font-weight:bold">[</span><span style="color:#f8f8f8;text-decoration:underline"> </span>{<span style="color:#f8f8f8;text-decoration:underline"> </span><span style="color:#204a87;font-weight:bold">name: dbuser_dify ,password: DBUser.Dify  ,superuser: true ,pgbouncer: true ,roles</span><span style="color:#000;font-weight:bold">:</span><span style="color:#f8f8f8;text-decoration:underline"> </span><span style="color:#000;font-weight:bold">[</span><span style="color:#f8f8f8;text-decoration:underline"> </span><span style="color:#000">dbrole_admin ] } ]</span><span style="color:#f8f8f8;text-decoration:underline">
</span></span></span><span style="display:flex;"><span><span style="color:#f8f8f8;text-decoration:underline">    </span><span style="color:#204a87;font-weight:bold">pg_databases</span><span style="color:#000;font-weight:bold">:</span><span style="color:#f8f8f8;text-decoration:underline"> </span><span style="color:#000;font-weight:bold">[</span><span style="color:#f8f8f8;text-decoration:underline"> </span>{<span style="color:#f8f8f8;text-decoration:underline"> </span><span style="color:#204a87;font-weight:bold">name: dify, owner: dbuser_dify, extensions</span><span style="color:#000;font-weight:bold">:</span><span style="color:#f8f8f8;text-decoration:underline"> </span><span style="color:#000;font-weight:bold">[</span><span style="color:#f8f8f8;text-decoration:underline"> </span>{<span style="color:#f8f8f8;text-decoration:underline"> </span><span style="color:#204a87;font-weight:bold">name</span><span style="color:#000;font-weight:bold">:</span><span style="color:#f8f8f8;text-decoration:underline"> </span><span style="color:#000">pgvector } ] } ]</span><span style="color:#f8f8f8;text-decoration:underline">
</span></span></span><span style="display:flex;"><span><span style="color:#f8f8f8;text-decoration:underline">    </span><span style="color:#204a87;font-weight:bold">pg_hba_rules</span><span style="color:#000;font-weight:bold">:</span><span style="color:#f8f8f8;text-decoration:underline"> </span><span style="color:#000;font-weight:bold">[</span><span style="color:#f8f8f8;text-decoration:underline"> </span>{<span style="color:#f8f8f8;text-decoration:underline"> </span><span style="color:#204a87;font-weight:bold">user: dbuser_dify , db: all ,addr: world ,auth: pwd ,title</span><span style="color:#000;font-weight:bold">:</span><span style="color:#f8f8f8;text-decoration:underline"> </span><span style="color:#4e9a06">&#39;allow dify user world pwd access&#39;</span><span style="color:#f8f8f8;text-decoration:underline"> </span>}<span style="color:#f8f8f8;text-decoration:underline"> </span><span style="color:#000;font-weight:bold">]</span><span style="color:#f8f8f8;text-decoration:underline">
</span></span></span><span style="display:flex;"><span><span style="color:#f8f8f8;text-decoration:underline">
</span></span></span><span style="display:flex;"><span><span style="color:#f8f8f8;text-decoration:underline"></span><span style="color:#204a87;font-weight:bold">redis-dify</span><span style="color:#000;font-weight:bold">:</span><span style="color:#f8f8f8;text-decoration:underline">
</span></span></span><span style="display:flex;"><span><span style="color:#f8f8f8;text-decoration:underline">  </span><span style="color:#204a87;font-weight:bold">hosts</span><span style="color:#000;font-weight:bold">:</span><span style="color:#f8f8f8;text-decoration:underline"> </span>{<span style="color:#f8f8f8;text-decoration:underline"> </span><span style="color:#204a87;font-weight:bold">10.10.10.10</span><span style="color:#000;font-weight:bold">:</span><span style="color:#f8f8f8;text-decoration:underline"> </span>{<span style="color:#f8f8f8;text-decoration:underline"> </span><span style="color:#204a87;font-weight:bold">redis_node: 1 , redis_instances</span><span style="color:#000;font-weight:bold">:</span><span style="color:#f8f8f8;text-decoration:underline"> </span>{<span style="color:#f8f8f8;text-decoration:underline"> </span><span style="color:#204a87;font-weight:bold">6379</span><span style="color:#000;font-weight:bold">:</span><span style="color:#f8f8f8;text-decoration:underline"> </span>{<span style="color:#f8f8f8;text-decoration:underline"> </span>}<span style="color:#f8f8f8;text-decoration:underline"> </span>}<span style="color:#f8f8f8;text-decoration:underline"> </span>}<span style="color:#f8f8f8;text-decoration:underline"> </span>}<span style="color:#f8f8f8;text-decoration:underline">
</span></span></span><span style="display:flex;"><span><span style="color:#f8f8f8;text-decoration:underline">  </span><span style="color:#204a87;font-weight:bold">vars</span><span style="color:#000;font-weight:bold">:</span><span style="color:#f8f8f8;text-decoration:underline"> </span>{<span style="color:#f8f8f8;text-decoration:underline"> </span><span style="color:#204a87;font-weight:bold">redis_cluster: redis-dify ,redis_password: &#39;redis.dify&#39; ,redis_max_memory</span><span style="color:#000;font-weight:bold">:</span><span style="color:#f8f8f8;text-decoration:underline"> </span><span style="color:#000">64MB }</span><span style="color:#f8f8f8;text-decoration:underline">
</span></span></span></code></pre></div><p>For demonstration purposes, we use single-instance configurations. You can refer to the Pigsty documentation to deploy <a href="/docs/concept/ha/">high availability</a> PG and Redis clusters. After defining the clusters, use the following commands to create the PG and Redis clusters:</p>
<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>bin/pgsql-add  pg-meta                <span style="color:#8f5902;font-style:italic"># create the dify database cluster</span>
</span></span><span style="display:flex;"><span>bin/redis-add  redis-dify             <span style="color:#8f5902;font-style:italic"># create redis cluster</span>
</span></span></code></pre></div><p>Alternatively, you can define a new <a href="/docs/pgsql/user/">business user</a> and <a href="/docs/pgsql/db/">business database</a> on an existing PostgreSQL cluster, such as <code>pg-meta</code>, and create them with the following commands:</p>
<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>bin/pgsql-user pg-meta dbuser_dify    <span style="color:#8f5902;font-style:italic"># create dify biz user</span>
</span></span><span style="display:flex;"><span>bin/pgsql-db   pg-meta dify           <span style="color:#8f5902;font-style:italic"># create dify biz database</span>
</span></span></code></pre></div><p>You should be able to access PostgreSQL and Redis with the following connection strings, adjusting the connection information as needed:</p>
<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>psql postgres://dbuser_dify:DBUser.Dify@10.10.10.10:5432/dify -c <span style="color:#4e9a06">&#39;SELECT 1&#39;</span>
</span></span><span style="display:flex;"><span>redis-cli -u redis://redis.dify@10.10.10.10:6379/0 ping
</span></span></code></pre></div><p>Once you confirm these connection strings are working, you&rsquo;re all set to start deploying Dify.</p>
<p>For demonstration purposes, we&rsquo;re using direct IP connections. For a multi-node high availability PG cluster, please refer to the <a href="/docs/concept/svc/">service access</a> section.</p>
<p>The above assumes you are already a Pigsty user familiar with deploying PostgreSQL and Redis clusters. You can skip the next section and proceed to see <a href="/blog/pg/dify-setup/#dify-configuration">how to configure Dify</a>.</p>
<hr>
<h2 id="starting-from-scratch">Starting from Scratch</h2>
<p>If you&rsquo;re already familiar with setting up Pigsty, feel free to skip this section.</p>
<p><a href="/docs/setup/prepare/">Prepare</a> a fresh Linux x86_64 node that runs <a href="/docs/reference/compatibility/">compatible</a> OS, then run as a <strong>sudo-able</strong> user:</p>
<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>curl -fsSL https://repo.pigsty.io/get <span style="color:#000;font-weight:bold">|</span> bash
</span></span></code></pre></div><p>It will <a href="/blog/pg/dify-setup/#download">download</a> Pigsty source to your home, then perform <a href="/blog/pg/dify-setup/#configure">configure</a> and <a href="/blog/pg/dify-setup/#install">install</a> to finish the installation.</p>
<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span><span style="color:#204a87">cd</span> ~/pigsty   <span style="color:#8f5902;font-style:italic"># get pigsty source and entering dir</span>
</span></span><span style="display:flex;"><span>./bootstrap   <span style="color:#8f5902;font-style:italic"># download bootstrap pkgs &amp; ansible [optional]</span>
</span></span><span style="display:flex;"><span>./configure   <span style="color:#8f5902;font-style:italic"># pre-check and config templating   [optional]</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#8f5902;font-style:italic"># change pigsty.yml, adding those cluster definitions above into all.children </span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>./install.yml <span style="color:#8f5902;font-style:italic"># install pigsty according to pigsty.yml</span>
</span></span></code></pre></div><p>You should insert the above PostgreSQL cluster and Redis cluster definitions into the <code>pigsty.yml</code> file, then run <a href="/docs/infra/#infrayml"><code>install.yml</code></a> to complete the installation.</p>
<p><strong>Redis Deploy</strong></p>
<p>Pigsty will not deploy redis in <code>install.yml</code>, so you have to run <a href="/zh/docs/redis#redisyml"><code>redis.yml</code></a> playbook to install Redis explicitly:</p>
<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>./redis.yml
</span></span></code></pre></div><p><strong>Docker Deploy</strong></p>
<p>Pigsty will not deploy Docker by default, so you need to install Docker with the <a href="/zh/docs/docker#dockeryml"><code>docker.yml</code></a> playbook.</p>
<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>./docker.yml
</span></span></code></pre></div><hr>
<h2 id="dify-confiugration">Dify Confiugration</h2>
<p>You can configure dify in the <a href="https://github.com/Vonng/pigsty/blob/main/app/dify/.env"><code>.env</code></a> file:</p>
<p>All parameters are self-explanatory and filled in with default values that work directly in the <a href="/docs/setup/provision/">Pigsty sandbox env</a>.
Fill in the database connection information according to your actual conf, consistent with the PG/Redis cluster configuration above.</p>
<p>Changing the <code>SECRET_KEY</code> field is recommended. You can generate a strong key with <code>openssl rand -base64 42</code>:</p>
<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span><span style="color:#8f5902;font-style:italic"># meta parameter</span>
</span></span><span style="display:flex;"><span><span style="color:#000">DIFY_PORT</span><span style="color:#ce5c00;font-weight:bold">=</span><span style="color:#0000cf;font-weight:bold">8001</span> <span style="color:#8f5902;font-style:italic"># expose dify nginx service with port 8001 by default</span>
</span></span><span style="display:flex;"><span><span style="color:#000">LOG_LEVEL</span><span style="color:#ce5c00;font-weight:bold">=</span>INFO <span style="color:#8f5902;font-style:italic"># The log level for the application. Supported values are `DEBUG`, `INFO`, `WARNING`, `ERROR`, `CRITICAL`</span>
</span></span><span style="display:flex;"><span><span style="color:#000">SECRET_KEY</span><span style="color:#ce5c00;font-weight:bold">=</span>sk-9f73s3ljTXVcMT3Blb3ljTqtsKiGHXVcMT3BlbkFJLK7U <span style="color:#8f5902;font-style:italic"># A secret key for signing and encryption, gen with `openssl rand -base64 42`</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#8f5902;font-style:italic"># postgres credential</span>
</span></span><span style="display:flex;"><span><span style="color:#000">PG_USERNAME</span><span style="color:#ce5c00;font-weight:bold">=</span>dbuser_dify
</span></span><span style="display:flex;"><span><span style="color:#000">PG_PASSWORD</span><span style="color:#ce5c00;font-weight:bold">=</span>DBUser.Dify
</span></span><span style="display:flex;"><span><span style="color:#000">PG_HOST</span><span style="color:#ce5c00;font-weight:bold">=</span>10.10.10.10
</span></span><span style="display:flex;"><span><span style="color:#000">PG_PORT</span><span style="color:#ce5c00;font-weight:bold">=</span><span style="color:#0000cf;font-weight:bold">5432</span>
</span></span><span style="display:flex;"><span><span style="color:#000">PG_DATABASE</span><span style="color:#ce5c00;font-weight:bold">=</span>dify
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#8f5902;font-style:italic"># redis credential</span>
</span></span><span style="display:flex;"><span><span style="color:#000">REDIS_HOST</span><span style="color:#ce5c00;font-weight:bold">=</span>10.10.10.10
</span></span><span style="display:flex;"><span><span style="color:#000">REDIS_PORT</span><span style="color:#ce5c00;font-weight:bold">=</span><span style="color:#0000cf;font-weight:bold">6379</span>
</span></span><span style="display:flex;"><span><span style="color:#000">REDIS_USERNAME</span><span style="color:#ce5c00;font-weight:bold">=</span><span style="color:#4e9a06">&#39;&#39;</span>
</span></span><span style="display:flex;"><span><span style="color:#000">REDIS_PASSWORD</span><span style="color:#ce5c00;font-weight:bold">=</span>redis.dify
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#8f5902;font-style:italic"># minio/s3 [OPTIONAL] when STORAGE_TYPE=s3</span>
</span></span><span style="display:flex;"><span><span style="color:#000">STORAGE_TYPE</span><span style="color:#ce5c00;font-weight:bold">=</span><span style="color:#204a87">local</span>
</span></span><span style="display:flex;"><span><span style="color:#000">S3_ENDPOINT</span><span style="color:#ce5c00;font-weight:bold">=</span><span style="color:#4e9a06">&#39;https://sss.pigsty&#39;</span>
</span></span><span style="display:flex;"><span><span style="color:#000">S3_BUCKET_NAME</span><span style="color:#ce5c00;font-weight:bold">=</span><span style="color:#4e9a06">&#39;infra&#39;</span>
</span></span><span style="display:flex;"><span><span style="color:#000">S3_ACCESS_KEY</span><span style="color:#ce5c00;font-weight:bold">=</span><span style="color:#4e9a06">&#39;dba&#39;</span>
</span></span><span style="display:flex;"><span><span style="color:#000">S3_SECRET_KEY</span><span style="color:#ce5c00;font-weight:bold">=</span><span style="color:#4e9a06">&#39;S3User.DBA&#39;</span>
</span></span><span style="display:flex;"><span><span style="color:#000">S3_REGION</span><span style="color:#ce5c00;font-weight:bold">=</span><span style="color:#4e9a06">&#39;us-east-1&#39;</span>
</span></span></code></pre></div><p>Now we can pull up dify with docker compose:</p>
<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span><span style="color:#204a87">cd</span> pigsty/app/dify <span style="color:#ce5c00;font-weight:bold">&amp;&amp;</span> make up
</span></span></code></pre></div><hr>
<h2 id="expose-dify-service-via-nginx">Expose Dify Service via Nginx</h2>
<p>Dify expose web/api via its own nginx through port 80 by default, while pigsty uses port 80 for its own Nginx. T</p>
<p>herefore, we expose Dify via port <code>8001</code> by default, and use Pigsty&rsquo;s Nginx to forward to this port.</p>
<p>Change <code>infra_portal</code> in <code>pigsty.yml</code>, with the new <code>dify</code> line:</p>
<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span><span style="color:#204a87;font-weight:bold">infra_portal</span><span style="color:#000;font-weight:bold">:</span><span style="color:#f8f8f8;text-decoration:underline">                     </span><span style="color:#8f5902;font-style:italic"># domain names and upstream servers</span><span style="color:#f8f8f8;text-decoration:underline">
</span></span></span><span style="display:flex;"><span><span style="color:#f8f8f8;text-decoration:underline">  </span><span style="color:#204a87;font-weight:bold">home         </span><span style="color:#000;font-weight:bold">:</span><span style="color:#f8f8f8;text-decoration:underline"> </span>{<span style="color:#f8f8f8;text-decoration:underline"> </span><span style="color:#204a87;font-weight:bold">domain</span><span style="color:#000;font-weight:bold">:</span><span style="color:#f8f8f8;text-decoration:underline"> </span><span style="color:#000">h.pigsty }</span><span style="color:#f8f8f8;text-decoration:underline">
</span></span></span><span style="display:flex;"><span><span style="color:#f8f8f8;text-decoration:underline">  </span><span style="color:#204a87;font-weight:bold">grafana      </span><span style="color:#000;font-weight:bold">:</span><span style="color:#f8f8f8;text-decoration:underline"> </span>{<span style="color:#f8f8f8;text-decoration:underline"> </span><span style="color:#204a87;font-weight:bold">domain: g.pigsty ,endpoint</span><span style="color:#000;font-weight:bold">:</span><span style="color:#f8f8f8;text-decoration:underline"> </span><span style="color:#4e9a06">&#34;${admin_ip}:3000&#34;</span><span style="color:#f8f8f8;text-decoration:underline"> </span><span style="color:#204a87;font-weight:bold">, websocket</span><span style="color:#000;font-weight:bold">:</span><span style="color:#f8f8f8;text-decoration:underline"> </span><span style="color:#204a87;font-weight:bold">true</span><span style="color:#f8f8f8;text-decoration:underline"> </span>}<span style="color:#f8f8f8;text-decoration:underline">
</span></span></span><span style="display:flex;"><span><span style="color:#f8f8f8;text-decoration:underline">  </span><span style="color:#204a87;font-weight:bold">prometheus   </span><span style="color:#000;font-weight:bold">:</span><span style="color:#f8f8f8;text-decoration:underline"> </span>{<span style="color:#f8f8f8;text-decoration:underline"> </span><span style="color:#204a87;font-weight:bold">domain: p.pigsty ,endpoint</span><span style="color:#000;font-weight:bold">:</span><span style="color:#f8f8f8;text-decoration:underline"> </span><span style="color:#4e9a06">&#34;${admin_ip}:9090&#34;</span><span style="color:#f8f8f8;text-decoration:underline"> </span>}<span style="color:#f8f8f8;text-decoration:underline">
</span></span></span><span style="display:flex;"><span><span style="color:#f8f8f8;text-decoration:underline">  </span><span style="color:#204a87;font-weight:bold">alertmanager </span><span style="color:#000;font-weight:bold">:</span><span style="color:#f8f8f8;text-decoration:underline"> </span>{<span style="color:#f8f8f8;text-decoration:underline"> </span><span style="color:#204a87;font-weight:bold">domain: a.pigsty ,endpoint</span><span style="color:#000;font-weight:bold">:</span><span style="color:#f8f8f8;text-decoration:underline"> </span><span style="color:#4e9a06">&#34;${admin_ip}:9093&#34;</span><span style="color:#f8f8f8;text-decoration:underline"> </span>}<span style="color:#f8f8f8;text-decoration:underline">
</span></span></span><span style="display:flex;"><span><span style="color:#f8f8f8;text-decoration:underline">  </span><span style="color:#204a87;font-weight:bold">blackbox     </span><span style="color:#000;font-weight:bold">:</span><span style="color:#f8f8f8;text-decoration:underline"> </span>{<span style="color:#f8f8f8;text-decoration:underline"> </span><span style="color:#204a87;font-weight:bold">endpoint</span><span style="color:#000;font-weight:bold">:</span><span style="color:#f8f8f8;text-decoration:underline"> </span><span style="color:#4e9a06">&#34;${admin_ip}:9115&#34;</span><span style="color:#f8f8f8;text-decoration:underline"> </span>}<span style="color:#f8f8f8;text-decoration:underline">
</span></span></span><span style="display:flex;"><span><span style="color:#f8f8f8;text-decoration:underline">  </span><span style="color:#204a87;font-weight:bold">loki         </span><span style="color:#000;font-weight:bold">:</span><span style="color:#f8f8f8;text-decoration:underline"> </span>{<span style="color:#f8f8f8;text-decoration:underline"> </span><span style="color:#204a87;font-weight:bold">endpoint</span><span style="color:#000;font-weight:bold">:</span><span style="color:#f8f8f8;text-decoration:underline"> </span><span style="color:#4e9a06">&#34;${admin_ip}:3100&#34;</span><span style="color:#f8f8f8;text-decoration:underline"> </span>}<span style="color:#f8f8f8;text-decoration:underline">
</span></span></span><span style="display:flex;"><span><span style="color:#f8f8f8;text-decoration:underline">  
</span></span></span><span style="display:flex;"><span><span style="color:#f8f8f8;text-decoration:underline">  </span><span style="color:#204a87;font-weight:bold">dify         </span><span style="color:#000;font-weight:bold">:</span><span style="color:#f8f8f8;text-decoration:underline"> </span>{<span style="color:#f8f8f8;text-decoration:underline"> </span><span style="color:#204a87;font-weight:bold">domain: dify.pigsty ,endpoint</span><span style="color:#000;font-weight:bold">:</span><span style="color:#f8f8f8;text-decoration:underline"> </span><span style="color:#4e9a06">&#34;10.10.10.10:8001&#34;</span><span style="color:#204a87;font-weight:bold">, websocket</span><span style="color:#000;font-weight:bold">:</span><span style="color:#f8f8f8;text-decoration:underline"> </span><span style="color:#204a87;font-weight:bold">true</span><span style="color:#f8f8f8;text-decoration:underline"> </span>}<span style="color:#f8f8f8;text-decoration:underline">
</span></span></span></code></pre></div><p>Then expose dify web service via Pigsty&rsquo;s Nginx server:</p>
<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>./infra.yml -t nginx
</span></span></code></pre></div><p>Don&rsquo;t forget to add <code>dify.pigsty</code> to your DNS or local <code>/etc/hosts</code> / <code>C:\Windows\System32\drivers\etc\hosts</code> to access via domain name.</p>

</div>





    
	
  
    
    
	
    


  

<div class="td-content" style="page-break-before: always">
    <h1 id="pg-7b7e2fed3610aaf3b302a1fa64530049">PGCon.Dev 2024, The conf that shutdown PG for a week</h1>
	
	<div class="td-byline mb-4">
		By <b><a href="https://vonng.com">Ruohang Feng</a>(<a href="https://vonng.com/en/">@Vonng</a>) | <a href="https://mp.weixin.qq.com/s/dW3byoQkEIR0_EzWxobrWg">Wechat Column</a></b> |
        
		<time datetime="2024-06-17" class="text-muted">2024-06-17</time>
        
	</div>
	<p>PGCon.Dev, once known as PGCon—the annual must-attend gathering for PostgreSQL hackers and key forum for its future direction, has been held in Ottawa since its inception in 2007.</p>
<p>This year marks a new chapter as the original organizer, Dan, hands over the reins to a new team, and the event moves to SFU&rsquo;s Harbour Centre in Vancouver, kicking off a new era with grandeur.</p>
<p>How engaging was this event? <a href="https://peter.eisentraut.org/">Peter Eisentraut</a>, member of the PostgreSQL core team, noted that during PGCon.Dev, <a href="https://peter.eisentraut.org/blog/2024/06/04/how-engaging-was-pgconfdev-really">there were no code commits to PostgreSQL</a> &ndash; resulting in the longest pause in twenty years, a whopping week! a historic coding ceasefire! Why? Because all the developers were at the conference!</p>
<p><img alt="intro.png" src="/zh/blog/pg/pgcondev-2024/intro.png"></p>
<blockquote>
<p>Considering the last few interruptions that occurred in the early days of the project twenty years ago,</p>
</blockquote>
<p>I’ve been embracing PostgreSQL for a decade, but attending a global PG Hacker conference in person was a first for me, and I’m immensely grateful for the organizer&rsquo;s efforts.
PGCon.Dev 2024 wrapped up on May 31st, though this post comes a bit delayed as I’ve been exploring Vancouver and Banff National Park ;)</p>
<hr>
<h2 id="day-zero-extension-summit">Day Zero: Extension Summit</h2>
<p>Day zero is for leadership meetings, and I&rsquo;ve signed up for the afternoon&rsquo;s Extension Ecosystem Summit.</p>
<p>Maybe this summit is somewhat subtly related to my recent post, &ldquo;<a href="https://medium.com/@fengruohang/postgres-is-eating-the-database-world-157c204dcfc4">Postgres is eating the database world</a>,&rdquo;  highlighting PostgreSQL&rsquo;s thriving extension ecosystem as a unique and critical success factor and drawing the community&rsquo;s attention.</p>
<p><a href="https://medium.com/@fengruohang/postgres-is-eating-the-database-world-157c204dcfc4"><img alt="ecosystem.jpg" src="/zh/blog/pg/pgcondev-2024/ecosystem.jpg"></a></p>
<p>I participated in David Wheeler&rsquo;s Binary Packing session along with other PostgreSQL community leaders. Despite some hesitation to new standards like PGXN v2 from current RPM/APT maintainers.
In the latter half of the summit, I attended a session led by Yurii Rashkovskii, discussing extension directory structures, metadata, naming conflicts, version control, and binary distribution ideas.</p>
<p><img alt="extension-summit.jpg" src="/zh/blog/pg/pgcondev-2024/extension-summit.jpg"></p>
<p>Prior to this summit, the PostgreSQL community had held <a href="https://www.eventbrite.com/e/postgres-extension-ecosystem-mini-summit-tickets-851127263557">six mini-summits</a> discussing these topics intensely, with visions for the extension ecosystem&rsquo;s future development shared by various speakers. Recordings of these sessions are available on <a href="https://www.youtube.com/playlist?list=PL11N188AYb_aT6ulbJfrQJJziWb012jG3">YouTube</a>.</p>
<p>And after the summit, I had a chance to chat with Devrim, the RPM maintainer, about extension packing, which was quite enlightening.</p>
<p><img src="/zh/blog/pg/pgcondev-2024/devrim-keith.gif"></p>
<blockquote>
<p>&ldquo;Keith Fan Group&rdquo; &ndash; from Devrim on Extension Summit</p>
</blockquote>
<hr>
<h2 id="day-one-brilliant-talks-and-bar-social">Day One: Brilliant Talks and Bar Social</h2>
<p>The core of PGCon.Dev lies in its sessions. Unlike some China domestic conferences with mundane product pitches or irrelevant tech details, PGCon.Dev presentations are genuinely engaging and substantive. The official program kicked off on May 29th, after a day of closed-door leadership meetings and the Ecosystem Summit on the 28th.</p>
<p>The opening was co-hosted by <a href="https://jkatz05.com/">Jonathan Katz</a>, 1 of the 7 core PostgreSQL team members and a chief product manager at AWS RDS, and <a href="https://postgresql.life/post/melanie_plageman/">Melanie Plageman</a>, a recent PG committer from Microsoft. A highlight was when Andres Freund, the developer who uncovered the famous <code>xz</code> backdoor, was celebrated as a superhero on stage.</p>
<p><img alt="andres-hero.jpeg" src="/zh/blog/pg/pgcondev-2024/andres-hero.jpeg"></p>
<p>Following the opening, the regular session tracks began. Although conference videos aren&rsquo;t out yet, I&rsquo;m confident they&rsquo;ll &ldquo;soon&rdquo; be available on YouTube. Most sessions had three tracks running simultaneously; here are some highlights I chose to attend.</p>
<hr>
<h3 id="pushing-the-boundaries-of-pg-extensions">Pushing the Boundaries of PG Extensions</h3>
<p>Yurii&rsquo;s talk, &ldquo;<a href="https://slides.omnigr.es/pushing-boundaries-pgconfdev2024/1">Pushing the Boundaries of PG Extensions</a>,&rdquo; tackled what kind of extension APIs PostgreSQL should offer. PostgreSQL boasts robust extensibility, but the current extension API set is decades old, from the 9.x era. Yurii&rsquo;s proposal aims to address issues with the existing extension mechanisms. Challenges such as installing multiple versions of an extension simultaneously, avoiding database restarts post-extension installations, managing extensions as seamlessly as data, and handling dependencies among extensions were discussed.</p>
<p>Yurii and Viggy, founders of <a href="https://omnigres.com/">Omnigres</a>, aim to transform PostgreSQL into a full-fledged application development platform, including hosting HTTP servers directly within the database. They designed a new extension API and management system for PostgreSQL to achieve this. Their innovative improvements represent the forefront of exploration into PostgreSQL&rsquo;s core extension mechanisms.</p>
<p><img alt="yurii-extension.png" src="/zh/blog/pg/pgcondev-2024/yurii-extension.png"></p>
<p>I had a great conversation with Viggy and Yurii. Yurii walked me through compiling and installing Omni. I plan to support the Omni extension series in the next version of Pigsty, making this powerful application development framework plug-and-play.</p>
<hr>
<h3 id="anarchy-in-dbms">Anarchy in DBMS</h3>
<p>Abigale Kim from CMU, under the mentorship of celebrity professor Andy Pavlo, delivered the talk &ldquo;<a href="https://abigalekim.github.io/assets/pdf/Anarchy_in_the_Database_PGConfDev2024.pdf">Anarchy in the Database—A Survey and Evaluation of DBMS Extensibility</a>.&rdquo; This topic intrigued me since Pigsty&rsquo;s primary value proposition is about PostgreSQL&rsquo;s <a href="https://pigsty.io/docs/reference/extension/"><strong>extensibility</strong></a>.</p>
<p>Kim’s research revealed interesting insights: <strong>PostgreSQL is the most extensible DBMS</strong>, supporting 9 out of 10 extensibility points, closely followed by DuckDB. With over 375+ available extensions, PostgreSQL significantly outpaces other databases.</p>
<p><img alt="kim-extensibility.png" src="/zh/blog/pg/pgcondev-2024/kim-extensibility.png"></p>
<p>Kim&rsquo;s quantitative analysis of compatibility levels among these extensions resulted in a compatibility matrix, unveiling conflicts—most notably, powerful extensions like TimescaleDB and Citus are prone to clashes. This information is very valuable for users and distribution maintainers. <a href="https://abigalekim.github.io/assets/pdf/Anarchy_in_the_Database_PGConfDev2024.pdf">Read the detailed study</a>.</p>
<p>I joked with Kim that — now I could brag about PostgreSQL&rsquo;s extensibility with her research data.</p>
<hr>
<h3 id="how-postgresql-is-misused-and-abused">How PostgreSQL is Misused and Abused</h3>
<p>The first-afternoon session featured <a href="https://postgresql.life/post/karen_jex/">Karen Jex</a> from CrunchyData, an unusual perspective from a user — and a female DBA. Karen shared common blunders by PostgreSQL beginners. While I knew all of what was discussed, it reaffirmed that beginners worldwide make similar mistakes — an enlightening perspective for PG Hackers, who found the session quite engaging.</p>
<h3 id="postgresql-and-the-ai-ecosystem">PostgreSQL and the AI Ecosystem</h3>
<p>The second-afternoon session by <a href="https://postgresql.life/post/bruce_momjian/">Bruce Momjian</a>, co-founder of the PGDG and a core committee member from the start, was unexpectedly about using PostgreSQL&rsquo;s multi-dimensional arrays and queries to implement <a href="https://momjian.us/main/writings/pgsql/AI.pdf">neural network inference and training</a>.</p>
<p><img alt="bruce-ai.png" src="/zh/blog/pg/pgcondev-2024/bruce-ai.png"></p>
<blockquote>
<p>Haha, some ArgParser code. I see it</p>
</blockquote>
<p>During the lunch, Bruce explained that Jonathan Katz needed a topic to introduce the vector database extension PGVector in the PostgreSQL ecosystem, so Bruce was roped in to &ldquo;fill the gap.&rdquo; <a href="/">Check out Bruce’s presentation</a>.</p>
<h3 id="pb-level-postgresql-deployments">PB-Level PostgreSQL Deployments</h3>
<p>The third afternoon session by <a href="https://postgresql.life/post/chris_travers/">Chris Travers</a> discussed their transition from using ElasticSearch for data storage—with a poor experience and high maintenance for 1PB over 30 days retention, to a horizontally scaled PostgreSQL cluster perfectly <a href="https://www.pgevents.ca/events/pgconfdev2024/sessions/session/135/slides/30/">handling 10PB of data</a>. Normally, PostgreSQL comfort levels on a single machine range from several dozen to a few hundred TB. Deployments at the PB scale, especially at 10PB, even within a horizontally scaled cluster, are exceptionally rare. While the practice itself is standard—partitioning and sharding—the scale of data managed is truly impressive.</p>
<hr>
<h3 id="highlight-when-hardware-and-database-collide">Highlight: When Hardware and Database Collide</h3>
<p>Undoubtedly, the standout presentation of the event, Margo Seltzer&rsquo;s talk &ldquo;<a href="https://www.pgevents.ca/events/pgconfdev2024/schedule/session/192-keynote-when-hardware-and-databases-collide/">When Hardware and Database Collide</a>&rdquo; was not only the most passionate and compelling talk I&rsquo;ve attended live but also a highlight across all conferences.</p>
<p>Professor Margo Seltzer, formerly of Harvard and now at UBC, a member of the National Academy of Engineering and the creator of BerkeleyDB, delivered a powerful discourse on the core challenges facing databases today. She pinpointed that the bottleneck for databases has shifted from disk I/O to main memory speed. Emerging hardware technologies like <strong>HBM</strong> and <strong>CXL</strong> could be the solution, posing new challenges for PostgreSQL hackers to tackle.</p>
<p><img alt="margo.png" src="/zh/blog/pg/pgcondev-2024/margo.png"></p>
<p>This was a refreshing divergence from China&rsquo;s typically monotonous academic talks, leaving a profound impact and inspiration. Once the conference video is released, I highly recommend checking out her energizing presentation.</p>
<hr>
<h3 id="wetbar-social">WetBar Social</h3>
<p>Following Margo&rsquo;s session, the official Social Event took place at Rogue Kitchen &amp; Wetbar, just a street away from the venue at Waterfront Station, boasting views of the Pacific and iconic Vancouver landmarks.</p>
<p>The informal setting was perfect for engaging with new and old peers. Conversations with notable figures like Devrim, Tomasz, Yurii, and Keith were particularly enriching. As an RPM maintainer, I had an extensive and fruitful discussion with Devrim, resolving many longstanding queries.</p>
<p><img alt="social-bar.png" src="/zh/blog/pg/pgcondev-2024/social-bar.png"></p>
<p>The atmosphere was warm and familiar, with many reconnecting after long periods. A couple of beers in, conversations flowed even more freely among fellow PostgreSQL enthusiasts. The event concluded with an invitation from Melanie for a board game session, which I regretfully declined due to my limited English in such interactive settings.</p>
<hr>
<h2 id="day-2-debate-lunch-and-lighting-talks">Day 2: Debate, Lunch, and Lighting Talks</h2>
<h3 id="multi-threading-postgres">Multi-Threading Postgres</h3>
<p>The warmth from the previous night&rsquo;s socializing carried over into the next day, marked by the eagerly anticipated session on &ldquo;<strong>Multi-threaded PostgreSQL</strong>,&rdquo; which was packed to capacity. The discussion, initiated by Heikki, centered on the pros and cons of PostgreSQL&rsquo;s process and threading models, along with detailed implementation plans and current progress.</p>
<p>The threading model promises numerous benefits: cheaper connections (akin to a built-in connection pool), shared relation and plan caches, dynamic adjustment of shared memory, config changes without restarts, more aggressive Vacuum operations, runtime Explain Analyze, and easier memory usage limits per connection. However, there&rsquo;s significant opposition, maybe led by Tom Lane, concerned about potential bugs, loss of isolation benefits from the multi-process model, and extensive incompatibilities requiring many extensions to be rewritten.</p>
<p><img alt="heikki-multithread.png" src="/zh/blog/pg/pgcondev-2024/heikki-multithread.png"></p>
<p>Heikki laid out a detailed plan to transition to the threading model over five to seven years, aiming for a seamless shift without intermediate states. Intriguingly, he cited Tom Lane&rsquo;s critical comment in his presentation:</p>
<blockquote>
<p>For the record, I think this will be a disaster. There is far too much code that will get broken, largely silently, and much of it is not under our control. &ndash; regards, tom lane</p>
</blockquote>
<p>Although Tom Lane smiled benignly without voicing any objections, the strongest dissent at the conference came not from him but from an extension maintainer. The elder developer, who maintained several extensions, raised concerns about compatibility, specifically regarding memory allocation and usage. Heikki suggested that extension authors should adapt their work to a new model during a transition grace period of about five years. This suggestion visibly upset the maintainer, who left the meeting in anger.</p>
<p>Given the proposed threading model&rsquo;s significant impact on the existing extension ecosystem, I&rsquo;m skeptical about this change. At the conference, I consulted on the threading model with Heikki, Tom Lane, and other hackers. The community&rsquo;s overall stance is one of curious &amp; cautious observation. So far, the only progress is in PG 17, where the fork-exec-related code has been refactored and global variables marked for future modifications. Any real implementation would likely not occur until at least PG 20+.</p>
<hr>
<h3 id="hallway-track">Hallway Track</h3>
<p>The sessions on the second day were slightly less intense than the first, so many attendees chose the &ldquo;Hallway Track&rdquo;—engaging in conversations in the corridors and lobby. I&rsquo;m usually not great at networking as an introvert, but the vibrant atmosphere quickly drew me in. Eye contact alone was enough to spark conversations, like triggering NPC dialogue in an RPG. I also managed to subtly promote Pigsty to every corner of the PG community.</p>
<p><img alt="hallway-track.jpg" src="/zh/blog/pg/pgcondev-2024/hallway-track.jpg"></p>
<p>Despite being a first-timer at PGCon.Dev, I was surprised by the recognition and attention I received, largely thanks to the widely read article, &ldquo;<a href="https://medium.com/@fengruohang/postgres-is-eating-the-database-world-157c204dcfc4">PostgreSQL is eating the Database world</a>.&rdquo; Many recognized me by my badge <a href="https://vonng.com/en/">Vonng</a> / <a href="https://pigsty.io">Pigsty</a>.</p>
<p>A simple yet effective networking trick is never to underestimate small gifts&rsquo; effect. I handed out gold-plated Slonik pins, PostgreSQL&rsquo;s mascot, which became a coveted item at the conference. Everyone who talked with me received one, and those who didn&rsquo;t have one were left asking where to get one. LOL</p>
<p><img alt="collect.png" src="/zh/blog/pg/pgcondev-2024/collect.png"></p>
<p>Anyway, I&rsquo;m glad to have made many new friends and connections.</p>
<hr>
<h3 id="multinational-community-lunch">Multinational Community Lunch</h3>
<p>As for lunch, HighGo hosted key participants from the American, European, Japanese, and Chinese PostgreSQL communities at a Cantonese restaurant in Vancouver. The conversation ranged from serious technical discussions to lighter topics. I&rsquo;ve made acquaintance with Tatsuro Yamada, who gives a talk, &ldquo;<a href="https://www.pgevents.ca/events/pgconfdev2024/schedule/session/62-advice-is-seldom-welcome-but-efficacious/">Advice is seldom welcome but efficacious</a>&rdquo;, and Kyotaro Horiguchi, a core contributor to PostgreSQL known for his work on WAL replication and multibyte string processing and the author of pg_hint_plan.</p>
<p><img alt="lunch.jpeg" src="/zh/blog/pg/pgcondev-2024/lunch.jpeg"></p>
<p>Another major contributor to the PostgreSQL community, <strong>Mark Wong</strong> organizes PGUS and has developed a series of PostgreSQL monitoring extensions. He also manages community merchandise like contributor coins, shirts, and stickers. He even handcrafted a charming yarn elephant mascot, which was so beloved that one was sneakily &ldquo;borrowed&rdquo; at the last PG Conf US.</p>
<p><img alt="elephant.png" src="/zh/blog/pg/pgcondev-2024/elephant.png"></p>
<p>Bruce, already a familiar face in the PG Chinese community, Andreas Scherbaum from Germany, organizer of the European PG conferences, and Miao Jian, founder of Han Gao, representing the only Chinese database company at PGCon.Dev, all shared insightful stories and discussions about the challenges and nuances of developing databases in their respective regions.</p>
<p>On returning to the conference venue, I had a conversation with <a href="https://www.crunchydata.com/news/jan-wieck-former-postgres-core-team-member-joins-crunchy-data">Jan Wieck</a>, a PostgreSQL Hackers Emeritus. He shared his story of participating in the PostgreSQL project from the early days and encouraged me to get more involved in the PostgreSQL community, reminding me its future depends on the younger generation.</p>
<hr>
<h3 id="making-pg-hacking-more-inclusive">Making PG Hacking More Inclusive</h3>
<p>At PGCon.Dev, a special session on community building chaired by Robert Hass, featured three new PostgreSQL contributors sharing their journey and challenges, notably the barriers for non-native English speakers, timezone differences, and emotionally charged email communications.</p>
<p>Robert emphasized in a post-conference blog <a href="https://rhaas.blogspot.com/2024/06/2024pgconfdev-and-growing-community.html">his desire to see more developers from India and Japan rise to senior positions within PostgreSQL&rsquo;s ranks</a>, noting the underrepresentation from these countries despite their significant developer communities.</p>
<blockquote>
<p>While we&rsquo;re at it, I&rsquo;d really like to see more people from India and Japan in senior positions within the project. We have very large developer communities from both countries, but there is no one from either of those countries on the core team, and they&rsquo;re also underrepresented in other senior positions. At the risk of picking specific examples to illustrate a general point, there is no one from either country on the infrastructure team or the code of conduct committee. We do have a few committers from those countries, which is very good, and I was pleased to see Amit Kapila on the 2024.pgconf.dev organizing commitee, but, overall, I think we are still not where we should be. Part of getting people involved is making them feel like they are not alone, and part of it is also making them feel like progression is possible. Let&rsquo;s try harder to do that.</p>
</blockquote>
<p>Frankly, the lack of mention of China in discussions about inclusivity at PGCon.Dev, in favor of India and Japan, left a bittersweet taste. But I think China deserves the snub, given its poor international community engagement.</p>
<p>China has hundreds of &ldquo;domestic/national&rdquo; databases, many mere forks of PostgreSQL, yet there&rsquo;s only a single notable Chinese contributor to PostgreSQL is Richard Guo from PieCloudDB, recently promoted to PG Committer.
At the conference, the Chinese presence was minimal, summing up to five attendees, including myself. It&rsquo;s regrettable that China&rsquo;s understanding and adoption of PostgreSQL lag behind the global standard by about 10-15 years.</p>
<p>I hope my involvement can bootstrap and enhance Chinese participation in the global PostgreSQL ecosystem, making their users, developers, products, and open-source projects more recognized and accepted worldwide.</p>
<hr>
<h3 id="lightning-talks">Lightning Talks</h3>
<p>Yesterday’s event closed with a series of lightning talks—5 minutes max per speaker, or you&rsquo;re out. Concise and punchy, the session wrapped up 11 topics in just 45 minutes. Keith shared improvements to PG Monitor, and Peter Eisentraut discussed SQL standard updates. But from my perspective, the highlight was Devrim Gündüz&rsquo;s talk on PG RPMs, which lived up to his promise of a &ldquo;big reveal&rdquo; made at the bar the previous night, packing a 75-slide presentation into 5 lively minutes.</p>
<p><img alt="devrim.png" src="/zh/blog/pg/pgcondev-2024/devrim.png"></p>
<p>Speaking of PostgreSQL, despite being open-source, most users rely on official pre-compiled binaries packages rather than building from source. I maintain 34 RPM extensions for <a href="https://pigsty.io">Pigsty</a>, my Postgres distribution, but much of the ecosystem, including over a hundred other extensions, is managed by Devrim from the official PGDG repo. His efforts ensure quality for the world’s most advanced and popular database.</p>
<p>Devrim is a fascinating character — a Turkish native living in London, a part-time DJ, and the maintainer of the PGDG RPM repository, sporting a PostgreSQL logo tattoo. After an engaging chat about the PGDG repository, he shared insights on how extensions are added, highlighting the community-driven nature of PGXN and recent popular additions like <code>pgvector</code>, (<a href="https://github.com/pgvector/pgvector/issues/76">which I made the suggestion haha</a>).</p>
<p>Interestingly, with the latest Pigsty v2.7 release, four of my maintained (packaging) extensions (<code>pgsql-http</code>, <code>pgsql-gzip</code>, <code>pg_net</code>, <code>pg_bigm</code>) were adopted into the PGDG official repository. Devrim admitted to scouring Pigsty&rsquo;s <a href="/docs/reference/extension/">extension list</a> for good picks, though he humorously dismissed any hopes for my Rust pgrx extensions making the cut, reaffirming his commitment to not blending Go and Rust plugins into the official repository. Our conversation was so enriching that I&rsquo;ve committed myself to becoming a &ldquo;PG Extension Hunter,&rdquo; scouting and recommending new plugins for official inclusion.</p>
<hr>
<h2 id="day-3-unconference">Day 3: Unconference</h2>
<p>One of the highlights of PGCon.Dev is the Unconference, a self-organized meeting with no predefined agenda, driven by attendee-proposed topics. On day three, Joseph Conway facilitated the session where anyone could pitch topics for discussion, which were then voted on by participants. My proposal for a <strong>Built-in Prometheus Metrics Exporter</strong> was merged into a broader <strong>Observability</strong> topic spearheaded by Jeremy.</p>
<p><img alt="unconference.png" src="/zh/blog/pg/pgcondev-2024/unconference.png"></p>
<p>The top-voted topics were Multithreading (42 votes), Observability (35 votes), and Enhanced Community Engagement (35 votes). Observability features were a major focus, reflecting the community&rsquo;s priority. I proposed integrating a contrib monitoring extension in PostgreSQL to directly expose metrics via HTTP endpoint, using <code>pg_exporter</code> as a blueprint but embedded to overcome the limitations of external components, especially during crash recovery scenarios.</p>
<p><img alt="unconference2.png" src="/zh/blog/pg/pgcondev-2024/unconference2.png"></p>
<p>There&rsquo;s a clear focus on observability among the community. As the author of <a href="https://github.com/Vonng/pg_exporter">pg_exporter</a>, I proposed developing a first-party monitoring extension. This extension would integrate Prometheus monitoring endpoints directly into PostgreSQL, exposing metrics via HTTP without needing external components.</p>
<p>The rationale for this proposal is straightforward. While <code>pg_exporter</code> works well, it&rsquo;s an external component that adds management complexity. Additionally, in scenarios where PostgreSQL is recovering from a crash and cannot accept new connections, external tools struggle to access internal states. An in-kernel extension could seamlessly capture this information.</p>
<p>The suggested implementation involves a background worker process similar to the <code>bgw_replstatus</code> extension. This process would listen on an additional port to expose monitoring metrics through HTTP, using pg_exporter as a blueprint. Metrics would primarily be defined via a Collector configuration table, except for a few critical system indicators.</p>
<p>This idea garnered attention from several PostgreSQL hackers at the event. Developers from EDB and CloudNativePG are evaluating whether <a href="https://github.com/Vonng/pg_exporter"><code>pg_exporter</code></a> could be directly integrated into their distributions as part of their monitoring solutions. And finally, an Observability Special Interest Group (SIG) was formed by attendees interested in observability, planning to continue discussions through a mailing list.</p>
<hr>
<h3 id="issue-support-for-loongarch-architecture">Issue: Support for LoongArch Architecture</h3>
<p>During the last two days, I have had some discussions with PG Hackers about some Chinese-specific issues.</p>
<p>A notable suggestion was supporting the LoongArch architecture in the PGDG global repository, which was backed by some enthusiastically local chip and OS manufacturers. Despite the interest, Devrim indicated a &ldquo;No&rdquo; due to the lack of support for LoongArch in OS Distro used in the PG community, like CentOS 7, Rocky 8/9, and Debian 10/11/12. Tomasz Rybak was more receptive, noting potential future support if LoongArch runs on Debian 13.</p>
<p>In summary, official PG RPMs might not yet support LoongArch, but APT has a chance, contingent on broader OS support for mainstream open-source Linux distributions.</p>
<hr>
<h3 id="issue-server-side-chinese-character-encoding">Issue: Server-side Chinese Character Encoding</h3>
<p>At the recent conference, Jeremy Schneider presented an insightful talk on collation rules that resonated with me. He highlighted the pitfalls of not using C.UTF8 for collation, a practice I&rsquo;ve advocated for based on my own <a href="https://pigsty.cc/zh/blog/admin/collate/">research</a>, and which is detailed in his presentation here.</p>
<p>Post-talk, I discussed further with Jeremy and Peter Eisentraut the nuances of character sets in China, especially the challenges posed by the mandatory <strong>GB18030</strong> standard, which PostgreSQL can handle on the client side but not the server side. Also, there are some issues about 20 Chinese characters not working on the <code>convert_to</code> + <code>gb18030</code> encoding mapping.</p>
<hr>
<h3 id="closing">Closing</h3>
<p>The event closed with Jonathan Katz and Melanie Plageman wrapping up an exceptional conference that leaves us looking forward to next year&rsquo;s PGCon.Dev 2025 in Canada, possibly in Vancouver, Toronto, Ottawa, or Montreal.</p>
<p><img alt="closing.jpeg" src="/zh/blog/pg/pgcondev-2024/closing.jpeg"></p>
<p>Inspired by the engagement at this conference, I&rsquo;m considering presenting on Pigsty or PostgreSQL observability next year.</p>
<hr>
<p>Notably, following the conference, Pigsty&rsquo;s international CDN traffic spiked significantly, highlighting the growing global reach of our PostgreSQL distribution, which really made my day.</p>
<p><a href="https://pigsty.io/"><img alt="pigsty-traffic-en.png" src="/zh/blog/pg/pgcondev-2024/pigsty-traffic-en.png"></a></p>
<blockquote>
<p>Pigsty CDN Traffic Growth after PGCon.Dev 2024</p>
</blockquote>
<hr>
<p>Some slides are <a href="https://www.pgevents.ca/events/pgconfdev2024/sessions/">available</a> on the official site, and some blog posts about PGCon are here.Dev 2024:</p>
<ul>
<li>
<p><a href="https://andreas.scherbaum.la/post/2024-06-14_postgresql-development-conference-2024-review/">Andreas Scherbaum PostgreSQL Development Conference 2024 - Review</a></p>
</li>
<li>
<p><a href="https://wiki.postgresql.org/wiki/PgCon_2024_Developer_Meeting">PgCon 2024 Developer Meeting</a></p>
</li>
<li>
<p><a href="https://rhaas.blogspot.com/2024/06/2024pgconfdev-and-growing-community.html">Robert Haas: 2024.pgconf.dev and Growing the Community</a></p>
</li>
<li>
<p><a href="https://peter.eisentraut.org/blog/2024/06/04/how-engaging-was-pgconfdev-really">How engaging was PGConf.dev really?</a></p>
</li>
<li>
<p><a href="https://www.highgo.ca/2024/06/11/pgconf-dev-2024-shaping-the-future-of-postgresql-in-vancouver/">Cary Huang: PGConf.dev 2024：在温哥华塑造 PostgreSQL 的未来</a></p>
</li>
<li>
<p><a href="https://mp.weixin.qq.com/s/C0YyE52KbLLbnG1C2FqGRg">PGCon.Dev 扩展生态峰会小记 @ 温哥华</a></p>
</li>
<li>
<p><a href="https://mp.weixin.qq.com/s/4t1thBCDVS8y9dHiOxPZaA">PG大会2024开幕，温哥华饭搭子驴友团呢？</a></p>
</li>
</ul>

</div>





    
	
  
    
    
	
    


  

<div class="td-content" style="page-break-before: always">
    <h1 id="pg-7d36280c97d93954ecc5eee99cde64b7">Postgres is eating the database world</h1>
	
	<div class="td-byline mb-4">
		By <b><a href="https://vonng.com">Ruohang Feng</a>(<a href="https://vonng.com/en/">@Vonng</a>)| <a href="https://mp.weixin.qq.com/s/8_uhRH93oAoHZqoC90DA6g">WeChat</a> | <a href="https://medium.com/@fengruohang/postgres-is-eating-the-database-world-157c204dcfc4">Medium</a></b> |
        
		<time datetime="2024-03-04" class="text-muted">2024-03-04</time>
        
	</div>
	<p>PostgreSQL isn’t just a simple relational database; it’s a data management framework with the potential to engulf the entire database realm. The trend of “Using Postgres for Everything” is no longer limited to a few elite teams but is becoming a mainstream best practice.</p>
<hr>
<h2 id="olaps-new-challenger">OLAP&rsquo;s New Challenger</h2>
<p>In a 2016 database meetup, I argued that a significant gap in the PostgreSQL ecosystem was the lack of a <strong>sufficiently good</strong> columnar storage engine for OLAP workloads. While PostgreSQL itself offers lots of analysis features, its performance in full-scale analysis on larger datasets doesn’t quite measure up to dedicated real-time data warehouses.</p>
<p>Consider <a href="https://benchmark.clickhouse.com/">ClickBench</a>, an analytics performance benchmark, where we’ve documented the performance of PostgreSQL, its ecosystem extensions, and derivative databases. The untuned PostgreSQL performs poorly (<strong>x1050</strong>), but it can reach (<strong>x47</strong>) with optimization. Additionally, there are three analysis-related extensions: columnar store <strong>Hydra</strong> (<strong>x42</strong>), time-series <strong>TimescaleDB</strong> (<strong>x103</strong>), and distributed <strong>Citus</strong> (<strong>x262</strong>).</p>
<p><a href="https://benchmark.clickhouse.com/"><img alt="clickbench.png" src="/zh/blog/pg/pg-eat-db-world/clickbench-en.png"></a></p>
<blockquote>
<p>ClickBench c6a.4xlarge, 500gb gp2 results in relative time</p>
</blockquote>
<p>This performance can&rsquo;t be considered bad, especially compared to pure OLTP databases like MySQL and MariaDB (<strong>x3065, x19700</strong>); however, its third-tier performance is not &ldquo;good enough,&rdquo; lagging behind the first-tier OLAP components like Umbra, ClickHouse, Databend, SelectDB (<strong>x3~x4</strong>) by an order of magnitude. It&rsquo;s a tough spot - not satisfying enough to use, but too good to discard.</p>
<p>However, the arrival of <a href="https://www.paradedb.com/"><strong>ParadeDB</strong></a> and <a href="https://duckdb.org/"><strong>DuckDB</strong></a> changed the game!</p>
<p><strong>ParadeDB</strong>&rsquo;s native PG extension <strong>pg_analytics</strong> achieves second-tier performance (<strong>x10</strong>), narrowing the gap to the top tier to just 3–4x. Given the additional benefits, this level of performance discrepancy is often acceptable - ACID, freshness and real-time data without ETL, no additional learning curve, no maintenance of separate services, not to mention its ElasticSearch grade full-text search capabilities.</p>
<p><strong>DuckDB</strong> focuses on pure OLAP, pushing analysis performance to the extreme (<strong>x3.2</strong>) — excluding the academically focused, closed-source database Umbra, DuckDB is arguably the fastest for practical OLAP performance. It’s not a PG extension, but PostgreSQL can fully leverage DuckDB’s analysis performance boost as an embedded file database through projects like <a href="https://github.com/alitrack/duckdb_fdw"><strong>DuckDB FDW</strong></a> and <a href="https://github.com/hydradatabase/pg_quack"><strong>pg_quack</strong></a>.</p>
<p>The emergence of ParadeDB and DuckDB propels PostgreSQL&rsquo;s analysis capabilities to the top tier of OLAP, filling the last crucial gap in its analytic performance.</p>
<hr>
<h2 id="the-pendulum-of-database-realm">The Pendulum of Database Realm</h2>
<p>The distinction between OLTP and OLAP didn’t exist at the inception of databases. The separation of OLAP data warehouses from databases emerged in the 1990s due to traditional OLTP databases struggling to support analytics scenarios&rsquo; query patterns and performance demands.</p>
<p>For a long time, best practice in data processing involved using MySQL/PostgreSQL for OLTP workloads and syncing data to specialized OLAP systems like Greenplum, ClickHouse, Doris, Snowflake, etc., through ETL processes.</p>
<figure class="card rounded p-2 td-post-card mb-4 mt-4" style="max-width: 735px">
<img class="card-img-top" src="/zh/blog/pg/pg-eat-db-world/ddia_hu04f70ed29e59e1b4862c5f1df5de3cec_998548_768x512_fit_catmullrom_3.png" width="725" height="512">
</figure>
<blockquote>
<p>DDIA, Martin Kleppmann, ch3, The republic of OLTP &amp; Kingdom of OLAP</p>
</blockquote>
<p>Like many &ldquo;specialized databases,&rdquo; the strength of dedicated OLAP systems often lies in <strong>performance</strong> — achieving 1-3 orders of magnitude improvement over native PG or MySQL. The <strong>cost</strong>, however, is redundant data, excessive data movement, lack of agreement on data values among distributed components, extra labor expense for specialized skills, extra licensing costs, limited query language power, programmability and extensibility, limited tool integration, poor data integrity and availability compared with a complete DMBS.</p>
<p>However, as the saying goes, &ldquo;What goes around comes around&rdquo;. With <a href="/blog/cloud/bonus/">hardware improving over thirty years following Moore&rsquo;s Law</a>, performance has increased exponentially while costs have plummeted. In 2024, a single x86 machine can have hundreds of cores (512 vCPU <a href="https://www.amd.com/zh-hans/products/cpu/amd-epyc-9754">EPYC 9754</a>x2), several TBs of RAM, a single NVMe SSD can hold up to 64TB, and a single all-flash rack can reach 2PB; object storage like S3 offers virtually unlimited storage.</p>
<p><a href="/blog/cloud/bonus/"><img alt="io-bandwidth.png" src="/zh/blog/pg/pg-eat-db-world/io-bandwidth.png"></a></p>
<p>Hardware advancements have solved the data volume and performance issue, while database software developments (PostgreSQL, ParadeDB, DuckDB) have addressed access method challenges. This puts the fundamental assumptions of the analytics sector — the so-called “big data” industry — under scrutiny.</p>
<p>As DuckDB&rsquo;s manifesto <a href="https://motherduck.com/blog/big-data-is-dead/">&quot;<strong>Big Data is Dead</strong>&quot;</a> suggests, <strong>the era of big data is over</strong>. Most people don&rsquo;t have that much data, and most data is seldom queried. The frontier of big data recedes as hardware and software evolve, rendering &ldquo;big data&rdquo; unnecessary for 99% of scenarios.</p>
<p>If 99% of use cases can now be handled on a single machine with standalone DuckDB or PostgreSQL (and its replicas), what&rsquo;s the point of using dedicated analytics components? If every smartphone can send and receive texts freely, what&rsquo;s the point of pagers? (With the caveat that North American hospitals still use pagers, indicating that maybe less than 1% of scenarios might genuinely need &ldquo;big data.&rdquo;)</p>
<p>The shift in fundamental assumptions is steering the database world from a phase of diversification back to convergence, from a big bang to a mass extinction. In this process, a new era of unified, multi-modeled, super-converged databases will emerge, reuniting OLTP and OLAP. But who will lead this monumental task of reconsolidating the database field?</p>
<hr>
<h2 id="postgresql-the-database-world-eater">PostgreSQL: The Database World Eater</h2>
<p>There are a plethora of niches in the database realm: time-series, geospatial, document, search, graph, vector databases, message queues, and object databases. PostgreSQL makes its presence felt across all these domains.</p>
<p>A case in point is the PostGIS extension, which sets the de facto standard in geospatial databases; the TimescaleDB extension awkwardly positions “generic” time-series databases; and the vector extension, <strong>PGVector</strong>, turns the dedicated vector database niche into a punchline.</p>
<p>This isn’t the first time; we’re witnessing it again in the oldest and largest subdomain: OLAP analytics. But PostgreSQL’s ambition doesn’t stop at OLAP; it’s eyeing the entire database world!</p>
<p><a href="/docs/reference/extension/"><img alt="ecosystem.jpg" src="/zh/blog/pg/pg-eat-db-world/ecosystem.jpg"></a></p>
<p>What makes PostgreSQL so capable? Sure, it&rsquo;s advanced, but so is Oracle; it&rsquo;s open-source, as is MySQL. PostgreSQL&rsquo;s edge comes from being <strong>both advanced and open-source</strong>, allowing it to compete with Oracle/MySQL. But its true uniqueness lies in its <strong>extreme extensibility and thriving extension ecosystem</strong>.</p>
<p><a href="https://www.timescale.com/state-of-postgres/2022/"><img alt="survey.png" src="/zh/blog/pg/pg-eat-db-world/survey.png"></a></p>
<blockquote>
<p>TimescaleDB survey: <a href="https://www.timescale.com/state-of-postgres/2022/">what is the main reason you choose to use PostgreSQL</a></p>
</blockquote>
<p>PostgreSQL isn’t just a relational database; it’s a data management framework capable of engulfing the entire database galaxy. Besides being open-source and advanced, its core competitiveness stems from <strong>extensibility</strong>, i.e., its infra’s reusability and extension&rsquo;s composability.</p>
<hr>
<h3 id="the-magic-of-extreme-extensibility">The Magic of Extreme Extensibility</h3>
<p>PostgreSQL allows users to develop extensions, leveraging the database&rsquo;s common infra to deliver features at minimal cost. For instance, the vector database extension <a href="https://github.com/pgvector/pgvector">pgvector</a>, with just several thousand lines of code, is negligible in complexity compared to PostgreSQL&rsquo;s millions of lines. Yet, this &ldquo;insignificant&rdquo; extension achieves complete vector data types and indexing capabilities, <a href="https://supabase.com/blog/pgvector-vs-pinecone">outperforming</a> lots of specialized vector databases.</p>
<p>Why? Because pgvector&rsquo;s creators didn&rsquo;t need to worry about the database&rsquo;s general additional complexities: ACID, recovery, backup &amp; PITR, high availability, access control, monitoring, deployment, 3rd-party ecosystem tools, client drivers, etc., which require millions of lines of code to solve well. They only focused on the essential complexity of their problem.</p>
<p>For example, ElasticSearch was developed on the Lucene search library, while the Rust ecosystem has an improved next-gen full-text search library, <a href="https://github.com/quickwit-oss/tantivy">Tantivy</a>, as a Lucene alternative. ParadeDB only needs to wrap and connect it to PostgreSQL&rsquo;s interface to offer search services comparable to ElasticSearch. More importantly, it can stand on the shoulders of PostgreSQL, leveraging the entire PG ecosystem&rsquo;s united strength (e.g., mixed searches with PG Vector) to &ldquo;unfairly&rdquo; compete with another dedicated database.</p>
<p><a href="/docs/reference/extension/"><img alt="img" src="/img/pigsty/extension.png"></a></p>
<blockquote>
<p>Pigsty has 255 <a href="/docs/reference/extension/"><strong>extensions</strong></a> available. And there are <a href="https://gist.github.com/joelonsql/e5aa27f8cc9bd22b8999b7de8aee9d47"><strong>1000+</strong></a> more in the ecosystem</p>
</blockquote>
<hr>
<p>The extensibility brings another huge advantage: the <strong>composability</strong> of extensions, allowing different extensions to work together, creating a synergistic effect where 1+1 &raquo; 2. For instance, TimescaleDB can be combined with PostGIS for spatio-temporal data support; the BM25 extension for full-text search can be combined with the PGVector extension, providing hybrid search capabilities.</p>
<p>Furthermore, the <strong>distributive</strong> extension <a href="https://www.citusdata.com/"><strong>Citus</strong></a> can transparently transform a standalone cluster into a horizontally partitioned distributed database cluster. This capability can be orthogonally combined with other features, making PostGIS a distributed geospatial database, PGVector a distributed vector database, ParadeDB a distributed full-text search database, and so on.</p>
<hr>
<p>What’s more powerful is that extensions <strong>evolve independently</strong>, without the cumbersome need for main branch merges and coordination.  This allows for scaling — PG’s extensibility lets numerous teams explore database possibilities in parallel, with all extensions being optional, not affecting the core functionality’s reliability. Those features that are mature and robust have the chance to be stably integrated into the main branch.</p>
<p>PostgreSQL achieves both foundational <strong>reliability</strong> and <strong>agile functionality</strong> through the magic of extreme extensibility, making it an outlier in the database world and changing the game rules of the database landscape.</p>
<hr>
<h2 id="game-changer-in-the-db-arena">Game Changer in the DB Arena</h2>
<p><strong>The emergence of PostgreSQL has shifted the paradigms in the database domain</strong>: Teams endeavoring to craft a “new database kernel” now face a formidable trial — how to stand out against the open-source, feature-rich Postgres. What’s their unique value proposition?</p>
<p>Until a revolutionary hardware breakthrough occurs, the advent of practical, new, general-purpose database kernels seems unlikely. No singular database can match the overall prowess of PG, bolstered by all its extensions — not even Oracle, given PG’s ace of being open-source and free.</p>
<p>A niche database product might carve out a space for itself if it can outperform PostgreSQL by an order of magnitude in specific aspects (typically performance). However, it usually doesn’t take long before the PostgreSQL ecosystem spawns open-source extension alternatives. Opting to develop a PG extension rather than a whole new database gives teams a crushing speed advantage in playing catch-up!</p>
<p>Following this logic, the PostgreSQL ecosystem is poised to snowball, accruing advantages and inevitably moving towards a monopoly, mirroring the Linux kernel’s status in server OS within a few years. Developer surveys and database trend reports confirm this trajectory.</p>
<p><a href="https://survey.stackoverflow.co/2023/#section-most-popular-technologies-databases"><img alt="sf-survey.png" src="/zh/blog/pg/pg-eat-db-world/sf-survey.png"></a></p>
<blockquote>
<p><a href="https://survey.stackoverflow.co/2023/#section-most-popular-technologies-databases"><strong>StackOverflow 2023 Survey: PostgreSQL, the Decathlete</strong></a></p>
</blockquote>
<p><a href="https://demo.pigsty.cc/d/sf-survey"><img alt="sf-trend.jpg" src="/zh/blog/pg/pg-eat-db-world/sf-trend.jpg"></a></p>
<blockquote>
<p><a href="https://demo.pigsty.cc/d/sf-survey"><strong>StackOverflow&rsquo;s Database Trends Over the Past 7 Years</strong></a></p>
</blockquote>
<p>PostgreSQL has long been the favorite database in HackerNews &amp; StackOverflow. Many new open-source projects default to PostgreSQL as their primary, if not only, database choice. And many new-gen companies are going All in PostgreSQL.</p>
<p>As “<a href="https://www.amazingcto.com/postgres-for-everything/"><strong>Radical Simplicity: Just Use Postgres</strong></a>” says, Simplifying tech stacks, reducing components, accelerating development, lowering risks, and adding more features can be achieved by <strong>“Just Use Postgres.”</strong> Postgres can replace many backend technologies, including MySQL, Kafka, RabbitMQ, ElasticSearch, Mongo, and Redis, effortlessly serving millions of users. <strong>Just Use Postgres</strong> is no longer limited to a few elite teams but becoming a mainstream best practice.</p>
<hr>
<h2 id="what-else-can-be-done">What Else Can Be Done?</h2>
<p>The endgame for the database domain seems predictable. But what can we do, and what should we do?</p>
<p>PostgreSQL is already a near-perfect database kernel for the vast majority of scenarios, making the idea of a kernel &ldquo;bottleneck&rdquo; absurd. Forks of PostgreSQL and MySQL that tout kernel modifications as selling points are essentially going nowhere.</p>
<p>This is similar to the situation with the Linux OS kernel today; despite the plethora of Linux distros, everyone opts for the same kernel. Forking the Linux kernel is seen as creating unnecessary difficulties, and the industry frowns upon it.</p>
<p>Accordingly, the main conflict is no longer the database kernel itself but two directions— database <strong>extensions</strong> and <strong>services</strong>! The former pertains to internal extensibility, while the latter relates to external composability. Much like the OS ecosystem, the competitive landscape will concentrate on <strong>database distributions</strong>. In the database domain, only those distributions centered around extensions and services stand a chance for ultimate success.</p>
<p>Kernel remains lukewarm, with MariaDB, the fork of MySQL’s parent, nearing delisting, while AWS, profiting from offering services and extensions on top of the free kernel, thrives. Investment has flowed into numerous PG ecosystem extensions and service distributions: Citus, TimescaleDB, Hydra, PostgresML, ParadeDB, FerretDB, StackGres, Aiven, Neon, Supabase, Tembo, PostgresAI, and our own PG distro — — <a href="https://pigsty.io/">Pigsty</a>.</p>
<p><img src="/img/pigsty/players.png"></p>
<hr>
<p>A dilemma within the PostgreSQL ecosystem is the independent evolution of many extensions and tools, lacking a unifier to synergize them. For instance, Hydra releases its own package and Docker image, and so does PostgresML, each distributing PostgreSQL images with their own extensions and only their own. These images and packages are far from comprehensive database services like AWS RDS.</p>
<p>Even service providers and ecosystem integrators like AWS fall short in front of numerous extensions, unable to include many due to various reasons (AGPLv3 license, security challenges with multi-tenancy),
thus failing to leverage the synergistic amplification potential of PostgreSQL ecosystem extensions.</p>
<blockquote>
<table>
<thead>
<tr>
<th><strong>Extesion Category</strong></th>
<th><a href="https://pigsty.io/docs/reference/extension/"><strong>Pigsty RDS &amp; PGDG</strong></a></th>
<th style="text-align:center"><a href="https://docs.aws.amazon.com/AmazonRDS/latest/PostgreSQLReleaseNotes/postgresql-extensions.html"><strong>AWS RDS PG</strong></a></th>
<th style="text-align:center"><a href="https://help.aliyun.com/zh/rds/apsaradb-rds-for-postgresql/extensions-supported-by-apsaradb-rds-for-postgresql"><strong>Aliyun RDS PG</strong></a></th>
</tr>
</thead>
<tbody>
<tr>
<td>Add Extension</td>
<td><i class="fas fa-circle-check text-success"></i> Free to Install</td>
<td style="text-align:center"><i class="fas fa-circle-xmark text-danger"></i> Not Allowed</td>
<td style="text-align:center"><i class="fas fa-circle-xmark text-danger"></i> Not Allowed</td>
</tr>
<tr>
<td>Geo Spatial</td>
<td><i class="fas fa-circle-check text-success"></i> PostGIS 3.4.2</td>
<td style="text-align:center"><i class="fas fa-circle-check text-success"></i> PostGIS 3.4.1</td>
<td style="text-align:center"><i class="fas fa-circle-check text-success"></i> PostGIS 3.3.4</td>
</tr>
<tr>
<td>Time Series</td>
<td><i class="fas fa-circle-check text-success"></i> TimescaleDB 2.14.2</td>
<td style="text-align:center"><i class="fas fa-circle-xmark text-danger"></i></td>
<td style="text-align:center"><i class="fas fa-circle-xmark text-danger"></i></td>
</tr>
<tr>
<td>Distributive</td>
<td><i class="fas fa-circle-check text-success"></i> Citus 12.1</td>
<td style="text-align:center"><i class="fas fa-circle-xmark text-danger"></i></td>
<td style="text-align:center"><i class="fas fa-circle-xmark text-danger"></i></td>
</tr>
<tr>
<td>AI / ML</td>
<td><i class="fas fa-circle-check text-success"></i> PostgresML 2.8.1</td>
<td style="text-align:center"><i class="fas fa-circle-xmark text-danger"></i></td>
<td style="text-align:center"><i class="fas fa-circle-xmark text-danger"></i></td>
</tr>
<tr>
<td>Columnar</td>
<td><i class="fas fa-circle-check text-success"></i> Hydra 1.1.1</td>
<td style="text-align:center"><i class="fas fa-circle-xmark text-danger"></i></td>
<td style="text-align:center"><i class="fas fa-circle-xmark text-danger"></i></td>
</tr>
<tr>
<td>Vector</td>
<td><i class="fas fa-circle-check text-success"></i> PGVector 0.6</td>
<td style="text-align:center"><i class="fas fa-circle-check text-success"></i> PGVector 0.6</td>
<td style="text-align:center"><i class="fas fa-circle-check text-success"></i> pase 0.0.1</td>
</tr>
<tr>
<td>Sparse Vector</td>
<td><i class="fas fa-circle-check text-success"></i> PG Sparse 0.5.6</td>
<td style="text-align:center"><i class="fas fa-circle-xmark text-danger"></i></td>
<td style="text-align:center"><i class="fas fa-circle-xmark text-danger"></i></td>
</tr>
<tr>
<td>Full-Text Search</td>
<td><i class="fas fa-circle-check text-success"></i> pg_bm25 0.5.6<br /></td>
<td style="text-align:center"><i class="fas fa-circle-xmark text-danger"></i></td>
<td style="text-align:center"><i class="fas fa-circle-xmark text-danger"></i></td>
</tr>
<tr>
<td>Graph</td>
<td><i class="fas fa-circle-check text-success"></i> Apache AGE 1.5.0</td>
<td style="text-align:center"><i class="fas fa-circle-xmark text-danger"></i></td>
<td style="text-align:center"><i class="fas fa-circle-xmark text-danger"></i></td>
</tr>
<tr>
<td>GraphQL</td>
<td><i class="fas fa-circle-check text-success"></i> PG GraphQL 1.5.0</td>
<td style="text-align:center"><i class="fas fa-circle-xmark text-danger"></i></td>
<td style="text-align:center"><i class="fas fa-circle-xmark text-danger"></i></td>
</tr>
<tr>
<td>Message Queue</td>
<td><i class="fas fa-circle-check text-success"></i> pgq 3.5.0</td>
<td style="text-align:center"><i class="fas fa-circle-xmark text-danger"></i></td>
<td style="text-align:center"><i class="fas fa-circle-xmark text-danger"></i></td>
</tr>
<tr>
<td>OLAP</td>
<td><i class="fas fa-circle-check text-success"></i> pg_analytics 0.5.6</td>
<td style="text-align:center"><i class="fas fa-circle-xmark text-danger"></i></td>
<td style="text-align:center"><i class="fas fa-circle-xmark text-danger"></i></td>
</tr>
<tr>
<td>DuckDB</td>
<td><i class="fas fa-circle-check text-success"></i> duckdb_fdw 1.1</td>
<td style="text-align:center"><i class="fas fa-circle-xmark text-danger"></i></td>
<td style="text-align:center"><i class="fas fa-circle-xmark text-danger"></i></td>
</tr>
<tr>
<td>CDC</td>
<td><i class="fas fa-circle-check text-success"></i> wal2json 2.5.3</td>
<td style="text-align:center"><i class="fas fa-circle-check text-success"></i> wal2json 2.5</td>
<td style="text-align:center"><i class="fas fa-circle-xmark text-danger"></i></td>
</tr>
<tr>
<td>Bloat Control</td>
<td><i class="fas fa-circle-check text-success"></i> pg_repack 1.5.0</td>
<td style="text-align:center"><i class="fas fa-circle-check text-success"></i> pg_repack 1.5.0</td>
<td style="text-align:center"><i class="fas fa-circle-check text-success"></i> pg_repack 1.4.8</td>
</tr>
<tr>
<td>Point Cloud</td>
<td><i class="fas fa-circle-check text-success"></i> PG PointCloud 1.2.5</td>
<td style="text-align:center"><i class="fas fa-circle-xmark text-danger"></i></td>
<td style="text-align:center"><i class="fas fa-circle-check text-success"></i> Ganos PointCloud 6.1</td>
</tr>
</tbody>
</table>
<p>Many important extensions are not available on Cloud RDS (PG 16, 2024-02-29)</p>
</blockquote>
<p>Extensions are the soul of PostgreSQL. A Postgres without the freedom to use extensions is like cooking without salt, a giant constrained.</p>
<p>Addressing this issue is one of our primary goals.</p>
<hr>
<h2 id="our-resolution-pigsty">Our Resolution: Pigsty</h2>
<p>Despite earlier exposure to MySQL Oracle, and MSSQL, when I first used PostgreSQL in 2015, I was convinced of its future dominance in the database realm. Nearly a decade later, I’ve transitioned from a user and administrator to a contributor and developer, witnessing PG’s march toward that goal.</p>
<p>Interactions with diverse users revealed that the database field&rsquo;s shortcoming isn&rsquo;t the kernel anymore — PostgreSQL is already sufficient. The real issue is <strong>leveraging the kernel’s capabilities</strong>, which is the reason behind RDS’s booming success.</p>
<p>However, I believe this capability should be as accessible as free software, like the PostgreSQL kernel itself — available to every user, not just renting from cyber feudal lords.</p>
<p>Thus, I created <a href="https://pigsty.io/"><strong>Pigsty</strong></a>, a battery-included, local-first PostgreSQL distribution as an open-source <a href="/blog/cloud/rds/">RDS</a> Alternative, which aims to harness the collective power of PostgreSQL ecosystem extensions and democratize access to production-grade database services.</p>
<p><a href="https://pigsty.io"><img alt="img" src="/img/pigsty/homepage.en.png"></a></p>
<blockquote>
<p>Pigsty stands for <strong>P</strong>ostgreSQL <strong>i</strong>n <strong>G</strong>reat <strong>STY</strong>le, representing the zenith of PostgreSQL.</p>
</blockquote>
<p>We’ve defined six core propositions addressing the central issues in PostgreSQL database services:</p>
<p><strong>Extensible Postgres</strong>, <strong>Reliable Infras</strong>, <strong>Observable Graphics</strong>, <strong>Available Services</strong>, <strong>Maintainable Toolbox</strong>, and <strong>Composable Modules</strong>.</p>
<p>The initials of these value propositions offer another acronym for Pigsty:</p>
<blockquote>
<p><strong>P</strong>ostgres, <strong>I</strong>nfras, <strong>G</strong>raphics, <strong>S</strong>ervice, <strong>T</strong>oolbox, <strong>Y</strong>ours.</p>
<p>Your graphical Postgres infrastructure service toolbox.</p>
</blockquote>
<p><strong>Extensible PostgreSQL</strong> is the linchpin of this distribution. In the recently launched <a href="https://github.com/Vonng/pigsty/releases/tag/v2.6.0"><strong>Pigsty v2.6</strong></a>, we integrated DuckDB FDW and ParadeDB extensions, massively boosting PostgreSQL’s analytical capabilities and ensuring every user can easily harness this power.</p>
<p>Our aim is to integrate the strengths within the PostgreSQL ecosystem, creating a synergistic force akin to the <strong>Ubuntu</strong> of the database world. I believe the kernel debate is settled, and the real competitive frontier lies here.</p>
<ul>
<li><a href="https://postgis.net/"><strong>PostGIS</strong></a>: Provides geospatial data types and indexes, the de facto standard for GIS (&amp; <strong>pgPointCloud</strong>, <strong>pgRouting</strong>).</li>
<li><a href="https://www.timescale.com/"><strong>TimescaleDB</strong></a>: Adds time-series, continuous aggregates, distributed, columnar storage, and automatic compression capabilities.</li>
<li><a href="https://github.com/pgvector/pgvector"><strong>PGVector</strong></a>: Support AI vectors/embeddings and ivfflat, hnsw vector indexes (&amp; <strong>pg_sparse</strong> for sparse vectors).</li>
<li><a href="https://www.citusdata.com/"><strong>Citus</strong></a>: Transforms classic master-slave PG clusters into horizontally partitioned distributed database clusters.</li>
<li><a href="https://www.hydra.so/"><strong>Hydra</strong></a>: Adds columnar storage and analytics, rivaling ClickHouse’s analytic capabilities.</li>
<li><a href="https://www.paradedb.com/"><strong>ParadeDB</strong></a>: Elevates full-text search and mixed retrieval to ElasticSearch levels (&amp; <strong>zhparser</strong> for Chinese tokenization).</li>
<li><a href="https://age.apache.org/"><strong>Apache AGE</strong></a>: Graph database extension, adding Neo4J-like OpenCypher query support to PostgreSQL.</li>
<li><a href="https://github.com/supabase/pg_graphql"><strong>PG GraphQL</strong></a>: Adds native built-in GraphQL query language support to PostgreSQL.</li>
<li><a href="https://github.com/alitrack/duckdb_fdw"><strong>DuckDB FDW</strong></a>: Enables direct access to DuckDB’s powerful embedded analytic database files through PostgreSQL (&amp; DuckDB CLI).</li>
<li><a href="https://github.com/Vonng/pigsty/tree/master/app/supabase"><strong>Supabase</strong></a>: An open-source Firebase alternative based on PostgreSQL, providing a complete app development storage solution.</li>
<li><a href="https://github.com/Vonng/pigsty/tree/master/app/ferretdb"><strong>FerretDB</strong></a>: An open-source MongoDB alternative based on PostgreSQL, compatible with MongoDB APIs/drivers.</li>
<li><a href="https://github.com/Vonng/pigsty/tree/master/app/pgml"><strong>PostgresML</strong></a>: Facilitates classic machine learning algorithms, calling, deploying, and training AI models with SQL.</li>
</ul>
<p><a href="https://pigsty.io"><img alt="img" src="/img/pigsty/desc.png"></a></p>
<p>Developers, your choices will shape the future of the database world. I hope my work helps you better utilize the world’s most advanced open-source database kernel: <strong>PostgreSQL</strong>.</p>
<blockquote>
<p><a href="https://pigsty.io/blog/pg/pg-eat-db-world/">Read in Pigsty’s Blog</a> <em>|</em> <a href="https://github.com/Vonng/pigsty">GitHub Repo: Pigsty</a> <em>|</em> <a href="https://pigsty.io/">Official Website</a></p>
</blockquote>

</div>





    
	
  
    
    
	
    


  

<div class="td-content" style="page-break-before: always">
    <h1 id="pg-fe0303de91d0c7a97aa03dbbd71290fa">PostgreSQL Convention 2024</h1>
	
	<div class="td-byline mb-4">
		By <b><a href="https://vonng.com/en/">Ruohang Feng</a> (<a href="https://vonng.com/en/">@Vonng</a>) | <a href="https://mp.weixin.qq.com/s/W1hwbl3qmjC4Dcmadc8uSg">Wechat Column</a></b> |
        
		<time datetime="2023-11-27" class="text-muted">2023-11-27</time>
        
	</div>
	<p><img src="/img/blog/hero/pg-convention.jpg"></p>
<ul>
<li><a href="/blog/pg/pg-convention/#background">Background</a></li>
<li><a href="/blog/pg/pg-convention/#0x01-naming-convention">0x01 Naming Convention</a></li>
<li><a href="/blog/pg/pg-convention/#0x02-design-convention">0x01 Design Convention</a></li>
<li><a href="/blog/pg/pg-convention/#0x03-query-convention">0x01 Query Convention</a></li>
<li><a href="/blog/pg/pg-convention/#0x04-administration-convention">0x01 Admin Convention</a></li>
</ul>
<blockquote>
<p>Roughly translated from <a href="/zh/blog/pg/pg-convention/">PostgreSQL Convention 2024</a> with Google.</p>
</blockquote>
<hr>
<h2 id="0x00-background">0x00 Background</h2>
<blockquote>
<p>No Rules, No Lines</p>
</blockquote>
<p>The functions of PostgreSQL are very powerful, but to use PostgreSQL well requires the cooperation of backend, operation and maintenance, and DBA.</p>
<p>This article has compiled a development/operation and maintenance protocol based on the principles and characteristics of the PostgreSQL database, hoping to reduce the confusion you encounter when using the PostgreSQL database: hello, me, everyone.</p>
<p>The first version of this article is mainly for PostgreSQL 9.4 - PostgreSQL 10. The latest version has been updated and adjusted for PostgreSQL 15/16.</p>
<hr>
<h2 id="0x01-naming-convention">0x01 naming convention</h2>
<blockquote>
<p>There are only two hard problems in computer science: cache invalidation and <strong>naming</strong> .</p>
</blockquote>
<p><strong>Generic naming rules</strong> (Generic)</p>
<ul>
<li>This rule applies to all objects <strong>in the database</strong> , including: library names, table names, index names, column names, function names, view names, serial number names, aliases, etc.</li>
<li>The object name must use only lowercase letters, underscores, and numbers, and the first letter must be a lowercase letter.</li>
<li>The length of the object name must not exceed 63 characters, and the naming <code>snake_case</code>style must be uniform.</li>
<li>The use of SQL reserved words is prohibited, use <code>select pg_get_keywords();</code>to obtain a list of reserved keywords.</li>
<li>Dollar signs are prohibited <code>$</code>, Chinese characters are prohibited, and do not <code>pg</code>begin with .</li>
<li>Improve your wording taste and be honest and elegant; do not use pinyin, do not use uncommon words, and do not use niche abbreviations.</li>
</ul>
<p><strong>Cluster naming rules</strong> (Cluster)</p>
<ul>
<li>The name of the PostgreSQL cluster will be used as the namespace of the cluster resource and must be a valid DNS domain name without any dots or underscores.</li>
<li>The cluster name should start with a lowercase letter, contain only lowercase letters, numbers, and minus signs, and conform to the regular expression: <code>[a-z][a-z0-9-]*</code>.</li>
<li>PostgreSQL database cluster naming usually follows a three-part structure: <code>pg-&lt;biz&gt;-&lt;tld&gt;</code>. Database type/business name/business line or environment</li>
<li><code>biz</code>The English words that best represent the characteristics of the business should only consist of lowercase letters and numbers, and should not contain hyphens <code>-</code>.</li>
<li>When using a backup cluster to build a delayed slave database of an existing cluster, <code>biz</code>the name should be <code>&lt;biz&gt;delay</code>, for example <code>pg-testdelay</code>.</li>
<li>When branching an existing cluster, you can <code>biz</code>add a number at the end of : for example, <code>pg-user1</code>you can branch from <code>pg-user2</code>, <code>pg-user3</code>etc.</li>
<li>For horizontally sharded clusters, <code>biz</code>the name should include <code>shard</code>and be preceded by the shard number, for example <code>pg-testshard1</code>, <code>pg-testshard2</code>,&hellip;</li>
<li><code>&lt;tld&gt;</code>It is the top-level business line and can also be used to distinguish different environments: for example <code>-tt</code>, <code>-dev</code>, <code>-uat</code>, <code>-prod</code>etc. It can be omitted if not required.</li>
</ul>
<p><strong>Service naming rules</strong> (Service)</p>
<ul>
<li>Each PostgreSQL cluster will provide 2 to 6 types of external services, which use fixed naming rules by default.</li>
<li>The service name is prefixed with the cluster name and the service type is suffixed, for example <code>pg-test-primary</code>, <code>pg-test-replica</code>.</li>
<li>Read-write services are uniformly <code>primary</code>named with the suffix, and read-only services are uniformly <code>replica</code>named with the suffix. These two services are required.</li>
<li>ETL pull/individual user query is <code>offline</code>named with the suffix, and direct connection to the main database/ETL write is <code>default</code>named with the suffix, which is an optional service.</li>
<li>The synchronous read service is <code>standby</code>named with the suffix, and the delayed slave library service is <code>delayed</code>named with the suffix. A small number of core libraries can provide this service.</li>
</ul>
<p><strong>Instance naming rules</strong> (Instance)</p>
<ul>
<li>A PostgreSQL cluster consists of at least one instance, and each instance has a unique instance number assigned from zero or one within the cluster.</li>
<li><strong>The instance name</strong><code>-</code> is composed of the cluster name + instance number with hyphens , for example: <code>pg-test-1</code>, <code>pg-test-2</code>.</li>
<li>Once assigned, the instance number cannot be modified until the instance is offline and destroyed, and cannot be reassigned for use.</li>
<li>The instance name will be used as a label for monitoring system data <code>ins</code>and will be attached to all data of this instance.</li>
<li>If you are using a host/database 1:1 exclusive deployment, the node Hostname can use the database instance name.</li>
</ul>
<p><strong>Database naming rules</strong> (Database)</p>
<ul>
<li>The database name should be consistent with the cluster and application, and must be a highly distinguishable English word.</li>
<li>The naming is <code>&lt;tld&gt;_&lt;biz&gt;</code>constructed in the form of , <code>&lt;tld&gt;</code>which is the top-level business line. It can also be used to distinguish different environments and can be omitted if not used.</li>
<li><code>&lt;biz&gt;</code>For a specific business name, for example, <code>pg-test-tt</code>the cluster can use the library name <code>tt_test</code>or <code>test</code>. This is not mandatory, i.e. it is allowed to create <code>&lt;biz&gt;</code>other databases with different cluster names.</li>
<li>For sharded libraries, <code>&lt;biz&gt;</code>the section must <code>shard</code>end with but <strong>should not</strong> contain the shard number, for example <code>pg-testshard1</code>, <code>pg-testshard2</code>both <code>testshard</code>should be used.</li>
<li>Multiple parts use <code>-</code>joins. For example: <code>&lt;biz&gt;-chat-shard</code>, <code>&lt;biz&gt;-payment</code>etc., no more than three paragraphs in total.</li>
</ul>
<p><strong>Role naming convention</strong> (Role/User)</p>
<ul>
<li><code>dbsu</code>There is only one database super user : <code>postgres</code>, the user used for streaming replication is named <code>replicator</code>.</li>
<li>The users used for monitoring are uniformly named <code>dbuser_monitor</code>, and the super users used for daily management are: <code>dbuser_dba</code>.</li>
<li>The business user used by the program/service defaults to using <code>dbuser_&lt;biz&gt;</code>as the username, for example <code>dbuser_test</code>. Access from different services should be differentiated using separate business users.</li>
<li>The database user applied for by the individual user agrees to use <code>dbp_&lt;name&gt;</code>, where is <code>name</code>the standard user name in LDAP.</li>
<li>The default permission group naming is fixed as: <code>dbrole_readonly</code>, <code>dbrole_readwrite</code>, <code>dbrole_admin</code>, <code>dbrole_offline</code>.</li>
</ul>
<p><strong>Schema naming rules</strong> (Schema)</p>
<ul>
<li>The business uniformly uses a global <code>&lt;prefix&gt;</code>as the schema name, as short as possible, and is set to <code>search_path</code>the first element by default.</li>
<li><code>&lt;prefix&gt;</code>You must not use <code>public</code>, <code>monitor</code>, and must not conflict with any schema name used by PostgreSQL extensions, such as: <code>timescaledb</code>, <code>citus</code>, <code>repack</code>, <code>graphql</code>, <code>net</code>, <code>cron</code>,&hellip; It is not appropriate to use special names: <code>dba</code>, <code>trash</code>.</li>
<li>Sharding mode naming rules adopt: <code>rel_&lt;partition_total_num&gt;_&lt;partition_index&gt;</code>. The middle is the total number of shards, which is currently fixed at 8192. The suffix is the shard number, counting from 0. Such as <code>rel_8192_0</code>,&hellip;,,, <code>rel_8192_11</code>etc.</li>
<li>Creating additional schemas, or using <code>&lt;prefix&gt;</code>schema names other than , will require R&amp;D to explain their necessity.</li>
</ul>
<p><strong>Relationship naming rules</strong> (Relation)</p>
<ul>
<li>The first priority for relationship naming is to have clear meaning. Do not use ambiguous abbreviations or be too lengthy. Follow general naming rules.</li>
<li>Table names should use <strong>plural nouns</strong> and be consistent with historical conventions. Words with irregular plural forms should be avoided as much as possible.</li>
<li>Views use <code>v_</code>as the naming prefix, materialized views use <code>mv_</code>as the naming prefix, temporary tables use <code>tmp_</code>as the naming prefix.</li>
<li>Inherited or partitioned tables should be prefixed by the parent table name and suffixed by the child table attributes (rules, shard ranges, etc.).</li>
<li>The time range partition uses the starting interval as the naming suffix. If the first partition has no upper bound, the R&amp;D will specify a far enough time point: grade partition: <code>tbl_2023</code>, month-level partition <code>tbl_202304</code>, day-level partition <code>tbl_20230405</code>, hour-level partition <code>tbl_2023040518</code>. The default partition <code>_default</code>ends with .</li>
<li>The hash partition is named with the remainder as the suffix of the partition table name, and the list partition is manually specified by the R&amp;D team with a reasonable partition table name corresponding to the list item.</li>
</ul>
<p><strong>Index naming rules</strong> (Index)</p>
<ul>
<li>When creating an index, the index name should be <strong>specified explicitly</strong> and consistent with the PostgreSQL default naming rules.</li>
<li>Index names are prefixed with the table name, primary key indexes <code>_pkey</code>end with , unique indexes <code>_key</code>end with , ordinary indexes end <code>_idx</code>with , and indexes used for <code>EXCLUDED</code>constraints <code>_excl</code>end with .</li>
<li>When using conditional index/function index, the function and condition content used should be reflected in the index name. For example <code>tbl_md5_title_idx</code>, <code>tbl_ts_ge_2023_idx</code>, but the length limit cannot be exceeded.</li>
</ul>
<p><strong>Field naming rules</strong> (Attribute)</p>
<ul>
<li>It is prohibited to use system column reserved field names: <code>oid</code>, <code>xmin</code>, <code>xmax</code>, <code>cmin</code>, <code>cmax</code>, <code>ctid</code>.</li>
<li>Primary key columns are usually named with <code>id</code>or as <code>id</code>a suffix.</li>
<li>The conventional name is the creation time field <code>created_time</code>, and the conventional name is the last modification time field.<code>updated_time</code></li>
<li><code>is_</code>It is recommended to use , etc. as the prefix for Boolean fields <code>has_</code>.</li>
<li>Additional flexible JSONB fields are fixed using <code>extra</code>as column names.</li>
<li>The remaining field names must be consistent with existing table naming conventions, and any field naming that breaks conventions should be accompanied by written design instructions and explanations.</li>
</ul>
<p><strong>Enumeration item naming</strong> (Enum)</p>
<ul>
<li>Enumeration items should be used by default <code>camelCase</code>, but other styles are allowed.</li>
</ul>
<p><strong>Function naming rules</strong> (Function)</p>
<ul>
<li>Function names start with verbs: <code>select</code>, <code>insert</code>, <code>delete</code>, <code>update</code>, <code>upsert</code>, <code>create</code>,….</li>
<li>Important parameters can be reflected in the function name through <code>_by_ids</code>the <code>_by_user_ids</code>suffix of.</li>
<li>Avoid function overloading and try to keep only one function with the same name.</li>
<li><code>BIGINT/INTEGER/SMALLINT</code>It is forbidden to overload function signatures through integer types such as , which may cause ambiguity when calling.</li>
<li>Use named parameters for variables in stored procedures and functions, and avoid positional parameters ( <code>$1</code>, <code>$2</code>,&hellip;).</li>
<li>If the parameter name conflicts with the object name, add before the parameter <code>_</code>, for example <code>_user_id</code>.</li>
</ul>
<p><strong>Comment specifications</strong> (Comment)</p>
<ul>
<li>Try your best to provide comments ( <code>COMMENT</code>) for various objects. Comments should be in English, concise and concise, and one line should be used.</li>
<li>When the object&rsquo;s schema or content semantics change, be sure to update the annotations to keep them in sync with the actual situation.</li>
</ul>
<hr>
<h2 id="0x02-design-convention">0x02 Design Convention</h2>
<blockquote>
<p>To each his own</p>
</blockquote>
<p><strong>Things to note when creating a table</strong></p>
<ul>
<li>The DDL statement for creating a table needs to use the standard format, with SQL keywords in uppercase letters and other words in lowercase letters.</li>
<li>Use lowercase letters uniformly in field names/table names/aliases, and try not to be case-sensitive. If you encounter a mixed case, or a name that conflicts with SQL keywords, you need to use double quotation marks for quoting.</li>
<li>Use specialized type (NUMERIC, ENUM, INET, MONEY, JSON, UUID, &hellip;) if applicable, and avoid using <code>TEXT</code> type as much as possible. The <code>TEXT</code> type is not conducive to the database&rsquo;s understanding of the data. Use these types to improve data storage, query, indexing, and calculation efficiency, and improve maintainability.</li>
<li>Optimizing column layout and alignment types can have additional performance/storage gains.</li>
<li>Unique constraints must be guaranteed by the database, and any unique column must have a corresponding unique constraint. <code>EXCLUDE</code>Constraints are generalized unique constraints that can be used to ensure data integrity in low-frequency update scenarios.</li>
</ul>
<p><strong>Partition table considerations</strong></p>
<ul>
<li>If a single table exceeds hundreds of TB, or the monthly incremental data exceeds more than ten GB, you can consider table partitioning.</li>
<li>A guideline for partitioning is to keep the size of each partition within the comfortable range of 1GB to 64GB.</li>
<li>Tables that are conditionally partitioned by time range are first partitioned by time range. Commonly used granularities include: decade, year, month, day, and hour. The partitions required in the future should be created at least three months in advance.</li>
<li>For extremely skewed data distributions, different time granularities can be combined, for example: 1900 - 2000 as one large partition, 2000 - 2020 as year partitions, and after 2020 as month partitions. When using time partitioning, the table name uses the value of the lower limit of the partition (if infinity, use a value that is far enough back).</li>
</ul>
<p><strong>Notes on wide tables</strong></p>
<ul>
<li>Wide tables (for example, tables with dozens of fields) can be considered for vertical splitting, with mutual references to the main table through the same primary key.</li>
<li>Because of the PostgreSQL MVCC mechanism, the write amplification phenomenon of wide tables is more obvious, reducing frequent updates to wide tables.</li>
<li>In Internet scenarios, it is allowed to appropriately lower the normalization level and reduce multi-table connections to improve performance.</li>
</ul>
<p><strong>Primary key considerations</strong></p>
<ul>
<li>Every table <strong>must</strong> have <strong>an identity column</strong> , and in principle it must have a primary key. The minimum requirement is to have <strong>a non-null unique constraint</strong> .</li>
<li>The identity column is used to uniquely identify any tuple in the table, and logical replication and many third-party tools depend on it.</li>
<li>If the primary key contains multiple columns, it should be specified using a single column after creating the field list of the table DDL <code>PRIMARY KEY(a,b,...)</code>.</li>
<li>In principle, it is recommended to use integer <code>UUID</code>types for primary keys, which can be used with caution and text types with limited length. Using other types requires explicit explanation and evaluation.</li>
<li>The primary key usually uses a single integer column. In principle, it is recommended to use it <code>BIGINT</code>. Use it with caution <code>INTEGER</code>and it is not allowed <code>SMALLINT</code>.</li>
<li>The primary key should be used to <code>GENERATED ALWAYS AS IDENTITY</code>generate a unique primary key; <code>SERIAL</code>, <code>BIGSERIAL</code>which is only allowed when compatibility with PG versions below 10 is required.</li>
<li>The primary key can use <code>UUID</code>the type as the primary key, and it is recommended to use UUID v1/v7; use UUIDv4 as the primary key with caution, as random UUID has poor locality and has a collision probability.</li>
<li>When using a string column as a primary key, you should add a length limit. Generally used <code>VARCHAR(64)</code>, use of longer strings should be explained and evaluated.</li>
<li><code>INSERT/UPDATE</code>In principle, it is forbidden to modify the value of the primary key column, and <code>INSERT RETURNING</code> it can be used to return the automatically generated primary key value.</li>
</ul>
<p><strong>Foreign key considerations</strong></p>
<ul>
<li>When defining a foreign key, the reference must explicitly set the corresponding action: <code>SET NULL</code>, <code>SET DEFAULT</code>, <code>CASCADE</code>, and use cascading operations with caution.</li>
<li>The columns referenced by foreign keys need to be primary key columns in other tables/this table.</li>
<li>Internet businesses, especially partition tables and horizontal shard libraries, use foreign keys with caution and can be solved at the application layer.</li>
</ul>
<p><strong>Null/Default Value Considerations</strong></p>
<ul>
<li>If there is no distinction between zero and null values in the field semantics, null values are not allowed and <code>NOT NULL</code>constraints must be configured for the column.</li>
<li>If a field has a default value semantically, <code>DEFAULT</code>the default value should be configured.</li>
</ul>
<p><strong>Numeric type considerations</strong></p>
<ul>
<li>Used for regular numeric fields <code>INTEGER</code>. Used for numeric columns whose capacity is uncertain <code>BIGINT</code>.</li>
<li>Don&rsquo;t use it without special reasons <code>SMALLINT</code>. The performance and storage improvements are very small, but there will be many additional problems.</li>
<li>Note that the SQL standard does not provide unsigned integers, and values exceeding <code>INTMAX</code>but not exceeding <code>UINTMAX</code>need to be upgraded and stored. Do not store more <code>INT64MAX</code>values in <code>BIGINT</code>the column as it will overflow into negative numbers.</li>
<li><code>REAL</code>Represents a 4-byte floating point number, <code>FLOAT</code>represents an 8-byte floating point number. Floating point numbers can only be used in scenarios where the final precision doesn&rsquo;t matter, such as geographic coordinates. <strong>Remember not to use equality judgment on floating point numbers, except for zero values</strong> .</li>
<li>Use exact numeric types <code>NUMERIC</code>. If possible, use <code>NUMERIC(p)</code>and <code>NUMERIC(p,s)</code>to set the number of significant digits and the number of significant digits in the decimal part. For example, the temperature in Celsius ( <code>37.0</code>) can <code>NUMERIC(3,1)</code>be stored with 3 significant digits and 1 decimal place using type.</li>
<li>Currency value type is used <code>MONEY</code>.</li>
</ul>
<p><strong>Text type considerations</strong></p>
<ul>
<li>PostgreSQL text types include <code>char(n)</code>, <code>varchar(n)</code>, <code>text</code>. By default, <code>text</code>the type can be used, which does not limit the string length, but is limited by the maximum field length of 1GB.</li>
<li>If conditions permit, it is preferable to use <code>varchar(n)</code>the type to set a maximum string length. This will introduce minimal additional checking overhead, but can avoid some dirty data and corner cases.</li>
<li>Avoid use <code>char(n)</code>, this type has unintuitive behavior (padding spaces and truncation) and has no storage or performance advantages in order to be compatible with the SQL standard.</li>
</ul>
<p><strong>Time type considerations</strong></p>
<ul>
<li>There are only two ways to store time: with time zone <code>TIMESTAMPTZ</code>and without time zone <code>TIMESTAMP</code>.</li>
<li>It is recommended to use one with time zone <code>TIMESTAMPTZ</code>. If you use <code>TIMESTAMP</code>storage, you must use 0 time zone standard time.</li>
<li>Please use it to generate 0 time zone time <code>now() AT TIME ZONE 'UTC'</code>. You cannot truncate the time zone directly <code>now()::TIMESTAMP</code>.</li>
<li>Uniformly use ISO-8601 format input and output time type: <code>2006-01-02 15:04:05</code>to avoid DMY and MDY problems.</li>
<li>Users in China can use <code>Asia/Hong_Kong</code>the +8 time zone uniformly because the Shanghai time zone abbreviation <code>CST</code>is ambiguous.</li>
</ul>
<p><strong>Notes on enumeration types</strong></p>
<ul>
<li>Fields that are more stable and have a small value space (within tens to hundreds) should use enumeration types instead of integers and strings.</li>
<li>Enumerations are internally implemented using dynamic integers, which have readability advantages over integers and performance, storage, and maintainability advantages over strings.</li>
<li>Enumeration items can only be added, not deleted, but existing enumeration values can be renamed. <code>ALTER TYPE &lt;enum_name&gt;</code>Used to modify enumerations.</li>
</ul>
<p><strong>UUID type considerations</strong></p>
<ul>
<li>Please note that the fully random UUIDv4 has poor locality when used as a primary key. Consider using UUIDv1/v7 instead if possible.</li>
<li>Some UUID generation/processing functions require additional extension plug-ins, such as <code>uuid-ossp</code>, <code>pg_uuidv7</code> etc. If you have this requirement, please specify it during configuration.</li>
</ul>
<p><strong>JSON type considerations</strong></p>
<ul>
<li>Unless there is a special reason, always use the binary storage <code>JSONB</code>type and related functions instead of the text version <code>JSON</code>.</li>
<li>Note the subtle differences between atomic types in JSON and their PostgreSQL counterparts: the zero character <code>text</code>is not allowed in the type corresponding to a JSON string <code>\u0000</code>, and the and <code>numeric</code>is not allowed in the type corresponding to a JSON numeric type . Boolean values only accept lowercase and literal values.<code>NaN``infinity``true``false</code></li>
<li>Please note that objects in the JSON standard <code>null</code>and null values in the SQL standard <code>NULL</code> are not the same concept.</li>
</ul>
<p><strong>Array type considerations</strong></p>
<ul>
<li>When storing a small number of elements, array fields can be used instead of individually.</li>
<li>Suitable for storing data with a relatively small number of elements and infrequent changes. If the number of elements in the array is very large or changes frequently, consider using a separate table to store the data and using foreign key associations.</li>
<li>For high-dimensional floating-point arrays, consider using <code>pgvector</code>the dedicated data types provided by the extension.</li>
</ul>
<p><strong>GIS type considerations</strong></p>
<ul>
<li>The GIS type uses the srid=4326 reference coordinate system by default.</li>
<li>Longitude and latitude coordinate points should use the Geography type without explicitly specifying the reference system coordinates 4326</li>
</ul>
<p><strong>Trigger considerations</strong></p>
<ul>
<li>Triggers will increase the complexity and maintenance cost of the database system, and their use is discouraged in principle. The use of rule systems is prohibited and such requirements should be replaced by triggers.</li>
<li>Typical scenarios for triggers are to automatically modify a row to the current timestamp after modifying it <code>updated_time</code>, or to record additions, deletions, and modifications of a table to another log table, or to maintain business consistency between the two tables.</li>
<li>Operations in triggers are transactional, meaning if the trigger or operations in the trigger fail, the entire transaction is rolled back, so test and prove the correctness of your triggers thoroughly. Special attention needs to be paid to recursive calls, deadlocks in complex query execution, and the execution sequence of multiple triggers.</li>
</ul>
<p><strong>Stored procedure/function considerations</strong></p>
<ul>
<li>
<p>Functions/stored procedures are suitable for encapsulating transactions, reducing concurrency conflicts, reducing network round-trips, reducing the amount of returned data, and executing <strong>a small amount</strong> of custom logic.</p>
</li>
<li>
<p>Stored procedures <strong>are not suitable</strong> for complex calculations, and are not suitable for trivial/frequent type conversion and packaging. In critical high-load systems, <strong>unnecessary</strong> computationally intensive logic in the database should be removed, such as using SQL in the database to convert WGS84 to other coordinate systems. Calculation logic closely related to data acquisition and filtering can use functions/stored procedures: for example, geometric relationship judgment in PostGIS.</p>
</li>
<li>
<p>Replaced functions and stored procedures that are no longer in use should be taken offline in a timely manner to avoid conflicts with future functions.</p>
</li>
<li>
<p>Use a unified syntax format for function creation. The signature occupies a separate line (function name and parameters), the return value starts on a separate line, and the language is the first label. Be sure to mark the function volatility level: <code>IMMUTABLE</code>, <code>STABLE</code>, <code>VOLATILE</code>. Add attribute tags, such as: <code>RETURNS NULL ON NULL INPUT</code>, <code>PARALLEL SAFE</code>, <code>ROWS 1</code>etc.</p>
<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sql" data-lang="sql"><span style="display:flex;"><span><span style="color:#204a87;font-weight:bold">CREATE</span><span style="color:#f8f8f8;text-decoration:underline"> </span><span style="color:#204a87;font-weight:bold">OR</span><span style="color:#f8f8f8;text-decoration:underline"> </span><span style="color:#204a87;font-weight:bold">REPLACE</span><span style="color:#f8f8f8;text-decoration:underline"> </span><span style="color:#204a87;font-weight:bold">FUNCTION</span><span style="color:#f8f8f8;text-decoration:underline">
</span></span></span><span style="display:flex;"><span><span style="color:#f8f8f8;text-decoration:underline">  </span><span style="color:#000">nspname</span><span style="color:#000;font-weight:bold">.</span><span style="color:#000">myfunc</span><span style="color:#000;font-weight:bold">(</span><span style="color:#000">arg1_</span><span style="color:#f8f8f8;text-decoration:underline"> </span><span style="color:#204a87">TEXT</span><span style="color:#000;font-weight:bold">,</span><span style="color:#f8f8f8;text-decoration:underline"> </span><span style="color:#000">arg2_</span><span style="color:#f8f8f8;text-decoration:underline"> </span><span style="color:#204a87">INTEGER</span><span style="color:#000;font-weight:bold">)</span><span style="color:#f8f8f8;text-decoration:underline">
</span></span></span><span style="display:flex;"><span><span style="color:#f8f8f8;text-decoration:underline">  </span><span style="color:#204a87;font-weight:bold">RETURNS</span><span style="color:#f8f8f8;text-decoration:underline"> </span><span style="color:#000">VOID</span><span style="color:#f8f8f8;text-decoration:underline">
</span></span></span><span style="display:flex;"><span><span style="color:#f8f8f8;text-decoration:underline"></span><span style="color:#204a87;font-weight:bold">LANGUAGE</span><span style="color:#f8f8f8;text-decoration:underline"> </span><span style="color:#204a87;font-weight:bold">SQL</span><span style="color:#f8f8f8;text-decoration:underline">
</span></span></span><span style="display:flex;"><span><span style="color:#f8f8f8;text-decoration:underline"></span><span style="color:#204a87;font-weight:bold">STABLE</span><span style="color:#f8f8f8;text-decoration:underline">
</span></span></span><span style="display:flex;"><span><span style="color:#f8f8f8;text-decoration:underline"></span><span style="color:#000">PARALLEL</span><span style="color:#f8f8f8;text-decoration:underline"> </span><span style="color:#000">SAFE</span><span style="color:#f8f8f8;text-decoration:underline">
</span></span></span><span style="display:flex;"><span><span style="color:#f8f8f8;text-decoration:underline"></span><span style="color:#204a87;font-weight:bold">ROWS</span><span style="color:#f8f8f8;text-decoration:underline"> </span><span style="color:#0000cf;font-weight:bold">1</span><span style="color:#f8f8f8;text-decoration:underline">
</span></span></span><span style="display:flex;"><span><span style="color:#f8f8f8;text-decoration:underline"></span><span style="color:#204a87;font-weight:bold">RETURNS</span><span style="color:#f8f8f8;text-decoration:underline"> </span><span style="color:#204a87;font-weight:bold">NULL</span><span style="color:#f8f8f8;text-decoration:underline"> </span><span style="color:#204a87;font-weight:bold">ON</span><span style="color:#f8f8f8;text-decoration:underline"> </span><span style="color:#204a87;font-weight:bold">NULL</span><span style="color:#f8f8f8;text-decoration:underline"> </span><span style="color:#204a87;font-weight:bold">INPUT</span><span style="color:#f8f8f8;text-decoration:underline">
</span></span></span><span style="display:flex;"><span><span style="color:#f8f8f8;text-decoration:underline"></span><span style="color:#204a87;font-weight:bold">AS</span><span style="color:#f8f8f8;text-decoration:underline"> </span><span style="color:#a40000">$</span><span style="color:#204a87;font-weight:bold">function</span><span style="color:#a40000">$</span><span style="color:#f8f8f8;text-decoration:underline">
</span></span></span><span style="display:flex;"><span><span style="color:#f8f8f8;text-decoration:underline"></span><span style="color:#204a87;font-weight:bold">SELECT</span><span style="color:#f8f8f8;text-decoration:underline"> </span><span style="color:#0000cf;font-weight:bold">1</span><span style="color:#000;font-weight:bold">;</span><span style="color:#f8f8f8;text-decoration:underline">
</span></span></span><span style="display:flex;"><span><span style="color:#f8f8f8;text-decoration:underline"></span><span style="color:#a40000">$</span><span style="color:#204a87;font-weight:bold">function</span><span style="color:#a40000">$</span><span style="color:#000;font-weight:bold">;</span><span style="color:#f8f8f8;text-decoration:underline">
</span></span></span></code></pre></div></li>
</ul>
<p><strong>Use sensible Locale options</strong></p>
<ul>
<li>Used by default <code>en_US.UTF8</code>and cannot be changed without special reasons.</li>
<li>The default <code>collate</code>rule must be <code>C</code>, to avoid string indexing problems.</li>
<li><a href="https://mp.weixin.qq.com/s/SEXcyRFmdXNI7rpPUB3Zew">https://mp.weixin.qq.com/s/SEXcyRFmdXNI7rpPUB3Zew</a></li>
</ul>
<p><strong>Use reasonable character encoding and localization configuration</strong></p>
<ul>
<li>Character encoding must be used <code>UTF8</code>, any other character encoding is strictly prohibited.</li>
<li>Must be used <code>C</code>as <code>LC_COLLATE</code>the default collation, any special requirements must be explicitly specified in the DDL/query clause to implement.</li>
<li>Character set <code>LC_CTYPE</code>is used by default <code>en_US.UTF8</code>, some extensions rely on character set information to work properly, such as <code>pg_trgm</code>.</li>
</ul>
<p><strong>Notes on indexing</strong></p>
<ul>
<li>All online queries must design corresponding indexes according to their access patterns, and full table scans are not allowed except for very small tables.</li>
<li>Indexes have a price, and it is not allowed to create unused indexes. Indexes that are no longer used should be cleaned up in time.</li>
<li>When building a joint index, columns with high differentiation and selectivity should be placed first, such as ID, timestamp, etc.</li>
<li>GiST index can be used to solve the nearest neighbor query problem, and traditional B-tree index cannot provide good support for KNN problem.</li>
<li>For data whose values are linearly related to the storage order of the heap table, if the usual query is a range query, it is recommended to use the BRIN index. The most typical scenario is to only append written time series data. BRIN index is more efficient than Btree.</li>
<li>When retrieving against JSONB/array fields, you can use GIN indexes to speed up queries.</li>
</ul>
<p><strong>Clarify the order of null values in B-tree indexes</strong></p>
<ul>
<li><code>NULLS FIRST</code>If there is a sorting requirement on a nullable column, it needs to be explicitly specified in the query and index <code>NULLS LAST</code>.</li>
<li>Note that <code>DESC</code>the default rule for sorting is <code>NULLS FIRST</code>that null values appear first in the sort, which is generally not desired behavior.</li>
<li>The sorting conditions of the index must match the query, such as:<code>CREATE INDEX ON tbl (id DESC NULLS LAST);</code></li>
</ul>
<p><strong>Disable indexing on large fields</strong></p>
<ul>
<li>The size of the indexed field cannot exceed 2KB (1/3 of the page capacity). You need to be careful when creating indexes on text types. The text to be indexed should use <code>varchar(n)</code>types with length constraints.</li>
<li>When a text type is used as a primary key, a maximum length must be set. In principle, the length should not exceed 64 characters. In special cases, the evaluation needs to be explicitly stated.</li>
<li>If there is a need for large field indexing, you can consider hashing the large field and establishing a function index. Or use another type of index (GIN).</li>
</ul>
<p><strong>Make the most of functional indexes</strong></p>
<ul>
<li>Any redundant fields that can be inferred from other fields in the same row can be replaced using functional indexes.</li>
<li>For statements that often use expressions as query conditions, you can use expression or function indexes to speed up queries.</li>
<li>Typical scenario: Establish a hash function index on a large field, and establish a <code>reverse</code>function index for text columns that require left fuzzy query.</li>
</ul>
<p><strong>Take advantage of partial indexes</strong></p>
<ul>
<li>For the part of the query where the query conditions are fixed, partial indexes can be used to reduce the index size and improve query efficiency.</li>
<li>If a field to be indexed in a query has only a limited number of values, several corresponding partial indexes can also be established.</li>
<li>If the columns in some indexes are frequently updated, please pay attention to the expansion of these indexes.</li>
</ul>
<hr>
<h2 id="0x03-query-convention">0x03 Query Convention</h2>
<blockquote>
<p>The limits of my language mean the limits of my world.</p>
<p>—Ludwig Wittgenstein</p>
</blockquote>
<p><strong>Use service access</strong></p>
<ul>
<li>Access to the production database must be through domain name access <a href="https://doc.pigsty.cc/#/zh/PGSQL-SVC">services</a> , and direct connection using IP addresses is strictly prohibited.</li>
<li>VIP is used for services and access, LVS/HAProxy shields the role changes of cluster instance members, and master-slave switching does not require application restart.</li>
</ul>
<p><strong>Read and write separation</strong></p>
<ul>
<li>Internet business scenario: Write requests must go through the main library and be accessed through the Primary service.</li>
<li>In principle, read requests go from the slave library and are accessed through the Replica service.</li>
<li>Exceptions: If you need &ldquo;Read Your Write&rdquo; consistency guarantees, and significant replication delays are detected, read requests can access the main library; or apply to the DBA to provide Standby services.</li>
</ul>
<p><strong>Separation of speed and slowness</strong></p>
<ul>
<li>Queries within 1 millisecond in production are called fast queries, and queries that exceed 1 second in production are called slow queries.</li>
<li>Slow queries must go to the offline slave database - Offline service/instance, and a timeout should be set during execution.</li>
<li>In principle, the execution time of online general queries in production should be controlled within 1ms.</li>
<li>If the execution time of an online general query in production exceeds 10ms, the technical solution needs to be modified and optimized before going online.</li>
<li>Online queries should be configured with a Timeout of the order of 10ms or faster to avoid avalanches caused by accumulation.</li>
<li>ETL data from the primary is prohibited, and the offline service should be used to retrieve data from a dedicated instance.</li>
</ul>
<p><strong>Use connection pool</strong></p>
<ul>
<li>Production applications must access the database through a connection pool and the PostgreSQL database through a 1:1 deployed Pgbouncer proxy. Offline service, individual users are strictly prohibited from using the connection pool directly.</li>
<li>Pgbouncer connection pool uses Transaction Pooling mode by default. Some session-level functions may not be available (such as Notify/Listen), so special attention is required. Pre-1.21 Pgbouncer does not support the use of Prepared Statements in this mode. In special scenarios, you can use Session Pooling or bypass the connection pool to directly access the database, which requires special DBA review and approval.</li>
<li>When using a connection pool, it is prohibited to modify the connection status, including modifying connection parameters, modifying search paths, changing roles, and changing databases. The connection must be completely destroyed after modification as a last resort. Putting the changed connection back into the connection pool will lead to the spread of contamination. Use of pg_dump to dump data via Pgbouncer is strictly prohibited.</li>
</ul>
<p><strong>Configure active timeout for query statements</strong></p>
<ul>
<li>Applications should configure active timeouts for all statements and proactively cancel requests after timeout to avoid avalanches. (Go context)</li>
<li>Statements that are executed periodically must be configured with a timeout smaller than the execution period to avoid avalanches.</li>
<li>HAProxy is configured with a default connection timeout of 24 hours for rolling expired long connections. Please do not run SQL that takes more than 1 day to execute on offline instances. This requirement will be specially adjusted by the DBA.</li>
</ul>
<p><strong>Pay attention to replication latency</strong></p>
<ul>
<li>Applications must be aware of synchronization delays between masters and slaves and properly handle situations where replication delays exceed reasonable limits.</li>
<li>Under normal circumstances, replication delays are on the order of 100µs/tens of KB, but in extreme cases, slave libraries may experience replication delays of minutes/hours. Applications should be aware of this phenomenon and have corresponding degradation plans - Select Read from the main library and try again later, or report an error directly.</li>
</ul>
<p><strong>Retry failed transactions</strong></p>
<ul>
<li><strong>Queries</strong> may be killed due to concurrency contention, administrator commands, etc. Applications need to be aware of this and retry if necessary.</li>
<li>When the application reports a large number of errors in the database, it can trigger the circuit breaker to avoid an avalanche. But be careful to distinguish the type and nature of errors.</li>
</ul>
<p><strong>Disconnected and reconnected</strong></p>
<ul>
<li>The database <strong>connection</strong> may be terminated for various reasons, and the application <strong>must</strong> have a disconnection reconnection mechanism.</li>
<li>It can be used <code>SELECT 1</code>as a heartbeat packet query to detect the presence of messages on the connection and keep it alive periodically.</li>
</ul>
<p><strong>Online service application code prohibits execution of DDL</strong></p>
<ul>
<li>It is strictly forbidden to execute DDL in production applications and do not make big news in the application code.</li>
<li>Exception scenario: Creating new time partitions for partitioned tables can be carefully managed by the application.</li>
<li>Special exception: Databases used by office systems, such as Gitlab/Jira/Confluence, etc., can grant application DDL permissions.</li>
</ul>
<p><strong>SELECT statement explicitly specifies column names</strong></p>
<ul>
<li>Avoid using it <code>SELECT *</code>, or <code>RETURNING</code>use it in a clause <code>*</code>. Please use a specific field list and do not return unused fields. When the table structure changes (for example, a new value column), queries that use column wildcards are likely to encounter column mismatch errors.</li>
<li>After the fields of some tables are maintained, the order will change. For example: after <code>id</code>upgrading the INTEGER primary key to <code>BIGINT</code>, <code>id</code>the column order will be the last column. This problem can only be fixed during maintenance and migration. R&amp;D developers should resist the compulsion to adjust the column order and explicitly specify the column order in the SELECT statement.</li>
<li>Exception: Wildcards are allowed when a stored procedure returns a specific table row type.</li>
</ul>
<p><strong>Disable online query full table scan</strong></p>
<ul>
<li>Exceptions: constant minimal table, extremely low-frequency operations, table/return result set is very small (within 100 records/100 KB).</li>
<li>Using negative operators such as on the first-level filter condition will result in a full table scan and must be <code>!=</code>avoided .<code>&lt;&gt;</code></li>
</ul>
<p><strong>Disallow long waits in transactions</strong></p>
<ul>
<li>Transactions must be committed or rolled back as soon as possible after being started. Transactions that exceed 10 minutes <code>IDEL IN Transaction</code>will be forcibly killed.</li>
<li>Applications should enable AutoCommit to avoid <code>BEGIN</code>unpaired <code>ROLLBACK</code>or unpaired applications later <code>COMMIT</code>.</li>
<li>Try to use the transaction infrastructure provided by the standard library, and do not control transactions manually unless absolutely necessary.</li>
</ul>
<p><strong>Things to note when using count</strong></p>
<ul>
<li><code>count(*)</code>It is the standard syntax for <strong>counting rows</strong> and has nothing to do with null values.</li>
<li><code>count(col)</code>The count is <strong>the number of non-null records</strong><code>col</code> in the column . NULL values in this column will not be counted.</li>
<li><code>count(distinct col)</code>When <code>col</code>deduplicating columns and counting them, null values are also ignored, that is, only the number of non-null distinct values is counted.</li>
<li><code>count((col1, col2))</code>When counting multiple columns, even if the columns to be counted are all empty, they will still be counted. <code>(NULL,NULL)</code>This is valid.</li>
<li><code>a(distinct (col1, col2))</code>For multi-column deduplication counting, even if the columns to be counted are all empty, they will be counted, <code>(NULL,NULL)</code>which is effective.</li>
</ul>
<p><strong>Things to note when using aggregate functions</strong></p>
<ul>
<li>All <code>count</code>aggregate functions except <code>NULL</code>But <code>count(col)</code>in this case it will be returned <code>0</code>as an exception.</li>
<li>If returning null from an aggregate function is not expected, use <code>coalesce</code>to set a default value.</li>
</ul>
<p><strong>Handle null values with caution</strong></p>
<ul>
<li>
<p>Clearly distinguish between zero values and null values. Use null values <code>IS NULL</code>for equivalence judgment, and use regular <code>=</code>operators for zero values for equivalence judgment.</p>
</li>
<li>
<p>When a null value is used as a function input parameter, it should have a type modifier, otherwise the overloaded function will not be able to identify which one to use.</p>
</li>
<li>
<p>Pay attention to the null value comparison logic: the result of any comparison operation involving null values is <code>unknown</code>  you need to pay attention to <code>null</code> the logic involved in Boolean operations:</p>
<ul>
<li><code>and</code>: <code>TRUE or NULL</code>Will return due to logical short circuit <code>TRUE</code>.</li>
<li><code>or</code>: <code>FALSE and NULL</code>Will return due to logical short circuit<code>FALSE</code></li>
<li>In other cases, as long as the operand appears <code>NULL</code>, the result is<code>NULL</code></li>
</ul>
</li>
<li>
<p>The result of logical judgment between null value and <strong>any value</strong> is null value, for example, <code>NULL=NULL</code>the return result is <code>NULL</code>not <code>TRUE/FALSE</code>.</p>
</li>
<li>
<p>For equality comparisons involving null values and non-null values, please use ``IS DISTINCT FROM <code> </code>for comparison to ensure that the comparison result is not null.</p>
</li>
<li>
<p>NULL values and aggregate functions: When <strong>all</strong> input values are NULL, the aggregate function returns NULL.</p>
</li>
</ul>
<p><strong>Note that the serial number is empty</strong></p>
<ul>
<li>When using <code>Serial</code>types, <code>INSERT</code>, <code>UPSERT</code>and other operations will consume sequence numbers, and this consumption will not be rolled back when the transaction fails.</li>
<li>When using an integer <code>INTEGER</code>as the primary key and the table has frequent insertion conflicts, you need to pay attention to the problem of integer overflow.</li>
</ul>
<p><strong>The cursor must be closed promptly after use</strong></p>
<p><strong>Repeated queries using prepared statements</strong></p>
<ul>
<li><strong>Prepared Statements</strong> should be used for repeated queries to eliminate the CPU overhead of database hard parsing. Pgbouncer versions earlier than 1.21 cannot support this feature in transaction pooling mode, please pay special attention.</li>
<li>Prepared statements will modify the connection status. Please pay attention to the impact of the connection pool on prepared statements.</li>
</ul>
<p><strong>Choose the appropriate transaction isolation level</strong></p>
<ul>
<li>The default isolation level is <strong>read committed</strong> , which is suitable for most simple read and write transactions. For ordinary transactions, choose the lowest isolation level that meets the requirements.</li>
<li>For write transactions that require transaction-level consistent snapshots, use the <strong>Repeatable Read</strong> isolation level.</li>
<li>For write transactions that have strict requirements on correctness (such as money-related), use the <strong>serializable</strong> isolation level.</li>
<li>When a concurrency conflict occurs between the RR and SR isolation levels, the application should actively retry depending on the error type.</li>
</ul>
<p>rh 09 <strong>Do not use count when judging the existence of a result.</strong></p>
<ul>
<li>It is faster than Count to <code>SELECT 1 FROM tbl WHERE xxx LIMIT 1</code>judge whether there are columns that meet the conditions.</li>
<li><code>SELECT exists(SELECT * FROM tbl WHERE xxx LIMIT 1)</code>The existence result can be converted to a Boolean value using .</li>
</ul>
<p><strong>Use the RETURNING clause to retrieve the modified results in one go</strong></p>
<ul>
<li><code>RETURNING</code>The clause can be used after the <code>INSERT</code>, <code>UPDATE</code>, <code>DELETE</code>statement to effectively reduce the number of database interactions.</li>
</ul>
<p><strong>Use UPSERT to simplify logic</strong></p>
<ul>
<li>When the business has an insert-failure-update sequence of operations, consider using <code>UPSERT</code>substitution.</li>
</ul>
<p><strong>Use advisory locks to deal with hotspot concurrency</strong> .</p>
<ul>
<li>For extremely high-frequency concurrent writes (spike) of single-row records, advisory locks should be used to lock the record ID.</li>
<li>If high concurrency contention can be resolved at the application level, don&rsquo;t do it at the database level.</li>
</ul>
<p><strong>Optimize IN operator</strong></p>
<ul>
<li>Use <code>EXISTS</code>clause instead of <code>IN</code>operator for better performance.</li>
<li>Use <code>=ANY(ARRAY[1,2,3,4])</code>instead <code>IN (1,2,3,4)</code>for better results.</li>
<li>Control the size of the parameter list. In principle, it should not exceed 10,000. If it exceeds, you can consider batch processing.</li>
</ul>
<p><strong>It is not recommended to use left fuzzy search</strong></p>
<ul>
<li>Left fuzzy search <code>WHERE col LIKE '%xxx'</code>cannot make full use of B-tree index. If necessary, <code>reverse</code>expression function index can be used.</li>
</ul>
<p><strong>Use arrays instead of temporary tables</strong></p>
<ul>
<li>Consider using an array instead of a temporary table, for example when obtaining corresponding records for a series of IDs. <code>=ANY(ARRAY[1,2,3])</code>Better than temporary table JOIN.</li>
</ul>
<hr>
<h2 id="0x04-administration-convention">0x04 Administration Convention</h2>
<p><strong>Use Pigsty to build PostgreSQL cluster and infrastructure</strong></p>
<ul>
<li>The production environment uses the Pigsty trunk version uniformly, and deploys the database on x86_64 machines and CentOS 7.9 / RockyLinux 8.8 operating systems.</li>
<li><code>pigsty.yml</code>Configuration files usually contain highly sensitive and important confidential information. Git should be used for version management and access permissions should be strictly controlled.</li>
<li><code>files/pki</code>The CA private key and other certificates generated within the system should be properly kept, regularly backed up to a secure area for storage and archiving, and access permissions should be strictly controlled.</li>
<li>All passwords are not allowed to use default values, and make sure they have been changed to new passwords with sufficient strength.</li>
<li>Strictly control access rights to management nodes and configuration code warehouses, and only allow DBA login and access.</li>
</ul>
<p><strong>Monitoring system is a must</strong></p>
<ul>
<li>Any deployment must have a monitoring system, and the production environment uses at least two sets of Infra nodes to provide redundancy.</li>
</ul>
<p><strong>Properly plan the cluster architecture according to needs</strong></p>
<ul>
<li>Any production database cluster managed by a DBA must have at least one online slave database for online failover.</li>
<li>The template is used by default <code>oltp</code>, the analytical database uses <code>olap</code>the template, the financial database uses <code>crit</code>the template, and the micro virtual machine (within four cores) uses <code>tiny</code>the template.</li>
<li>For businesses whose annual data volume exceeds 1TB, or for clusters whose write TPS exceeds 30,000 to 50,000, you can consider building a horizontal sharding cluster.</li>
</ul>
<p><strong>Configure cluster high availability using Patroni and Etcd</strong></p>
<ul>
<li>The production database cluster uses Patroni as the high-availability component and etcd as the DCS.</li>
<li><code>etcd</code>Use a dedicated virtual machine cluster, with 3 to 5 nodes, strictly scattered and distributed on different cabinets.</li>
<li>Patroni Failsafe mode must be turned on to ensure that the cluster main library can continue to work when etcd fails.</li>
</ul>
<p><strong>Configure cluster PITR using pgBackRest and MinIO</strong></p>
<ul>
<li>The production database cluster uses pgBackRest as the backup recovery/PITR solution and MinIO as the backup storage warehouse.</li>
<li>MinIO uses a multi-node multi-disk cluster, and can also use S3/OSS/COS services instead. Password encryption must be set for cold backup.</li>
<li>All database clusters perform a local full backup every day, retain the backup and WAL of the last week, and save a full backup every other month.</li>
<li>When a WAL archiving error occurs, you should check the backup warehouse and troubleshoot the problem in time.</li>
</ul>
<p><strong>Core business database configuration considerations</strong></p>
<ul>
<li>The core business cluster needs to configure at least two online slave libraries, one of which is a dedicated offline query instance.</li>
<li>The core business cluster needs to build a delayed slave cluster with a 24-hour delay for emergency data recovery.</li>
<li>Core business clusters usually use asynchronous submission, while those related to money use synchronous submission.</li>
</ul>
<p><strong>Financial database configuration considerations</strong></p>
<ul>
<li>The financial database cluster requires at least two online slave databases, one of which is a dedicated synchronization Standby instance, and Standby service access is enabled.</li>
<li>Money-related libraries must use <code>crit</code>templates with RPO = 0, enable synchronous submission to ensure zero data loss, and enable Watchdog as appropriate.</li>
<li>Money-related libraries must be forced to turn on data checksums and, if appropriate, turn on full DML logs.</li>
</ul>
<p><strong>Use reasonable character encoding and localization configuration</strong></p>
<ul>
<li>Character encoding must be used <code>UTF8</code>, any other character encoding is strictly prohibited.</li>
<li>Must be used <code>C</code>as <code>LC_COLLATE</code>the default collation, any special requirements must be explicitly specified in the DDL/query clause to implement.</li>
<li>Character set <code>LC_CTYPE</code>is used by default <code>en_US.UTF8</code>, some extensions rely on character set information to work properly, such as <code>pg_trgm</code>.</li>
</ul>
<p><strong>Business database management considerations</strong></p>
<ul>
<li>Multiple different databases are allowed to be created in the same cluster, and Ansible scripts must be used to create new business databases.</li>
<li>All business databases must exist synchronously in the Pgbouncer connection pool.</li>
</ul>
<p><strong>Business user management considerations</strong></p>
<ul>
<li>Different businesses/services must use different database users, and Ansible scripts must be used to create new business users.</li>
<li>All production business users must be synchronized in the user list file of the Pgbouncer connection pool.</li>
<li>Individual users should set a password with a default validity period of 90 days and change it regularly.</li>
<li>Individual users are only allowed to access authorized cluster offline instances or slave <code>pg_offline_query</code>libraries with from the springboard machine.</li>
</ul>
<p><strong>Notes on extension management</strong></p>
<ul>
<li><code>yum/apt</code>When installing a new extension, you must first install the corresponding major version of the extension binary package in all instances of the cluster .</li>
<li>Before enabling the extension, you need to confirm whether the extension needs to be added <code>shared_preload_libraries</code>. If necessary, a rolling restart should be arranged.</li>
<li>Note that <code>shared_preload_libraries</code>in order of priority, <code>citus</code>, <code>timescaledb</code>, <code>pgml</code>are usually placed first.</li>
<li><code>pg_stat_statements</code>and <code>auto_explain</code>are required plugins and must be enabled in all clusters.</li>
<li>Install extensions uniformly using , and create them <code>dbsu</code>in the business database .<code>CREATE EXTENSION</code></li>
</ul>
<p><strong>Database XID and age considerations</strong></p>
<ul>
<li>Pay attention to the age of the database and tables to avoid running out of XID transaction numbers. If the usage exceeds 20%, you should pay attention; if it exceeds 50%, you should intervene immediately.</li>
<li>When processing XID, execute the table one by one in order of age from largest to smallest <code>VACUUM FREEZE</code>.</li>
</ul>
<p><strong>Database table and index expansion considerations</strong></p>
<ul>
<li>Pay attention to the expansion rate of tables and indexes to avoid index performance degradation, and use <code>pg_repack</code>online processing to handle table/index expansion problems.</li>
<li>Generally speaking, indexes and tables whose expansion rate exceeds 50% can be considered for reorganization.</li>
<li>When dealing with table expansion exceeding 100GB, you should pay special attention and choose business low times.</li>
</ul>
<p><strong>Database restart considerations</strong></p>
<ul>
<li>Before restarting the database, execute it <code>CHECKPOINT</code>twice to force dirty pages to be flushed, which can speed up the restart process.</li>
<li>Before restarting the database, perform <code>pg_ctl reload</code>reload configuration to confirm that the configuration file is available normally.</li>
<li>To restart the database, use <code>pg_ctl restart</code>patronictl or patronictl to restart the entire cluster at the same time.</li>
<li>Use <code>kill -9</code>to shut down any database process is strictly prohibited.</li>
</ul>
<p><strong>Replication latency considerations</strong></p>
<ul>
<li>Monitor replication latency, especially when using replication slots.</li>
</ul>
<p><strong>New slave database data warm-up</strong></p>
<ul>
<li>When adding a new slave database instance to a high-load business cluster, the new database instance should be warmed up, and the HAProxy instance weight should be gradually adjusted and applied in gradients: 4, 8, 16, 32, 64, and 100. <code>pg_prewarm</code>Hot data can be loaded into memory using .</li>
</ul>
<p><strong>Database publishing process</strong></p>
<ul>
<li>Online database release requires several evaluation stages: R&amp;D self-test, supervisor review, QA review (optional), and DBA review.</li>
<li>During the R&amp;D self-test phase, R&amp;D should ensure that changes are executed correctly in the development and pre-release environments.
<ul>
<li>If a new table is created, the record order magnitude, daily data increment estimate, and read and write throughput magnitude estimate should be given.</li>
<li>If it is a new function, the average execution time and extreme case descriptions should be given.</li>
<li>If it is a mode change, all upstream and downstream dependencies must be sorted out.</li>
<li>If it is a data change and record revision, a rollback SQL must be given.</li>
</ul>
</li>
<li>The R&amp;D Team Leader needs to evaluate and review changes and be responsible for the content of the changes.</li>
<li>The DBA evaluates and reviews the form and impact of the release, puts forward review opinions, and calls back or implements them uniformly.</li>
</ul>
<p><strong>Data work order format</strong></p>
<ul>
<li>Database changes are made through the platform, with one work order for each change.</li>
<li>The title is clear: A certain business needs <code>xx</code>to perform an action in the database <code>yy</code>.</li>
<li>The goal is clear: what operations need to be performed on which instances in each step, and how to verify the results.</li>
<li>Rollback plan: Any changes need to provide a rollback plan, and new ones also need to provide a cleanup script.</li>
<li>Any changes need to be recorded and archived, and have complete approval records. They are first approved by the R&amp;D superior TL Review and then approved by the DBA.</li>
</ul>
<p><strong>Database change release considerations</strong></p>
<ul>
<li>Using a unified release window, changes of the day will be collected uniformly at 16:00 every day and executed sequentially; requirements confirmed by TL after 16:00 will be postponed to the next day. Database release is not allowed after 19:00. For emergency releases, please ask TL to make special instructions and send a copy to the CTO for approval before execution.</li>
<li>Database DDL changes and DML changes are uniformly <code>dbuser_dba</code>executed remotely using the administrator user to ensure that the default permissions work properly.</li>
<li>When the business administrator executes DDL by himself, <strong>he must</strong><code>SET ROLE dbrole_admin</code> first execute the release to ensure the default permissions.</li>
<li>Any changes require a rollback plan before they can be executed, and very few operations that cannot be rolled back need to be handled with special caution (such as enumeration of value additions)</li>
<li>Database changes use <code>psql</code>command line tools, connect to the cluster main database to execute, use <code>\i</code>execution scripts or <code>\e</code>manual execution in batches.</li>
</ul>
<p><strong>Things to note when deleting tables</strong></p>
<ul>
<li>The production data table <code>DROP</code>should be renamed first and allowed to cool for 1 to 3 days to ensure that it is not accessed before being removed.</li>
<li>When cleaning the table, you must sort out all dependencies, including directly and indirectly dependent objects: triggers, foreign key references, etc.</li>
<li>The temporary table to be deleted is usually placed in <code>trash</code>Schema and <code>ALTER TABLE SET SCHEMA</code>the schema name is modified.</li>
<li>In high-load business clusters, when removing particularly large tables (&gt; 100G), select business valleys to avoid preempting I/O.</li>
</ul>
<p><strong>Things to note when creating and deleting indexes</strong></p>
<ul>
<li>You must use <code>CREATE INDEX CONCURRENTLY</code>concurrent index creation and <code>DROP INDEX CONCURRENTLY</code>concurrent index removal.</li>
<li>When rebuilding an index, always create a new index first, then remove the old index, and modify the new index name to be consistent with the old index.</li>
<li>After index creation fails, you should remove <code>INVALID</code>the index in time. After modifying the index, use <code>analyze</code>to re-collect statistical data on the table.</li>
<li>When the business is idle, you can enable parallel index creation and set it <code>maintenance_work_mem</code>to a larger value to speed up index creation.</li>
</ul>
<p><strong>Make schema changes carefully</strong></p>
<ul>
<li>Try to avoid full table rewrite changes as much as possible. Full table rewrite is allowed for tables within 1GB. The DBA should notify all relevant business parties when the changes are made.</li>
<li>When adding new columns to an existing table, you should avoid using functions in default values <code>VOLATILE</code>to avoid a full table rewrite.</li>
<li>When changing a column type, all functions and views that depend on that type should be rebuilt if necessary, and <code>ANALYZE</code>statistics should be refreshed.</li>
</ul>
<p><strong>Control the batch size of data writing</strong></p>
<ul>
<li>Large batch write operations should be divided into small batches to avoid generating a large amount of WAL or occupying I/O at one time.</li>
<li>After a large batch <code>UPDATE</code>is executed, <code>VACUUM</code>the space occupied by dead tuples is reclaimed.</li>
<li>The essence of executing DDL statements is to modify the system directory, and it is also necessary to control the number of DDL statements in a batch.</li>
</ul>
<p><strong>Data loading considerations</strong></p>
<ul>
<li>Use <code>COPY</code>load data, which can be executed in parallel if necessary.</li>
<li>You can temporarily shut down before loading data <code>autovacuum</code>, disable triggers as needed, and create constraints and indexes after loading.</li>
<li>Turn it up <code>maintenance_work_mem</code>, increase it <code>max_wal_size</code>.</li>
<li>Executed after loading is complete <code>vacuum verbose analyze table</code>.</li>
</ul>
<p><strong>Notes on database migration and major version upgrades</strong></p>
<ul>
<li>The production environment uniformly uses standard migration to build script logic, and realizes requirements such as non-stop cluster migration and major version upgrades through blue-green deployment.</li>
<li>For clusters that do not require downtime, you can use <code>pg_dump | psql</code>logical export and import to stop and upgrade.</li>
</ul>
<p><strong>Data Accidental Deletion/Accidental Update Process</strong></p>
<ul>
<li>After an accident occurs, immediately assess whether it is necessary to stop the operation to stop bleeding, assess the scale of the impact, and decide on treatment methods.</li>
<li>If there is a way to recover on the R&amp;D side, priority will be given to the R&amp;D team to make corrections through SQL publishing; otherwise, use <code>pageinspect</code>and <code>pg_dirtyread</code>to rescue data from the bad table.</li>
<li>If there is a delayed slave library, extract data from the delayed slave library for repair. First, confirm the time point of accidental deletion, and advance the delay to extract data from the database to the XID.</li>
<li>A large area was accidentally deleted and written. After communicating with the business and agreeing, perform an in-place PITR rollback to a specific time.</li>
</ul>
<p><strong>Data corruption processing process</strong></p>
<ul>
<li>Confirm whether the slave database data can be used for recovery. If the slave database data is intact, you can switchover to the slave database first.</li>
<li>Temporarily shut down <code>auto_vacuum</code>, locate the root cause of the error, replace the failed disk and add a new slave database.</li>
<li>If the system directory is damaged, or use to <code>pg_filedump</code>recover data from table binaries.</li>
<li>If the CLOG is damaged, use <code>dd</code>to generate a fake submission record.</li>
</ul>
<p><strong>Things to note when the database connection is full</strong></p>
<ul>
<li>When the connection is full (avalanche), immediately use the kill connection query to cure the symptoms and stop the loss: <code>pg_cancel_backend</code>or <code>pg_terminate_backend</code>.</li>
<li>Use to <code>pg_terminate_backend</code>abort all normal backend processes, <code>psql</code> <code>\watch 1</code>starting with once per second ( ). And confirm the connection status from the monitoring system. If the accumulation continues, continue to increase the execution frequency of the connection killing query, for example, once every 0.1 seconds until there is no more accumulation.</li>
<li>After confirming that the bleeding has stopped from the monitoring system, try to stop the killing connection. If the accumulation reappears, immediately resume the killing connection. Immediately analyze the root cause and perform corresponding processing (upgrade, limit current, add index, etc.)</li>
</ul>

</div>





    
	
  
    
    
	
    


  

<div class="td-content" style="page-break-before: always">
    <h1 id="pg-9ac7b152e2b98d51f3cf9cda74feaf4a">PostgreSQL, The most successful database</h1>
	
	<div class="td-byline mb-4">
		By <b><a href="https://vonng.com">RuohangFeng</a>(<a href="https://vonng.com/en/">@Vonng</a>)| <a href="https://mp.weixin.qq.com/s/xewE87WEaZHp-K5hjuk65A">WeChat</a> | <a href="https://zhuanlan.zhihu.com/p/542019272">Zhihu</a></b> |
        
		<time datetime="2023-06-28" class="text-muted">2023-06-28</time>
        
	</div>
	<p>The <a href="https://survey.stackoverflow.co/2023">StackOverflow 2023 Survey</a>, featuring feedback from 90K developers across 185 countries, is out. PostgreSQL topped all three survey categories (used, loved, and wanted), earning its title as the undisputed &ldquo;Decathlete Database&rdquo; – it&rsquo;s hailed as the <strong>&ldquo;Linux of Database&rdquo;</strong>!</p>
<p><img src="/img/blog/db/pg-is-no1-1.png"></p>
<blockquote>
<p><a href="https://demo.pigsty.cc/d/sf-survey">https://demo.pigsty.cc/d/sf-survey</a></p>
</blockquote>
<p>What makes a database &ldquo;successful&rdquo;? It’s a mix of features, quality, security, performance, and cost, but success is mainly about adoption and legacy. The size, preference, and needs of its user base are what truly shape its ecosystem&rsquo;s prosperity. StackOverflow&rsquo;s annual surveys for seven years have provided a window into tech trends.</p>
<p><strong>PostgreSQL is now the world’s most popular database.</strong></p>
<p><strong>PostgreSQL is developers&rsquo; favorite database!</strong></p>
<p><strong>PostgreSQL sees the highest demand among users!</strong></p>
<p>Popularity, the <code>used</code> reflects the past, the <code>loved</code> indicates the present, and the <code>wanted</code> suggests the future. These metrics vividly showcase the vitality of a technology. PostgreSQL stands strong in both stock and potential, unlikely to be rivaled soon.</p>
<p>As a dedicated user, community member, expert, evangelist, and contributor to PostgreSQL, witnessing this moment is profoundly moving. Let&rsquo;s delve into the &ldquo;Why&rdquo; and &ldquo;What&rdquo; behind this phenomenon.</p>
<hr>
<h2 id="source-community-survey">Source: Community Survey</h2>
<p>Developers define the success of databases, and StackOverflow&rsquo;s survey, with popularity, love, and demand metrics, captures this directly.</p>
<blockquote>
<p>“Which <strong>database environments</strong> have you done extensive development work in over the past year, and which do you want to work in over the next year? If you both worked with the database and want to continue to do so, please check both boxes in that row.”</p>
</blockquote>
<p>Each database in the survey had two checkboxes: one for current use, marking the user as &ldquo;Used,&rdquo; and one for future interest, marking them as &ldquo;Wanted.&rdquo; Those who checked both were labeled as &ldquo;Loved/Admired.&rdquo;</p>
<p><img src="/img/blog/db/pg-is-no1-2.png"></p>
<blockquote>
<p><a href="https://survey.stackoverflow.co/2023">https://survey.stackoverflow.co/2023</a></p>
</blockquote>
<p>The percentage of &ldquo;Used&rdquo; respondents represents <strong>popularity</strong> or usage rate, shown as a bar chart, while &ldquo;Wanted&rdquo; indicates demand or desire, marked with blue dots. &ldquo;Loved/Admired&rdquo; shows as red dots, indicating love or reputation. In 2023, PostgreSQL outstripped MySQL in popularity, becoming the world’s most popular database, and led by a wide margin in demand and reputation.</p>
<p>Reviewing seven years of data and plotting the top 10 databases on a scatter chart of popularity vs. net love percentage (2*love% - 100), we gain insights into the database field&rsquo;s evolution and sense of scale.</p>
<p><img src="/img/blog/db/pg-is-no1-3.gif"></p>
<blockquote>
<p>X: Popularity, Y: Net Love Index (2 * loved - 100)</p>
</blockquote>
<p>The 2023 snapshot shows PostgreSQL in the top right, popular and loved, while MySQL, popular yet less favored, sits in the bottom right. Redis, moderately popular but much loved, is in the top left, and Oracle, neither popular nor loved, is in the bottom left. In the middle lie SQLite, MongoDB, and SQL Server.</p>
<p>Trends indicate PostgreSQL&rsquo;s growing popularity and love; MySQL&rsquo;s love remains flat with falling popularity. Redis and SQLite are progressing, MongoDB is peaking and declining, and the commercial RDBMSs SQL Server and Oracle are on a downward trend.</p>
<p>The takeaway: PostgreSQL&rsquo;s standing in the database realm, akin to Linux in server OS, seems unshakeable for the foreseeable future.</p>
<hr>
<h2 id="historical-accumulation-popularity">Historical Accumulation: Popularity</h2>
<blockquote>
<p>PostgreSQL — The world&rsquo;s most popular database</p>
</blockquote>
<p>Popularity is the percentage of total users who have used a technology in the past year. It reflects the accumulated usage over the past year and is a core metric of factual significance.</p>
<p>In 2023, PostgreSQL, branded as the &ldquo;most advanced,&rdquo; surpassed the &ldquo;most popular&rdquo; database MySQL with a usage rate of 45.6%, leading by 4.5% and reaching 1.1 times the usage rate of MySQL at 41.1%. Among professional developers (about three-quarters of the sample), PostgreSQL had already overtaken MySQL in 2022, with a 0.8 percentage point lead (46.5% vs 45.7%); this gap widened in 2023 to 49.1% vs 40.6%, or 1.2 times the usage rate among professional developers.</p>
<p>Over the past years, MySQL enjoyed the top spot in database popularity, proudly claiming the title of the “world’s most popular open-source relational database.” However, PostgreSQL has now claimed the crown. Compared to PostgreSQL and MySQL, other databases are not in the same league in terms of popularity.</p>
<p>The key trend to note is that among the top-ranked databases, only PostgreSQL has shown a consistent increase in popularity, demonstrating strong growth momentum, while all other databases have seen a decline in usage. As time progresses, the gap in popularity between PostgreSQL and other databases will likely widen, making it hard for any challenger to displace PostgreSQL in the near future.</p>
<p>Notably, the &ldquo;domestic database&rdquo; TiDB has entered the StackOverflow rankings for the first time, securing the 32nd spot with a 0.2% usage rate.</p>
<p>Popularity reflects the current scale and potential of a database, while love indicates its future growth potential.</p>
<hr>
<h2 id="current-momentum-love">Current Momentum: Love</h2>
<blockquote>
<p>PostgreSQL — The database developers love the most</p>
</blockquote>
<p>Love or admiration is a measure of the percentage of users who are willing to continue using a technology, acting as an annual &ldquo;retention rate&rdquo; metric that reflects the user&rsquo;s opinion and evaluation of the technology.</p>
<p>In 2023, PostgreSQL retained its title as the most loved database by developers. While Redis had been the favorite in previous years, PostgreSQL overtook Redis in 2022, becoming the top choice. PostgreSQL and Redis have maintained close reputation scores (around 70%), significantly outpacing other contenders.</p>
<p><img src="/img/blog/db/pg-is-no1-6.png"></p>
<p>In the 2022 PostgreSQL community survey, the majority of existing PostgreSQL users reported increased usage and deeper engagement, highlighting the stability of its core user base.</p>
<p><img src="/img/blog/db/pg-is-no1-7.png"></p>
<p>Redis, known for its simplicity and ease of use as a data structure cache server, is often paired with the relational database PostgreSQL, enjoying considerable popularity (20%, ranking sixth) among developers. Cross-analysis shows a strong connection between the two: 86% of Redis users are interested in using PostgreSQL, and 30% of PostgreSQL users want to use Redis. Other databases with positive reviews include SQLite, MongoDB, and SQL Server. MySQL and ElasticSearch receive mixed feedback, hovering around the 50% mark. The least favored databases include Access, IBM DB2, CouchDB, Couchbase, and Oracle.</p>
<p>Not all <strong>potential</strong> can be converted into kinetic energy. While user affection is significant, it doesn&rsquo;t always translate into action, leading to the third metric of interest – demand.</p>
<hr>
<h2 id="future-trends-demand">Future Trends: Demand</h2>
<blockquote>
<p>PostgreSQL - The Most Wanted Database</p>
</blockquote>
<p>The demand rate, or the level of desire, represents the percentage of users who will actually opt for a technology in the coming year. PostgreSQL stands out in demand/desire, significantly outpacing other databases with a 42.3% rate for the second consecutive year, showing relentless growth and widening the gap with its competitors.</p>
<p><img src="/img/blog/db/pg-is-no1-8.png"></p>
<p>In 2023, some databases saw notable demand increases, likely driven by the surge in large language model AI, spearheaded by OpenAI&rsquo;s ChatGPT. This demand for intelligence has, in turn, fueled the need for robust data infrastructure. A decade ago, support for NoSQL features like JSONB/GIN laid the groundwork for PostgreSQL&rsquo;s explosive growth during the internet boom. Today, the introduction of pgvector, the first vector extension built on a mature database, grants PostgreSQL a ticket into the AI era, setting the stage for growth in the next decade.</p>
<hr>
<h2 id="but-why">But Why?</h2>
<p>PostgreSQL leads in demand, usage, and popularity, with the right mix of timing, location, and human support, making it arguably the most successful database with no visible challengers in the near future. The secret to its success lies in its slogan: <strong>&ldquo;The World&rsquo;s Most Advanced Open Source Relational Database.&rdquo;</strong></p>
<p>Relational databases are so prevalent and crucial that they might dwarf the combined significance of other types like key-value, document, search engine, time-series, graph, and vector databases. Typically, &ldquo;database&rdquo; implicitly refers to &ldquo;relational database,&rdquo; where no other category dares claim mainstream status. Last year&rsquo;s &ldquo;Why PostgreSQL Will Be the Most Successful Database?&rdquo; delves into the competitive landscape of relational databases—a tripartite dominance. Excluding Microsoft’s relatively isolated SQL Server, the database scene, currently in a phase of consolidation, has three key players rooted in WireProtocol: Oracle, MySQL, and PostgreSQL, mirroring a <strong>&ldquo;Three Kingdoms&rdquo;</strong> saga in the relational database realm.</p>
<p><img src="/img/blog/db/pg-is-no1-9.png"></p>
<p>Oracle/MySQL are waning, while PostgreSQL is thriving. Oracle is an established commercial DB with deep tech history, rich features, and strong support, favored by well-funded, risk-averse enterprises, especially in finance. Yet, it&rsquo;s pricey and infamous for litigious practices. MS SQL Server shares similar traits with Oracle. Commercial databases are facing a slow decline due to the open-source wave.</p>
<p>MySQL, popular yet beleaguered, lags in stringent transaction processing and data analysis compared to PostgreSQL. Its agile development approach is also outperformed by NoSQL alternatives. Oracle&rsquo;s dominance, sibling rivalry with MariaDB, and competition from NewSQL players like TiDB/OB contribute to its decline.</p>
<p>Oracle, no doubt skilled, lacks integrity, hence &ldquo;talented but unprincipled.&rdquo; MySQL, despite its open-source merit, is limited in capability and sophistication, hence &ldquo;limited talent, weak ethics.&rdquo; PostgreSQL, embodying both capability and integrity, aligns with the open-source rise, popular demand, and advanced stability, epitomizing &ldquo;talented and principled.&rdquo;</p>
<hr>
<h2 id="open-source--advanced">Open Source &amp; Advanced</h2>
<p>The primary reasons for choosing PostgreSQL, as reflected in the TimescaleDB community survey, are its open-source nature and stability. Open-source implies free use, potential for modification, no vendor lock-in, and no &ldquo;chokepoint&rdquo; issues. Stability means reliable, consistent performance with a proven track record in large-scale production environments. Experienced developers value these attributes highly.</p>
<p>Broadly, aspects like extensibility, ecosystem, community, and protocols fall under &ldquo;open-source.&rdquo; Stability, ACID compliance, SQL support, scalability, and availability define &ldquo;advanced.&rdquo; These resonate with PostgreSQL&rsquo;s slogan: &ldquo;The world&rsquo;s most advanced open source relational database.&rdquo;</p>
<p><img src="/img/blog/db/pg-is-no1-10.png"></p>
<blockquote>
<p><a href="https://www.timescale.com/state-of-postgres/2022">https://www.timescale.com/state-of-postgres/2022</a></p>
</blockquote>
<hr>
<h2 id="the-virtue-of-open-source">The Virtue of Open Source</h2>
<blockquote>
<p>powered by developers worldwide. Friendly BSD license, thriving ecosystem, extensive expansion. A robust Oracle alternative, leading the charge.</p>
</blockquote>
<p>What is &ldquo;virtue&rdquo;? It&rsquo;s the manifestation of &ldquo;the way,&rdquo; and this way is <strong>open source</strong>. PostgreSQL stands as a venerable giant among open-source projects, epitomizing global collaborative success.</p>
<p>Back in the day, developing software/information services required exorbitantly priced <strong>commercial databases</strong>. Just the software licensing fees could hit six or seven figures, not to mention similar costs for hardware and service subscriptions. Oracle&rsquo;s licensing fee per CPU core could reach hundreds of thousands annually, prompting even giants like Alibaba to seek <strong>IOE alternatives</strong>. The rise of <strong>open-source databases</strong> like <strong>PostgreSQL</strong> and <strong>MySQL</strong> offered a fresh choice.</p>
<p>Open-source databases, free of charge, spurred an industry revolution: from tens of thousands per core per month for commercial licenses to a mere 20 bucks per core per month for hardware. Databases became accessible to regular businesses, enabling the provision of free information services.</p>
<p><img src="/img/blog/db/pg-is-no1-11.png"></p>
<p>Open source has been monumental: the history of the internet is a history of open-source software. The prosperity of the IT industry and the plethora of free information services owe much to open-source initiatives. <strong>Open source represents a form of successful Communism</strong> in software, with the industry&rsquo;s core means of production becoming communal property, available to developers worldwide as needed. Developers contribute according to their abilities, embracing the ethos of mutual benefit.</p>
<p>An open-source programmer&rsquo;s work encapsulates the intellect of countless top-tier developers. Programmers command high salaries because they are not mere laborers but <strong>contractors</strong> orchestrating software and hardware. They own the core means of production: software from the public domain and readily available server hardware. Thus, a few skilled engineers can swiftly tackle domain-specific problems leveraging the <strong>open-source ecosystem</strong>.</p>
<p><strong>Open source synergizes community efforts, drastically reducing redundancy and propelling technical advancements at an astonishing pace. Its momentum, now unstoppable, continues to grow like a snowball.</strong> Open source dominates foundational software, and the industry now views insular development or so-called &ldquo;self-reliance&rdquo; in software, especially in foundational aspects, as a colossal joke.</p>
<p><img src="/img/blog/db/pg-is-no1-12.png"></p>
<p><strong>For PostgreSQL, open source is its strongest asset against Oracle.</strong></p>
<p>Oracle is advanced, but PostgreSQL holds its own. It&rsquo;s the most Oracle-compatible open-source database, natively supporting 85% of Oracle&rsquo;s features, with specialized distributions reaching 96% compatibility. However, the real game-changer is cost: PG&rsquo;s open-source nature and significant cost advantage provide a substantial ecological niche. It doesn&rsquo;t need to surpass Oracle in features; being &ldquo;90% right at a fraction of the cost&rdquo; is enough to outcompete Oracle.</p>
<p>PostgreSQL is like an open-source &ldquo;Oracle,&rdquo; the only real threat to Oracle&rsquo;s dominance. As a leader in the &ldquo;de-Oracle&rdquo; movement, PG has spawned numerous &ldquo;domestically controllable&rdquo; database companies. According to CITIC, 36% of &ldquo;domestic databases&rdquo; are based on PG modifications or rebranding, with Huawei&rsquo;s openGauss and GaussDB as prime examples. Crucially, PostgreSQL uses a BSD-Like license, permitting such adaptations — you can rebrand and sell without deceit. This open attitude is something Oracle-acquired, GPL-licensed MySQL can&rsquo;t match.</p>
<hr>
<h2 id="the-advanced-in-talent">The advanced in Talent</h2>
<blockquote>
<p>The talent of PG lies in its advancement. Specializing in multiple areas, PostgreSQL offers a full-stack, multi-model approach: &ldquo;Self-managed, autonomous driving temporal-geospatial AI vector distributed document graph with full-text search, programmable hyper-converged, federated stream-batch processing in a single HTAP Serverless full-stack platform database&rdquo;, covering almost all database needs with a single component.</p>
</blockquote>
<p>PostgreSQL is not just a traditional OLTP &ldquo;relational database&rdquo; but a multi-modal database. For SMEs, a single PostgreSQL component can cover the vast majority of their data needs: OLTP, OLAP, time-series, GIS, tokenization and full-text search, JSON/XML documents, NoSQL features, graphs, vectors, and more.</p>
<p><img src="/img/blog/db/pg-is-no1-13.png"></p>
<blockquote>
<p>Emperor of Databases — Self-managed, autonomous driving temporal-geospatial AI vector distributed document graph with full-text search, programmable hyper-converged, federated stream-batch processing in a single HTAP Serverless full-stack platform database.</p>
</blockquote>
<p>The superiority of PostgreSQL is not only in its acclaimed <strong>kernel stability</strong> but also in its powerful <strong>extensibility</strong>. The plugin system transforms PostgreSQL from a single-threaded evolving database kernel to a platform with countless parallel-evolving extensions, exploring all possibilities simultaneously like quantum computing. PostgreSQL is omnipresent in every niche of data processing.</p>
<p>For instance, PostGIS for geospatial databases, TimescaleDB for time-series, Citus for distributed/columnar/HTAP databases, PGVector for AI vector databases, AGE for graph databases, PipelineDB for stream processing, and the ultimate trick — using Foreign Data Wrappers (FDW) for unified SQL access to all heterogeneous external databases. Thus, PG is a true full-stack database platform, far more advanced than a simple OLTP system like MySQL.</p>
<p><img src="/img/blog/db/pg-is-no1-14.png"></p>
<p>Within a significant scale, PostgreSQL can play multiple roles with a single component, greatly reducing project complexity and cost. Remember, designing for unneeded scale is futile and an example of <strong>premature optimization</strong>. If one technology can meet all needs, it&rsquo;s the best choice rather than reimplementing it with multiple components.</p>
<p>Taking Tantan as an example, with <strong>250 million TPS</strong> and <strong>200 TB</strong> of unique TP data, <strong>a single PostgreSQL selection</strong> remains stable and reliable, covering a wide range of functions beyond its primary OLTP role, including caching, OLAP, batch processing, and even message queuing. However, as the user base approaches <strong>tens of millions daily active users</strong>, these additional functions will eventually need to be handled by dedicated components.</p>
<p><img src="/img/blog/db/pg-is-no1-15.png"></p>
<p>PostgreSQL&rsquo;s advancement is also evident in its thriving ecosystem. Centered around the database kernel, there are specialized variants and &ldquo;higher-level databases&rdquo; built on it, like Greenplum, Supabase (an open-source alternative to Firebase), and the specialized graph database edgedb, among others. There are various open-source/commercial/cloud distributions integrating tools, like different RDS versions and the plug-and-play Pigsty; horizontally, there are even powerful mimetic components/versions emulating other databases without changing client drivers, like babelfish for SQL Server, FerretDB for MongoDB, and EnterpriseDB/IvorySQL for Oracle compatibility.</p>
<p><img src="/img/blog/db/pg-is-no1-16.png"></p>
<p>PostgreSQL&rsquo;s advanced features are its core competitive strength against MySQL, another open-source relational database.</p>
<p><strong>Advancement is PostgreSQL&rsquo;s core competitive edge over MySQL.</strong></p>
<p>MySQL&rsquo;s slogan is &ldquo;the world&rsquo;s most popular open-source relational database,&rdquo; characterized by being rough, fierce, and fast, catering to internet companies. These companies prioritize simplicity (mainly CRUD), data consistency and accuracy less than traditional sectors like banking, and can tolerate data inaccuracies over service downtime, unlike industries that cannot afford financial discrepancies.</p>
<p>However, times change, and PostgreSQL has rapidly advanced, surpassing MySQL in speed and robustness, leaving only &ldquo;roughness&rdquo; as MySQL&rsquo;s remaining trait.</p>
<p><img src="/img/blog/db/pg-is-no1-17.png"></p>
<blockquote>
<p>MySQL allows partial transaction commits by default, shocked</p>
</blockquote>
<p>MySQL allows partial transaction commits by default, revealing a gap between &ldquo;popular&rdquo; and &ldquo;advanced.&rdquo; Popularity fades with obsolescence, while advancement gains popularity through innovation. In times of change, without advanced features, popularity is fleeting. Research shows MySQL&rsquo;s pride in &ldquo;popularity&rdquo; cannot stand against PostgreSQL&rsquo;s &ldquo;advanced&rdquo; superiority.</p>
<p><strong>Advancement</strong> and <strong>open-source</strong> are PostgreSQL&rsquo;s success secrets. While Oracle is advanced and MySQL is open-source, PostgreSQL boasts both. With the right conditions, success is inevitable.</p>
<hr>
<h2 id="looking-ahead">Looking Ahead</h2>
<p>The PostgreSQL database kernel&rsquo;s role in the database ecosystem mirrors the Linux kernel&rsquo;s in the operating system domain. For databases, particularly OLTP, the battle of kernels has settled—PostgreSQL is now a perfect engine.</p>
<p>However, users need more than an engine; they need the complete car, driving capabilities, and traffic services. The database competition has shifted from software to <strong>Software enabled Service—complete database distributions and services</strong>. The race for PostgreSQL-based distributions is just beginning. Who will be the PostgreSQL equivalent of Debian, RedHat, or Ubuntu?</p>
<p>This is why we created <strong><a href="https://pigsty.io/">Pigsty</a></strong> — to develop an battery-included, open-source, local-first PostgreSQL distribution, making it easy for everyone to access and utilize a <strong>quality database service</strong>. Due to space limits, the detailed story is for <a href="/zh/blog//db/pgsql-x-pigsty/">another time</a>.</p>
<p><img src="/img/blog/db/pg-is-no1-18.png"></p>
<hr>
<h2 id="参考阅读">参考阅读</h2>
<p>2022-08 《<a href="http://mp.weixin.qq.com/s?__biz=MzU5ODAyNTM5Ng==&mid=2247485240&idx=1&sn=9052f03ae2ef21d9e21037fd7a1fa7fe&chksm=fe4b32e3c93cbbf522616346c1afd49e1e6edbb0898694df224fe2134a69c0c4562aab35587a&scene=21#wechat_redirect">PostgreSQL 到底有多强？</a>》</p>
<p>2022-07 《<a href="http://mp.weixin.qq.com/s?__biz=MzU5ODAyNTM5Ng==&mid=2247485216&idx=1&sn=1b59c7dda5f347145c2f39d2679a274d&chksm=fe4b32fbc93cbbed574358a3bcf127dd2e4f458638b46efaee1a885a5702a66a5d9ca18e3f90&scene=21#wechat_redirect">为什么PostgreSQL是最成功的数据库？</a>》</p>
<p>2022-06 《<a href="http://mp.weixin.qq.com/s?__biz=MzU5ODAyNTM5Ng==&mid=2247485170&idx=1&sn=657c75be06557df26e4521ce64178f14&chksm=fe4b3329c93cba3f840283c9df0e836e96a410f540e34ac9b1b68ca4d6247d5f31c94e2a41f4&scene=21#wechat_redirect">StackOverflow 2022数据库年度调查</a>》</p>
<p>2021-05 《<a href="http://mp.weixin.qq.com/s?__biz=MzU5ODAyNTM5Ng==&mid=2247484604&idx=1&sn=357b3381e7636709fa9e5e06894b7273&chksm=fe4b3167c93cb8719b7c6b048fd300a7773c73319ba0c119359f4f8a6684cd969434c5abbdfd&scene=21#wechat_redirect">Why PostgreSQL Rocks!</a>》</p>
<p>2021-05 《<a href="http://mp.weixin.qq.com/s?__biz=MzU5ODAyNTM5Ng==&mid=2247484591&idx=1&sn=a6ab13d93bfa26fca969ba163b01e1d5&chksm=fe4b3174c93cb862899cbce4b9063ed009bfe735df16bce6b246042e897d494648473eea3cea&scene=21#wechat_redirect">为什么说PostgreSQL前途无量？</a>》</p>
<p>2018 《<a href="http://mp.weixin.qq.com/s?__biz=MzU5ODAyNTM5Ng==&mid=2247483706&idx=1&sn=b842684b41ac6dde8310448ae0a81a76&chksm=fe4b34e1c93cbdf7dcfcdae5f3ddc38bc422989421266dcda957fa2b596e361815624c92b3ec&scene=21#wechat_redirect">PostgreSQL 好处都有啥？</a>》</p>
<p>2023 《<a href="http://mp.weixin.qq.com/s?__biz=MzU5ODAyNTM5Ng==&mid=2247485518&idx=1&sn=3d5f3c753facc829b2300a15df50d237&chksm=fe4b3d95c93cb4833b8e80433cff46a893f939154be60a2a24ee96598f96b32271301abfda1f&scene=21#wechat_redirect">更好的开源RDS替代：Pigsty</a>》</p>
<p>2023 《<a href="http://demo.pigsty.cc/d/sf-db-survey">StackOverflow 7年调研数据跟踪</a>》</p>
<p>2022 《<a href="https://www.timescale.com/state-of-postgres/2022">PostgreSQL 社区状态调查报告 2022</a>》</p>

</div>





    
	
  



          </main>
        </div>
      </div>
      <footer class="td-footer row d-print-none">
  <div class="container-fluid">
    <div class="row mx-md-2">
      <div class="td-footer__left col-6 col-sm-4 order-sm-1">
        <ul class="td-footer__links-list">
  
  <li class="td-footer__links-item" data-bs-toggle="tooltip" title="Mail" aria-label="Mail">
    <a target="_blank" rel="noopener" href="mailto:rh@vonng.com" aria-label="Mail">
      <i class="fa fa-envelope"></i>
    </a>
  </li>
  
  <li class="td-footer__links-item" data-bs-toggle="tooltip" title="GitHub" aria-label="GitHub">
    <a target="_blank" rel="noopener" href="https://github.com/Vonng/pigsty" aria-label="GitHub">
      <i class="fab fa-github"></i>
    </a>
  </li>
  
  <li class="td-footer__links-item" data-bs-toggle="tooltip" title="Twitter" aria-label="Twitter">
    <a target="_blank" rel="noopener" href="https://twitter.com/GobeUncleWang" aria-label="Twitter">
      <i class="fab fa-twitter"></i>
    </a>
  </li>
  
</ul>

      </div><div class="td-footer__right col-6 col-sm-4 order-sm-3">
        <ul class="td-footer__links-list">
  
  <li class="td-footer__links-item" data-bs-toggle="tooltip" title="WeChat" aria-label="WeChat">
    <a target="_blank" rel="noopener" href="/img/pigsty/pigsty-cc.jpg" aria-label="WeChat">
      <i class="fa fa-comment"></i>
    </a>
  </li>
  
  <li class="td-footer__links-item" data-bs-toggle="tooltip" title="Discord" aria-label="Discord">
    <a target="_blank" rel="noopener" href="https://discord.gg/wDzt5VyWEz" aria-label="Discord">
      <i class="fab fa-discord"></i>
    </a>
  </li>
  
  <li class="td-footer__links-item" data-bs-toggle="tooltip" title="Telegram" aria-label="Telegram">
    <a target="_blank" rel="noopener" href="https://t.me/joinchat/gV9zfZraNPM3YjFh" aria-label="Telegram">
      <i class="fab fa-telegram"></i>
    </a>
  </li>
  
</ul>

      </div><div class="td-footer__center col-12 col-sm-4 py-2 order-sm-2">
        <span class="td-footer__copyright">&copy;
    2018&ndash;2025
    <span class="td-footer__authors">Ruohang Feng</span></span><span class="td-footer__all_rights_reserved">All Rights Reserved</span></span><span class="ms-2"><a href="https://vonng.com/en/" target="_blank" rel="noopener">@Vonng</a></span>
<br><span>Pigsty® distributed under <a href="/docs/about/license" target="_blank" rel="noopener">AGPLv3</a></span>
<br><span class="ms-2"><a href="/docs/about/privacy" target="_blank" rel="noopener">Privacy Policy</a></span>
<span><a href="http://beian.miit.gov.cn/" target="_blank" rel="noopener">浙ICP备15016890号</a></span>
      </div>
    </div>
  </div>
</footer>

    </div>
    <script src="/js/main.min.248655eb216150e39da254c2f7aa5357805d0ec66bdb741b591cd35fb5f629ab.js" integrity="sha256-JIZV6yFhUOOdolTC96pTV4BdDsZr23QbWRzTX7X2Kas=" crossorigin="anonymous"></script>
<script defer src="/js/click-to-copy.min.f724d3de49218995223b7316aa2e53e2b34bf42026bf399ebb21bb02212402d1.js" integrity="sha256-9yTT3kkhiZUiO3MWqi5T4rNL9CAmvzmeuyG7AiEkAtE=" crossorigin="anonymous"></script>
<script src='/js/tabpane-persist.js'></script>

  </body>
</html>
